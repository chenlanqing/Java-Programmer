# 1、Hadoop环境搭建

前提条件：
- JDK
- 免密SSH登录
- 设置hostname

## 1.1、Hadoop2.x环境



### 1.1.1、伪集群安装

**环境**
- 系统：CentOS7.4
- Hadoop版本：hadoop-2.6.0-cdh5.14.4
- JDK版本：1.8.0_231
- 机器IP，静态地址：192.168.89.145
- hostname：hadoop
- 免密SSH登录

**配置步骤**
- 解压 Hadoop-2.5.0
- 配置 `etc/hadoop/hadoop-env.sh`：配置 `export JAVA_HOME=/usr/java/jdk1.8.0_231-amd64`，即设置Java的安装目录；
- 配置文件 `etc/hadoop/hdfs-site.xml`：
    ```xml
    <configuration>
        <property>
            <name>dfs.replication</name>
            <value>1</value>
        </property>
        <property>
            <name>dfs.permissions.enabled</name>
            <value>false</value>
        </property>
    </configuration>
    ```
- 配置文件 `etc/hadoop/core-site.xml`：
    ```xml
    <configuration>
        <property>
            <name>fs.defaultFS</name>
            <!-- hdfs的目录地址，这里配置的是hostname:port  -->
            <value>hdfs://bigdata1:9000</value>
        </property>
        <property>
            <name>hadoop.tmp.dir</name>
            <!-- hadoop的临时目录 -->
            <value>/opt/modules/hadoop-2.5.0/data/tmp</value>
        </property>
    </configuration>
    ```
- 配置文件 `etc/hadoop/slaves`：单机的话，配置当前机器的 hostname 即可；
- 格式化hdfs：`bin/hdfs namenode -format`
- 启动Hadoop：
    - 启动namnode： `sbin/hadoop-daemon.sh start namenode`
    - 启动datanode： `sbin/hadoop-daemon.sh start datanode`

### 1.1.2、集群安装

**环境**
- 系统：CentOS7.4
- Hadoop版本：hadoop-2.6.0-cdh5.14.4
- JDK版本：1.8.0_231
- 三台机器：
    - 192.168.89.141 hadoop001（主）
    - 192.168.89.142 hadoop002
    - 192.168.89.143 hadoop003
- 免密SSH登录，需要hadoop001能够免密登录hadoop002、hadoop003

## 1.2、Hadoop3.x环境


### 1.2.1、伪集群安装

**环境**
- 系统：CentOS7.4
- Hadoop版本：3.2.0
- JDK版本：1.8.0_231
- 机器IP，静态地址：192.168.89.141
- hostname：hadoop001
- 免密SSH登录

**配置步骤**
- 解压缩 hadoop.3.2.tar.gz 到目录：`/data/soft/`
- 创建目录：`mkdir -p /data/hadoop_repo/logs/hadoop`
- 修改 `etc/hadoop/hadoop-env.sh`配置，增加环境变量信息：
    ```
    export JAVA_HOME=/usr/java/jdk1.8.0_231-amd64
    export HADOOP_LOG_DIR=/data/hadoop_repo/logs/hadoop
    ```
- 修改 `etc/hadoop/core-site.xml`，注意 `fs.defaultFS` 属性中的主机名需要和你配置的主机名保持一致：
    ```xml
    <configuration>
        <property>
            <name>fs.defaultFS</name>
            <value>hdfs://hadoop001:9000</value>
        </property>
        <property>
            <name>hadoop.tmp.dir</name>
            <value>/data/hadoop_repo</value>
        </property>
    </configuration>
    ```
- 修改 `etc/hdfs-site.xml`，把 hdfs 中文件副本的数量设置为 1，因为现在伪分布集群只有一 个节点
    ```xml
    <configuration>
        <property>
            <name>dfs.replication</name>
            <value>1</value>
        </property>
    </configuration>
    ```    

- 修改 `etc/mapred-site.xml`，设置 mapreduce 使用的资源调度框架
    ```xml
    m
    ```

- 修改 `etc/yarn-site.xml`，设置 yarn 上支持运行的服务和环境变量白名单
    ```xml
    <configuration>
        <property>
            <name>yarn.nodemanager.aux-services</name>
            <value>mapreduce_shuffle</value>
        </property>
        <property>
            <name>yarn.nodemanager.env-whitelist</name>
            <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CL ASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
        </property>
    </configuration>
    ```
- 格式化 namenode： `bin/hdfs namenode -format`

    如果在后面的日志信息中能看到这一行，则说明 namenode 格式化成功。 `common.Storage: Storage directory /data/hadoop_repo/dfs/name has been successfully formatted.`
- 启动hadoop：`sbin/start-all.sh`，直接启动会报错，报错信息：
    ```
    [root@hadoop001 hadoop-3.2.0]# sbin/start-all.sh
    ERROR: Attempting to operate on hdfs namenode as root
    ERROR: but there is no HDFS_NAMENODE_USER defined. Aborting operation.
    Starting datanodes
    ERROR: Attempting to operate on hdfs datanode as root
    ERROR: but there is no HDFS_DATANODE_USER defined. Aborting operation.
    Starting secondary namenodes [hadoop100]
    ERROR: Attempting to operate on hdfs secondarynamenode as root
    ERROR: but there is no HDFS_SECONDARYNAMENODE_USER defined. Aborting operation. 2019-07-25 10:04:25,993 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
    Starting resourcemanager
    ERROR: Attempting to operate on yarn resourcemanager as root
    ERROR: but there is no YARN_RESOURCEMANAGER_USER defined. Aborting operation.
    Starting nodemanagers
    ERROR: Attempting to operate on yarn nodemanager as root
    ERROR: but there is no YARN_NODEMANAGER_USER defined. Aborting operation
    ```
- 修改脚本：`sbin/start-dfs.sh, sbin/stop-dfs.sh`，增加如下内容：
    ```
    HDFS_DATANODE_USER=root
    HDFS_DATANODE_SECURE_USER=hdfs
    HDFS_NAMENODE_USER=root
    HDFS_SECONDARYNAMENODE_USER=root
    ```

- 修改脚本：`sbin/start-yarn.sh, sbin/stop-yarn.sh`，增加如下内容：
    ```
    YARN_RESOURCEMANAGER_USER=root
    HADOOP_SECURE_DN_USER=yarn
    YARN_NODEMANAGER_USER=root
    ```
- 启动集群：`sbin/start-all.sh`
- 验证集群是否正常：`jps`，或者通过页面访问
    ```
    # 执行 jps 命令可以查看集群的进程信息，抛出 Jps 这个进程之外还需要有 5 个进程才说明 集群是正常启动的
    [root@hadoop001 sbin]# jps
    2882 ResourceManager
    2420 DataNode
    3365 Jps
    2619 SecondaryNameNode
    2315 NameNode
    2988 NodeManager
    ```
    还可以通过 webui 界面来验证集群服务是否正常:
    - hdfs webui 界面: http://192.168.89.141:9870
    - yarn webui 界面: http://192.168.89.141:8088

### 1.2.2、集群部署安装

**环境**
- 系统：CentOS7.4
- Hadoop版本：3.2.0
- JDK版本：1.8.0_231
- 三台机器：
    - 192.168.89.141 hadoop001（主）
    - 192.168.89.142 hadoop002
    - 192.168.89.143 hadoop003
- 免密SSH登录，需要hadoop001能够免密登录hadoop002、hadoop003

**配置步骤**
- 解压缩 hadoop.3.2.tar.gz 到目录：`/data/soft/`
- 创建目录：`mkdir -p /data/hadoop_repo/logs/hadoop`
- 修改 `etc/hadoop-env.sh`配置，增加环境变量信息：
    ```
    export JAVA_HOME=/usr/java/jdk1.8.0_231-amd64
    export HADOOP_LOG_DIR=/data/hadoop_repo/logs/hadoop
    ```
- 修改 `etc/core-site.xml`，注意 `fs.defaultFS` 属性中的主机名需要和你配置的主机名保持一致：
    ```xml
    <configuration>
        <property>
            <name>fs.defaultFS</name>
            <value>hdfs://hadoop001:9000</value>
        </property>
        <property>
            <name>hadoop.tmp.dir</name>
            <value>/data/hadoop_repo</value>
        </property>
    </configuration>
    ```
- 修改 `etc/hdfs-site.xml`，把 hdfs 中文件副本的数量设置为 2，小于集群的节点数
    ```xml
    <configuration>
        <property>
            <name>dfs.replication</name>
            <value>2</value>
        </property>
        <property>
            <name>dfs.namenode.secondary.http-address</name>
            <value>hadoop001:50090</value>
        </property>
    </configuration>
    ```    
- 修改 `etc/mapred-site.xml`，设置 mapreduce 使用的资源调度框架
    ```xml
    <configuration>
        <property>
            <name>mapreduce.framework.name</name>
            <value>yarn</value>
        </property>
    </configuration>
    ```
- 修改 `etc/yarn-site.xml`，设置 yarn 上支持运行的服务和环境变量白名单，`yarn.resourcemanager.hostname` 配置主节点
    ```xml
    <configuration>
        <property>
            <name>yarn.nodemanager.aux-services</name>
            <value>mapreduce_shuffle</value>
        </property>
        <property>
            <name>yarn.nodemanager.env-whitelist</name>
            <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CL ASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
        </property>
        <property>
            <name>yarn.resourcemanager.hostname</name>
            <value>hadoop001</value>
        </property>
    </configuration>
    ```
- 修改 `etc/workers` 文件，增加所有从节点的主机名，一个一行
    ```
    hadoop002
    hadoop003
    ```
- 修改脚本：`sbin/start-dfs.sh, sbin/stop-dfs.sh`，增加如下内容：
    ```
    HDFS_DATANODE_USER=root
    HDFS_DATANODE_SECURE_USER=hdfs
    HDFS_NAMENODE_USER=root
    HDFS_SECONDARYNAMENODE_USER=root
    ```
- 修改脚本：`sbin/start-yarn.sh, sbin/stop-yarn.sh`，增加如下内容：
    ```
    YARN_RESOURCEMANAGER_USER=root
    HADOOP_SECURE_DN_USER=yarn
    YARN_NODEMANAGER_USER=root
    ```
- 回到hadoop安装包的上级目录，把 `hadoop001` 节点上修改好配置的安装包拷贝到其他两个从节点：
    ```
    [root@hadoop100 soft]# scp -rq hadoop-3.2.0 hadoop002:/data/soft/ 
    [root@hadoop100 soft]# scp -rq hadoop-3.2.0 hadoop003:/data/soft/
    ```
- 在`hadoop001`节点上格式化 namenode：`bin/hdfs namenode -format`
- 启动集群，在 hadoop001 节点上执行下面命令：`sbin/start-all.sh`，启动和停止都只需要在 hadoop001 节点上操作
    ```
    [root@hadoop001 hadoop-3.2.0]# sbin/start-all.sh
    Starting namenodes on [hadoop001]
    Starting datanodes
    Starting secondary namenodes [hadoop001]
    Starting resourcemanager
    Starting nodemanagers
    ```
- 验证集群：分别在三台机器上执行jps命令：
    ```
    [root@hadoop001 hadoop-3.2.0]# jps
    10627 NameNode
    10900 SecondaryNameNode
    11480 Jps
    11147 ResourceManager

    [root@hadoop002 hadoop-3.2.0]# jps
    2066 DataNode
    2184 NodeManager
    2286 Jps

    [root@hadoop003 hadoop-3.2.0]# jps
    2113 Jps
    1890 DataNode
    2008 NodeManager
    ```

# 2、HBase环境搭建

## 2.1、版本选择

选择合适的HBase版本，主要版本类型：
- 官网版本：http://archive.apache.org/dist/hbase/
- CDH版本：http://archive.cloudera.com/cdh5/cdh/5/

## 2.2、前提条件

- JDK1.7以上
- Hadoop-2.5.0以上
- zookeeper-3.4.5以上

## 2.3、Hadoop2.x分布式安装配置

[Hadoop环境](#1.1Hadoop2.x环境)

## 2.4、配置zookeeper集群

hbase 依赖zookeeper，一般不使用hbase内置的zookeeper

[配置zookeeper集群](../Java/Java架构/分布式.md#71集群环境)

## 2.5、配置hbase

- 解压文件
- 修改`conf/hbase-env.sh`配置文件
    - 配置JDK目录：JAVA_HOME=${JAVA_HOME}
    - 配置不使用默认的zookeeper： HBASE_MANAGES_ZK=false
- 配置`conf/hbase-site.xml`文件
    ```xml
    <configuration>
        <property>
            <name>hbase.tmp.dir</name>
            <value>/opt/modules/hbase-0.98.6-cdh5.3.0/data/tmp</value>
        </property>
        <property>
            <name>hbase.rootdir</name>
            <value>hdfs://bigdata1:9000/hbase</value>
        </property>
        <property>
            <name>hbase.cluster.distributed</name>
            <value>true</value>
        </property>
        <property>
            <name>hbase.zookeeper.quorum</name>
            <value>zookeeper-node-1,zookeeper-node-2,zookeeper-node-3</value>
        </property>
    </configuration>
    ```
- 配置 `conf/regionservers`文件：一般是使用主机名
- 启动hbase：`bin/start-hbase.sh`