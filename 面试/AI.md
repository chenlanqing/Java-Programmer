# 一、LLM

## 1、大模型岗位能力要求

### 1.1、产品经理

- 大模型基础知识了解：什么是大模型 / 基本概念如训练 微调 学习等 -->方便和工程师沟通
- 大模型能力的边界了解: 有哪些能力 / 可以做什么 / 有什么缺点 --> 方便结合公司业务找到切入点
- 大模型基本使用（prompt）： 更体会大模型的能力和测试
- 业务数据从哪里来？：评估功能是否有数据来支持实现以及最终验收评估


### 1.2、大模型应用开发工程师

- 大模型基础知识：大模型技术架构（transfromer,embedding）/ 哪些可用的大模型
- 如何调用大模型: gpu知识 / 复杂prompt技术 / python / pytorch / transformers
- 大模型能力评估：是否需要进行微调
- 大模型应用开发中间件: langchain / llamaindex / rag / agent / embedding / 向量数据库等
- 大模型技术选型: 根据业务选择什么大模型 / 中间件选型
- 大模型AI应用开发流程: 开发 / 迭代 / 评估
- 功能容错能力分析：是否允许出现错误 / 如何后处理

### 1.3、大模型推理部署工程师

- 推理框架： vLLM、Tensorrt-LLM、DeepSpeed 和Text Generation Inference
- 掌握推理优化技术：模型压缩/量化技术、解码方法、底层优化与分布式并行推理
- GPU优化知识： cuda / 并行计算优化 / 访存优化 / 低比特计算
- 主流大模型架构: 包含哪些算子 / 各部分耗时分析和优化
- 模型推理性能测试：并发性能，资源利用率，吞吐

### 1.4、大模型算法工程师

- 推理熟悉大模型的训练和微调全过程：数据准备，清理，预训练、指令微调、强化学习，分布式训练，训练策略，模型评测
- 参数高效模型训练技术：LoRA / Prompt Tuning / Prefix Tuning / P-Tuning
- 大模型训练框架：Pytorch、Tensorflow、 Megatron、Deepspeed
- 负责跟踪、探索业界前沿的大模型训练及优化方案
- 大模型评测

## 2、怎么在AI项目中引入deepsearch功能

# 二、RAG


# 三、MCP

# 四、Agent

多智能体协作

## 1、在多智能体系统中，如何解决智能体间的冲突和竞争？

标准答案：
- 优先级队列机制
- 共识算法（如PBFT）
- 资源锁定策略
- 仲裁者模式

## 2、如何量化评估智能体系统的性能？

评估维度：
- 响应时间（RT）
- 准确率（Accuracy）
- 用户满意度（CSAT）
- 系统稳定性（SLA）

加分回答：建立A/B测试框架，实时监控关键指标，定期优化模型参数

## 3、如何设计智能体的状态持久化方案？

- Redis缓存策略
- 数据库事务管理
- 状态快照机制
- 故障恢复策略

# AI设计

## 1、什么是 AI-Native 应用（AI原生应用）？如何设计一个 AI原生应用？

