
 参考文章
 * http://www.cnblogs.com/dolphin0520/p/3920373.html
 * [深入理解Java内存模型](http://www.infoq.com/cn/articles/java-memory-model-1)
 * http://ifeve.com/jmm-faq/
 
JMM 在实现上的一个特点:首先确保正确性,然后再去追求执行效率
零.线程安全性

# 二.Java 内存模型基础:	
	* http://www.infoq.com/cn/articles/java-memory-model-1
## 1.并发编程模型分类:
	在并发编程中,需要处理两个关键问题:线程之间如何通信及线程之间如何同步
	1.1.通信:是指线程之间以何种机制来交换信息.在命令式编程中,线程之间的通信机制有两种:共享内存和消息传递
		(1).在共享内存的并发模型里，线程之间共享程序的公共状态，线程之间通过写-读内存中的公共状态来隐式进行通信。
		(2).在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过明确的发送消息来显式进行通信;
	1.2.同步:是指程序用于控制不同线程之间操作发生相对顺序的机制
		(1).在共享内存并发模型里,同步是显式进行的,必须显式指定某个方法或某段代码需要在线程之间互斥执行;
		(2).在消息传递的并发模型里,由于消息的发送必须在消息的接收之前,因此同步是隐式进行的;
## 2.Java 并发编程模型:
	的并发采用的是共享内存模型,Java 线程之间的通信总是隐式进行,整个通信过程对程序员完全透明
## 3.Java 内存模型的抽象
	3.1.所有实例域、静态域和数组元素存储在堆内存中,堆内存在线程之间共享;
	3.2.局部变量(Local variables)，方法定义参数(java语言规范称之为formal method parameters)和
		异常处理器参数(exception handler parameters)不会在线程之间共享，它们不会有内存可见性问题，也不受内存模型的影响
	3.3.Java 线程之间的通信由 Java 内存模型(本文简称为JMM)控制,JMM 决定一个线程对共享变量的写入何时对另一个线程可见
		(1).从抽象的角度来看,JMM 定义了线程和主内存之间的抽象关系:线程之间的共享变量存储在主内存(main memory)中,
			每个线程都有一个私有的本地内存(local memory)，本地内存中存储了该线程以读/写共享变量的副本。
			本地内存是JMM的一个抽象概念，并不真实存在
	3.4.线程A与线程B之间如要通信的话，必须要经历下面2个步骤:
		首先，线程A把本地内存A中更新过的共享变量刷新到主内存中去。
		然后，线程B到主内存中去读取线程A之前已更新过的共享变量。
## 4.指令重排序:
	4.1.在执行程序时为了提高性能,编译器和处理器常常会对指令做重排序.重排序分三种类型:
		(1).编译器优化的重排序:编译器在不改变单线程程序语义的前提下,可以重新安排语句的执行顺序
		(2).指令级并行的重排序:现代处理器采用了指令级并行技术(Instruction-Level Parallelism,ILP)来将多条指令重叠执行。
			如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序
		(3).内存系统的重排序:由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行
	4.2.从 Java 源代码到最终实际执行的指令序列，会分别经历下面三种重排序
		源代码-->1:编译器优化的重排序-->2:指令级并行的重排序-->3:内存系统的重排序-->最终执行的指令序列
		(1).上述 1 属于编译器重排序,2和3属于处理器重排序,这些重排序都可能会导致多线程程序出现内存可见性问题
		(2).对于编译器重排序，JMM 的编译器重排序规则会禁止特定类型的编译器重排序(不是所有的编译器重排序都要禁止);
		(3).对于处理器重排序，JMM 的处理器重排序规则会要求java编译器在生成指令序列时，插入特定类型的
			内存屏障(memory barriers，intel称之为memory fence)指令，通过内存屏障指令来禁止特定类型的处理器重排序
			(不是所有的处理器重排序都要禁止)
		(4).JMM 属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序
			和处理器重排序，为程序员提供一致的内存可见性保证
	4.3.处理器重排序与内存屏障指令(Memory Barrier)
		(1).写缓冲区可以保证指令流水线持续运行，它可以避免由于处理器停顿下来等待向内存写入数据而产生的延迟
			每个处理器上的写缓冲区，仅仅对它所在的处理器可见
			==> 处理器对内存的读/写操作的执行顺序，不一定与内存实际发生的读/写操作顺序一致！
				由于写缓冲区仅对自己的处理器可见，它会导致处理器执行内存操作的顺序可能会与内存实际的操作执行顺序不一致
		(2).常见的处理器都允许 Store-Load重排序；常见的处理器都不允许对存在数据依赖的操作做重排序。sparc-TSO 和x86拥有相
			对较强的处理器内存模型，它们仅允许对写-读操作做重排序(因为它们都使用了写缓冲区)
	4.4.JMM 内存屏障:是一种屏障指令,它使CPU或编译器对屏障指令之前和之后发出的内存操作执行一个排序约束
		(1).LoadLoad Barriers
			抽象示例:Load1; LoadLoad; Load2 
			描述:在Load2要读取的数据被访问前,保证Load1要读取的数据被读取完毕
		(2).StoreStore Barriers
			抽象示例:Store1; StoreStore; Store2 
			描述: 在Store2写入执行前,确保Store1数据对其他处理器可见(刷新到内存)
		(3).LoadStore Barriers 
			抽象示例:Load1; LoadStore; Store2 	
			描述:在Store2被写入前,保证Load1要读取的数据被读取完毕
		(4).StoreLoad Barriers
			抽象示例:Store1; StoreLoad; Load2  
			描述:在Load2读取操作执行前,保证Store1的写入对所有处理器可见.
			StoreLoad Barriers 会使该屏障之前的所有内存访问指令(存储和装载指令)完成之后.才执行该屏障之后的内存访问指令
			StoreLoad Barriers 是一个“全能型”的屏障，它同时具有其他三个屏障的效果,它同时具有其他三个屏障的效果,同时也是开销最大的屏障
## 5.happens-before:先行发生
	5.1.从JDK5开始，java使用新的 JSR -133内存模型,JSR-133提出了"happens-before"的概念,通过这个概念来阐述操作之间的内存可见性
		如果一个操作执行的结果需要对另一个操作可见,那么这两个操作之间必须存在happens-before关系
		这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间
		注意:两个操作之间具有happens-before关系,并不意味着前一个操作必须要在后一个操作之前执行！happens-before仅仅
			要求前一个操作(执行的结果)对后一个操作可见,且前一个操作按顺序排在第二个操作之前(the first is visible
			to and ordered before the second)
	5.2.happens-before规则:
		(1).程序顺序规则:一个线程中的每个操作,happens-before 于该线程中的任意后续操作
		(2).监视器锁规则:对一个监视器锁的解锁,happens-before 于随后对这个监视器锁的加锁
		(3).volatile变量规则:对一个volatile域的写，happens-before 于任意后续对这个volatile域的读
		(4).传递性:如果A happens-before B,且 B happens-before C,那么 A happens-before C
		(5).线程启动规则:Thread 对象的 start 方法 happens-before 于此线程的每一个动作;
		(6).线程终止规则:线程中的所有操作都先行发生于此线程的终止检测,可以通过 Thread.join() 方法结束,
			Thread.isAlive()的返回值等手段检测到已终止执行;
		(7).线程中断规则:对线程的 interrupt 方法的调用先行发生于被中断线程的代码检测到中断事件的发生
		(8).对象终结规则:一个对象的初始化完成先行发生于它的 finalize() 方法的开始
	5.3.一个happens-before规则通常对应于多个编译器重排序规则和处理器重排序规则

# 三.JMM-重排序:	
	* http://www.infoq.com/cn/articles/java-memory-model-2
## 1.数据依赖性:
	如果两个操作访问同一个变量,且这两个操作中有一个为写操作,此时这两个操作之间就存在数据依赖性
	1.1.数据依赖分为三种类型学:
		(1).写后读 	a = 1;b = a;	写一个变量之后，再读这个位置;
		(2).写后写	a = 1;a = 2;	写一个变量之后，再写这个变量;
		(3).读后写	a = b;b = 1;	读一个变量之后，再写这个变量;
		上述只要重排序两个操作的执行顺序，程序的执行结果将会被改变
	1.2.数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作,
		不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑
## 2.as-if-serial语义:
	不管怎么重排序(编译器和处理器为了提高并行度),(单线程)程序的执行结果不能被改变.
	(1).为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序
		如果操作之间不存在数据依赖关系，这些操作可能被编译器和处理器重排序
	(2).as-if-serial语义把单线程程序保护了起来，遵守as-if-serial语义的编译器，runtime 和处理器共同为编写
		单线程程序的程序员创建了一个幻觉：单线程程序是按程序的顺序来执行的
## 3.程序顺序规则:
	double pi  = 3.14;    //A
	double r   = 1.0;     //B
	double area = pi * r * r; //C
	根据happens-before的程序顺序规则，上面计算圆的面积的示例代码存在三个happens-before关系:
		A happens- before B;
		B happens- before C;
		A happens- before C; // 根据happens- before的传递性推导出来的
	(1).这里 A happens-before B,但实际执行时B却可以排在A之前执行(看上面的重排序后的执行顺序)
		如果A happens- before B，JMM 并不要求A一定要在B之前执行。JMM仅仅要求前一个操作(执行的结果)对后一个操作可见，
		且前一个操作按顺序排在第二个操作之前。这里操作A的执行结果不需要对操作B可见；而且重排序操作A和操作B后的执行结果，
		与操作A和操作B按happens-before顺序执行的结果一致.在这种情况下，JMM 会认为这种重排序并不非法,JMM 允许这种重排序
## 4.重排序对多线程的影响:
	(1).当代码中存在控制依赖性时，会影响指令序列执行的并行度。为此，编译器和处理器会采用猜测(Speculation)执行来克服控制
		相关性对并行度的影响。以处理器的猜测执行为例，执行线程B的处理器可以提前读取并计算a*a，
		然后把计算结果临时保存到一个名为重排序缓冲(reorder buffer ROB)的硬件缓存中
	(2).在单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果(这也是as-if-serial语义允许对存在控制依赖的操作做重
		排序的原因)；但在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果

# 四.JMM-顺序一致性
## 1.数据竞争与顺序一致性保证:
	1.1.当程序未正确同步时，就会存在数据竞争.java内存模型规范对数据竞争的定义如下:
		在一个线程中写一个变量,	在另一个线程读同一个变量, 而且写和读没有通过同步来排序;
		当代码中包含数据竞争时，程序的执行往往产生违反直觉的结果
	1.2.JMM 对正确同步的多线程程序的内存一致性做了如下保证
		如果程序是正确同步的，程序的执行将具有顺序一致性(sequentially consistent)--即程序的执行结果与该程序在
		顺序一致性内存模型中的执行结果相同
##2.顺序一致性内存模型:
	顺序一致性内存模型是一个理论参考模型，JMM和处理器内存模型在设计时通常会把顺序一致性内存模型作为参照
	2.1.两大特征:
		(1).一个线程中的所有操作必须按照程序的顺序来执行
		(2).(不管程序是否同步)所有线程都只能看到一个单一的操作执行顺序;
			在顺序一致性内存模型中，每个操作都必须原子执行且立刻对所有线程可见
	2.2.顺序一致性模型有一个单一的全局内存，这个内存通过一个左右摆动的开关可以连接到任意一个线程。
		同时，每一个线程必须按程序的顺序来执行内存读/写操作;
## 3.同步程序的顺序一致性效果:
	在顺序一致性模型中，所有操作完全按程序的顺序串行执行。而在JMM中，临界区内的代码可以重排序(但 JMM 不允许临界区内的
	代码“逸出”到临界区之外，那样会破坏监视器的语义)。JMM 会在退出监视器和进入监视器这两个关键时间点做一些特别处理，
	使得线程在这两个时间点具有与顺序一致性模型相同的内存视图(具体细节后文会说明)
## 4.未同步程序的执行特性:
	(1).对于未同步或未正确同步的多线程程序，JMM 只提供最小安全性:线程执行时读取到的值，要么是之前某个线程写入的值,
		要么是默认值(0，null，false)，JMM 保证线程读操作读取到的值不会无中生有的冒出来;
	(2).JMM 不保证未同步程序的执行结果与该程序在顺序一致性模型中的执行结果一致:
		因为未同步程序在顺序一致性模型中执行时，整体上是无序的，其执行结果无法预知。
		保证未同步程序在两个模型中的执行结果一致毫无意义
	(3).未同步程序在这两个模型中的执行特性有下面几个差异:
		①.顺序一致性模型保证单线程内的操作会按程序的顺序执行,而 JMM 不保证单线程内的操作会按程序的顺序执行
		②.顺序一致性模型保证所有线程只能看到一致的操作执行顺序,而 JMM 不保证所有线程能看到一致的操作执行顺序
	(4).JMM 不保证对64位的 long 型和 double 型变量的读/写操作具有原子性,而顺序一致性模型保证对所有的内存读/写操作都具有原子性

# 五.volatile 的特性:
	* http://www.cnblogs.com/dolphin0520/p/3920373.html
#1.把对volatile变量的单个读/写,看成是使用同一个监视器锁对这些单个读/写操作做了同步
	示例代码:
		class VolatileFeaturesExample {
		    volatile long vl = 0L;  //使用volatile声明64位的long型变量
		    public void set(long l) {
		        vl = l;   //单个volatile变量的写
		    }
		    public void getAndIncrement () {
		        vl++;    //复合(多个)volatile变量的读/写
		    }
		    public long get() {
		        return vl;   //单个volatile变量的读
		    }
		}
	假设有多个线程分别调用上面程序的三个方法,这个程序在语意上和下面程序等价:
		class VolatileFeaturesExample {
		    long vl = 0L;               // 64位的long型普通变量
		    public synchronized void set(long l) {     //对单个的普通 变量的写用同一个监视器同步
		        vl = l;
		    }
		    public void getAndIncrement () { //普通方法调用
		        long temp = get();           //调用已同步的读方法
		        temp += 1L;                  //普通写操作
		        set(temp);                   //调用已同步的写方法
		    }
		    public synchronized long get() { 
		    	//对单个的普通变量的读用同一个监视器同步
		        return vl;
		    }
		}
	(1).如上面示例程序所示,对一个volatile变量的单个读/写操作,与对一个普通变量的读/写操作使用同一个监视器锁来同步,
		它们之间的执行效果相同:
		volatile写和监视器的释放有相同的内存语义;volatile读与监视器的获取有相同的内存语义
	(2).监视器锁的happens-before规则保证释放监视器和获取监视器的两个线程之间的内存可见性,这意味着对一个volatile变量的读,
		总是能看到(任意线程)对这个volatile变量最后的写入;
	(3).监视器锁的语义决定了临界区代码的执行具有原子性.这意味着即使是64位的 long 型和 double 型变量，只要它是volatile变量，
		对该变量的读写就将具有原子性。如果是多个volatile操作或类似于volatile++这种复合操作，这些操作整体上不具有原子性
## 2.volatile写-读建立的happens before关系:从JSR-133开始，volatile变量的写-读可以实现线程之间的通信
	2.1.volatile写-读的内存语义:
		(1).volatile写的内存语义:当写一个volatile变量时,JMM 会把该线程对应的本地内存中的共享变量刷新到主内存;
		(2).volatile读的内存语义:当读一个volatile变量时,JMM 会把该线程对应的本地内存置为无效.线程接下来将从主内存中读取共享变量;
		线程A写一个volatile变量,实质上是线程A向接下来将要读这个volatile变量的某个线程发出了(其对共享变量所在修改的)消息。
		线程B读一个volatile变量,实质上是线程B接收了之前某个线程发出的(在写这个volatile变量之前对共享变量所做修改的)消息。
		线程A写一个volatile变量,随后线程B读这个volatile变量，这个过程实质上是线程A通过主内存向线程B发送消息。
	2.3.volatile 关键字用于表示可以被多个线程异步修改的成员变量,强制从公共堆栈中取得变量的值,不是从私有线程获取
		volatile 关键字在许多 Java 虚拟机中都没有实现.
		volatile 的目标用途是为了确保所有线程所看到的指定变量的值都是相同的;
		Java 语言中的 volatile 变量可以被看作是一种 “程度较轻的 synchronized”:与 synchronized 块相比,
		volatile 变量所需的编码较少,并且运行时开销也较少,但是它所能实现的功能也仅是 synchronized 的一部分
		缓存一致性问题:	
	2.3.volatile关键字的两层语义:一旦一个共享变量(类的成员变量、类的静态成员变量)被volatile修饰之后,那么就具备了两层语义:		
		(1).保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的;
		(2).禁止进行指令重排序
			//线程1
			boolean stop = false;
			while(!stop){
			    doSomething();
			}			 
			//线程2
			stop = true;
			如果要线程1和线程2正确执行,用volatile修饰 stop 变量:
			第一：使用volatile关键字会强制将修改的值立即写入主存；
			第二：使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量stop的缓存行无效
			(反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效)；
			第三：由于线程1的工作内存中缓存变量stop的缓存行无效，所以线程1再次读取变量stop的值时会去主存读取。
		3.2.1.可见性:当一个共享变量被volatile修饰时,它会保证修改的值会立即被更新到主存,
			当有其他线程需要读取时,它会去内存中读取新值;
			另外:通过 synchronized 和 Lock 也能够保证可见性，synchronized 和Lock 能保证同一时刻只有一个线程获取锁然
			后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性
			==>解决异步死循环:
				JVM 在设置 -server 时出现死循环:一个变量存在与公共堆栈中和线程的私有堆栈中.JVM 被设置了-server
				是为了线程运行的效率,线程一直在私有堆栈中获取变量的值,而调用 set 方法时虽然被执行了,但是更新的
				却是公共堆栈中的变量值;
				造成这样的原因就是私有堆栈中的值和公共堆栈的值不同步造成的
			==> 为什么 volatile 有这样的特性? 因为 Java 的 happens-before(先行发生)
				对于一个volatile变量的写操作先行发生于后面对这个变量的读操作
				可见性:基于CPU的内存屏障指令,被JSR-133抽象为happens-before原则
	3.3.volatile保证原子性吗? volatile也无法保证对变量的任何操作都是原子性的
		(1).原子性:在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行
			x = 10;         //语句1
			y = x;         //语句2
			x++;           //语句3
			x = x + 1;     //语句4
			上述四句那些是原子操作?
			①.其实只有语句1是原子性操作，其他三个语句都不是原子性操作。
			②.语句1是直接将数值10赋值给x，也就是说线程执行这个语句的会直接将数值10写入到工作内存中
			③.语句2实际上包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 
				这2个操作都是原子性操作，但是合起来就不是原子性操作了。
			④.同样的，x++和 x = x+1包括3个操作：读取x的值，进行加1操作，写入新的值。
			所以上面4个语句只有语句1的操作具备原子性
		(2).自增操作不是原子性操作，而且volatile也无法保证对变量的任何操作都是原子性的
		在java 1.5的 java.util.concurrent.atomic 包下提供了一些原子操作类,即对基本数据类型的 自增(加1操作)，
		自减(减1操作)、以及加法操作(加一个数)，减法操作(减一个数)进行了封装，保证这些操作是原子性操作。
		atomic是利用 CAS 来实现原子性操作的(Compare And Swap)，CAS 实际上是利用处理器提供的 CMPXCHG 指令实现的，
		而处理器执行 CMPXCHG 指令是一个原子性操作
	3.4.volatile能保证有序性吗? volatile关键字能禁止指令重排序，所以volatile能在一定程度上保证有序性
		3.4.1.有序性:在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，
			却会影响到多线程并发执行的正确性
		3.4.2.volatile关键字禁止指令重排序有两层意思:
			(1).当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；
				在其后面的操作肯定还没有进行；
			(2).在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行
	3.5.volatile的原理和实现机制
		"观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现加入volatile关键字时,会多出一个lock前缀指令"
	　　lock前缀指令实际上相当于一个内存屏障(也成内存栅栏)内存屏障会提供3个功能：
	　　(1).它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；
			即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；
	　　(2).它会强制将对缓存的修改操作立即写入主存；
	　　(3).如果是写操作，它会导致其他CPU中对应的缓存行无效。
	3.6.使用volatile关键字的场景:
		通常来说，使用volatile必须具备以下2个条件
		(1).对变量的写操作不依赖于当前值,或者能够确保只有单一的线程修改变量的值
		(2).该变量没有包含在具有其他变量的不变式中;
		(3).在访问变量时不需要加锁.
		仅当 volatile 变量能简化代码的实现以及对同步策略的验证时,才应该使用.
		如果在验证正确性时需要对可见性进行复杂的判断,那么就不要使用 volatile 变量.
		volatile 变量的正确使用:
			确保它们自身状态的可见性,确保它们所引用对象的状态的可见性,以及标识一些重要的程序生命周期事件的发生;
		==> 无状态对象:
			就是没有实例变量的对象,不能保存数据,是不变类,线程安全的
## 4.volatile内存语义的实现:
	4.1.为了实现volatile内存语义，JMM 会分别限制编译器重排序和处理器重排序这两种类型的重排序类型
	4.2.JMM 针对编译器制定的volatile重排序规则表:
		(1).当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。
			这个规则确保volatile写之前的操作不会被编译器重排序到volatile写之后
		(2).当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。
			这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前
		(3).当第一个操作是volatile写，第二个操作是volatile读时，不能重排序
	4.3.为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序:
		下面是基于保守策略的 JMM 内存屏障插入策略
		(1).在每个volatile写操作的前面插入一个 StoreStore 屏障:
			保证在volatile写之前,其前面的所有普通写操作已经对任意处理器可见了
			因为 StoreStore 屏障将保障上面所有的普通写在volatile写之前刷新到主内存
		(2).在每个volatile写操作的后面插入一个 StoreLoad 屏障:
			避免volatile写与后面可能有的volatile读/写操作重排序
			因为编译器常常无法准确判断在一个volatile写的后面，是否需要插入一个 StoreLoad 屏障,为了保证能
			正确实现volatile的内存语义，JMM 在这里采取了保守策略:在每个volatile写的后面或在每个volatile读
			的前面插入一个 StoreLoad 屏障
		(3).在每个volatile读操作的后面插入一个 LoadLoad 屏障:
			用来禁止处理器把上面的volatile读与下面的普通读重排序
		(4).在每个volatile读操作的后面插入一个 LoadStore 屏障:
			用来禁止处理器把上面的volatile读与下面的普通写重排序
		==> 在实际执行时，只要不改变volatile写-读的内存语义，编译器可以根据具体情况省略不必要的屏障
	4.4.JSR-133为什么要增强volatile的内存语义
		严格限制编译器和处理器对volatile变量与普通变量的重排序,确保volatile的写-读和监视器的释放-获取一样,具有相同的内存语义
	4.5.由于volatile仅仅保证对单个volatile变量的读/写具有原子性，而监视器锁的互斥执行的特性可以确保
		对整个临界区代码的执行具有原子性。
		在功能上，监视器锁比volatile更强大；在可伸缩性和执行性能上,volatile更有优势
## 5.volatile 和 synchronized 的区别:
	(1).volatile 不会进行加锁操作
		volatile变量是一种稍弱的同步机制在访问volatile变量时不会执行加锁机制,因此也就不会使执行线程阻塞,
		因此volatile变量是一种比 synchronized 关键字更轻量级的同步机制;
	(2).volatile 本质是在告诉JVM当前变量在寄存器中的值是不确定的,需要从主存中读取;synchronized 则是锁定当前变量,
		只是当前线程可以访问该变量,其他线程被阻塞; JDK1.6之后对 synchronized 进行了优化
	(3).volatile 只能使用在变量上,synchronized 则可以使用在变量\方法\类级别上;
	(4).volatile 只能保证可见性,不能保证原子性;synchronized 可以保证原子性和可见性;
	(5).volatile 不会造成线程的阻塞;synchronized 可能会造成线程的阻塞;
	(6).volatile 标记的变量不会被编译器优化;synchronized 标记的变量可以被编译器优化
# 六.锁:
## 1.锁的释放-获取建立的happens before 关系
	(1).锁是java并发编程中最重要的同步机制.锁除了让临界区互斥执行外，还可以让释放锁的线程向获取同一个锁的线程发送消息
## 2.锁释放和获取的内存语义:
	(1).当线程释放锁时,JMM 会把该线程对应的本地内存中的共享变量刷新到主内存中
	(2).当线程获取锁时,JMM 会把该线程对应的本地内存置为无效.从而使得被监视器保护的临界区代码必须要从主内存中去读取共享变量
	(3).锁释放与volatile写有相同的内存语义；锁获取与volatile读有相同的内存语义
	(4).下面对锁释放和锁获取的内存语义做个总结：
		线程A释放一个锁，实质上是线程A向接下来将要获取这个锁的某个线程发出了(线程A对共享变量所做修改的)消息。
		线程B获取一个锁，实质上是线程B接收了之前某个线程发出的(在释放这个锁之前对共享变量所做修改的)消息。
		线程A释放锁，随后线程B获取这个锁，这个过程实质上是线程A通过主内存向线程B发送消息
## 3.锁内存语义的实现:
	借助 ReentrantLock 的源代码，来分析锁内存语义的具体实现机制
	3.1.在 ReentrantLock 中，调用lock()方法获取锁；调用unlock()方法释放锁
		(1).ReentrantLock 的实现依赖于java同步器框架 AbstractQueuedSynchronizer(简称 AQS),
			AQS 使用一个整型的volatile变量命名为state来维护同步状态,这个volatile变量是ReentrantLock内存语义实现的关键
			AQS 的本质上是一个同步器/阻塞锁的基础框架，其作用主要是提供加锁、释放锁，
			并在内部维护一个FIFO等待队列，用于存储由于锁竞争而阻塞的线程
		(2).ReentrantLock 分为公平锁和非公平锁,我们首先分析公平锁
			①.使用公平锁时，加锁方法lock()的方法调用轨迹如下:
				ReentrantLock : lock()
				FairSync : lock()
				AbstractQueuedSynchronizer : acquire(int arg)
				FairSync : tryAcquire(int acquires) 真正开始加锁
					查看 tryAcquire 方法的实现,加锁方法首先读volatile变量state
			②.在使用公平锁时,解锁方法unlock()的方法调用轨迹如下:
				ReentrantLock : unlock()
				AbstractQueuedSynchronizer : release(int arg)
				Sync : tryRelease(int releases) 真正开始释放锁
					查看 tryRelease 方法的实现,在释放锁的最后写volatile变量state
			公平锁在释放锁的最后写volatile变量state;在获取锁时首先读这个volatile变量.根据volatile的happens-before规则,
			释放锁的线程在写volatile变量之前可见的共享变量,在获取锁的线程读取同一个volatile变量后将立即变的对获取锁的线程可见
		(3).非公平锁的内存语义的实现:非公平锁的释放和公平锁完全一样，所以这里仅仅分析非公平锁的获取
			使用非公平锁时，加锁方法lock()的方法调用轨迹如下:
				ReentrantLock : lock()
				NonfairSync : lock()
				AbstractQueuedSynchronizer : compareAndSetState(int expect, int update)
			该方法以原子操作的方式更新state变量,java的compareAndSet()方法调用简称为CAS.
			JDK 文档对该方法的说明如下:如果当前状态值等于预期值，则以原子方式将同步状态设置为给定的更新值。
			此操作具有 volatile 读和写的内存语义	
		(4).对公平锁和非公平锁的内存语义做个总结:
			①.公平锁和非公平锁释放时，最后都要写一个volatile变量state;
			②.公平锁获取时,首先会去读这个volatile变量;
			③.非公平锁获取时,首先会用compareAndSet()更新这个volatile变量,这个操作同时具有volatile读和volatile写的内存语义
	3.2.锁释放-获取的内存语义的实现至少有下面两种方式:
		(1).利用volatile变量的写-读所具有的内存语义
		(2).利用compareAndSet()所附带的volatile读和volatile写的内存语义
## 4.java.util.concurrent包的实现
	4.1.Java 线程之间的通信现在有了下面四种方式:
		(1).A线程 写volatile变量，随后 B线程 读这个volatile变量。
		(2).A线程 写volatile变量，随后 B线程 用compareAndSet()更新这个volatile变量。
		(3).A线程 用compareAndSet()更新一个volatile变量，随后 B线程 用 compareAndSet()更新这个volatile变量。
		(4).A线程 用compareAndSet()更新一个volatile变量，随后 B线程 读这个volatile变量
	4.2.concurrent包的源代码实现通用化的实现模式:
		(1).首先，声明共享变量为volatile；
		(2).然后，使用CAS的原子条件更新来实现线程之间的同步；
		(3).同时，配合以volatile的读/写和CAS所具有的volatile读和写的内存语义来实现线程之间的通信
	4.3.AbstractQueuedSynchronizer 非阻塞数据结构和原子变量类(java.util.concurrent.atomic包中的类),
		这些concurrent包中的基础类都是使用这种模式来实现的，而concurrent包中的高层类又是依赖于这些基础类来实现的
		(1).Lock 	同步器	阻塞队列	执行器		并发容器
		(2).AbstractQueuedSynchronizer 非阻塞数据结构 	原子变量类
		(3).volatile变量的读写	compareAndSet()
			(3)是底层实现,(2)是基于(3)来实现的,而(1)又是基于(2)来实现的

# 七.final:
    
	1.对于 final 域,编译器和处理器要遵守两个重排序规则:
		(1).在构造函数内对一个 final 域的写入,与随后把这个被构造对象的引用赋值给一个引用变量,这两个操作之间不能重排序
		(2).初次读一个包含 final 域的对象的引用,与随后初次读这个 final 域,这两个操作之间不能重排序
	2.写 final 域的重排序规则:禁止把 final 域的写重排序到构造函数之外
		2.1.这个规则的实现包含下面2个方面:
			(1).JMM 禁止编译器把 final 域的写重排序到构造函数之外。
			(2).编译器会在 final 域的写之后,构造函数 return 之前，插入一个 StoreStore 屏障。
				这个屏障禁止处理器把 final 域的写重排序到构造函数之外
		2.2.写 final 域的重排序规则可以确保:
			在对象引用为任意线程可见之前,对象的 final 域已经被正确初始化过了,而普通域不具有这个保障
	3.读 final 域的重排序规则:
		3.1.规则:在一个线程中,初次读对象引用与初次读该对象包含的 final 域,JMM 禁止处理器重排序这两个操作
			(注意:这个规则仅仅针对处理器)。编译器会在读 final 域操作的前面插入一个 LoadLoad 屏障
			初次读对象引用与初次读该对象包含的 final 域,这两个操作之间存在间接依赖关系
		3.2.读 final 域的重排序规则可以确保:
			在读一个对象的 final 域之前，一定会先读包含这个 final 域的对象的引用。在这个示例程序中，如果该引用不为 null，
			那么引用对象的 final 域一定已经被A线程初始化过了
	4.如果 final 域是引用类型:上述 final 域是针对基本数据类型,对于 final 域的引用类型有不同的效果:
		4.1.对于引用类型，写 final 域的重排序规则对编译器和处理器增加了如下约束:
			在构造函数内对一个 final 引用的对象的成员域的写入，与随后在构造函数外把这个被构造
			对象的引用赋值给一个引用变量，这两个操作之间不能重排序
		4.2.为什么 final 引用不能从构造函数内“逸出”:
			(1).写final域的重排序规则可以确保：在引用变量为任意线程可见之前，该引用变量指向的对象的final域已经在构造函数中被
			正确初始化过了。其实要得到这个效果，还需要一个保证：在构造函数内部，不能让这个被构造对象的引用为其他线程可见，
			也就是对象引用不能在构造函数中“逸出”
			(2).在构造函数返回前，被构造对象的引用不能为其他线程可见，因为此时的final域可能还没有被初始化。在构造函数返回后，
			任意线程都将保证能看到final域正确初始化之后的值
	5.final 语义在处理器中的实现:以 x86 处理器为例:
		由于x86处理器不会对写-写操作做重排序，所以在x86处理器中，写final域需要的StoreStore障屏会被省略掉。
		同样，由于x86处理器不会对存在间接依赖关系的操作做重排序，所以在x86处理器中，读final域需要的LoadLoad屏障也会被省略掉。
		也就是说在x86处理器中，final域的读/写不会插入任何内存屏障！

# 八.处理器内存模型:
	1.处理器的内存模型:
		(1).放松程序中写-读操作的顺序，由此产生了total store ordering内存模型(简称为TSO)。
		(2).在前面1的基础上，继续放松程序中写-写操作的顺序，由此产生了partial store order 内存模型(简称为PSO)。
		(3).在前面1和2的基础上，继续放松程序中读-写和读-读操作的顺序，由此产生了relaxed memory order内存模型(简称为RMO)
			和PowerPC内存模型
		注意:注意，这里处理器对读/写操作的放松，是以两个操作之间不存在数据依赖性为前提的(因为处理器要遵守as-if-serial语义,
		处理器不会对存在数据依赖性的两个内存操作做重排序)
		JMM屏蔽了不同处理器内存模型的差异，它在不同的处理器平台之上为java程序员呈现了一个一致的内存模型
	2.JMM，处理器内存模型与顺序一致性内存模型之间的关系
		JMM 是一个语言级的内存模型，处理器内存模型是硬件级的内存模型，顺序一致性内存模型是一个理论参考模型
	3.JMM把 happens- before要求禁止的重排序分为了下面两类:
			会改变程序执行结果的重排序。
			不会改变程序执行结果的重排序。
		JMM对这两种不同性质的重排序，采取了不同的策略：
			对于会改变程序执行结果的重排序，JMM要求编译器和处理器必须禁止这种重排序。
			对于不会改变程序执行结果的重排序，JMM对编译器和处理器不作要求(JMM允许这种重排序)

	4.旧的内存模型存在的问题:
		(1).旧的存储模型在许多情况下，不允许JVM发生各种重排序行为
		(2).在旧的内存模型中，final 字段并没有同其他字段进行区别对待——这意味着同
			步是保证所有线程看到一个在构造方法中初始化的 final 字段的唯一方法
		(3).旧的内存模型允许volatile变量的写操作和非volaitle变量的读写操作一起进行重排序
