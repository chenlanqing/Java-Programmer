<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
**目录**

- [1、缓存](#1%E7%BC%93%E5%AD%98)
- [2、高并发环境下缓存场景问题](#2%E9%AB%98%E5%B9%B6%E5%8F%91%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%BC%93%E5%AD%98%E5%9C%BA%E6%99%AF%E9%97%AE%E9%A2%98)
  - [2.1、缓存一致性](#21%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7)
    - [2.2.1、产生原因](#221%E4%BA%A7%E7%94%9F%E5%8E%9F%E5%9B%A0)
  - [2.3、缓存穿透](#23%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F)
    - [2.3.1、什么是缓存穿透](#231%E4%BB%80%E4%B9%88%E6%98%AF%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F)
    - [2.3.2、缓存穿透造成后果](#232%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E9%80%A0%E6%88%90%E5%90%8E%E6%9E%9C)
    - [2.3.3、缓存穿透产生原因](#233%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E4%BA%A7%E7%94%9F%E5%8E%9F%E5%9B%A0)
    - [2.3.4、缓存穿透的解决方法](#234%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95)
  - [2.4、缓存雪崩](#24%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9)
    - [2.4.1、缓存雪崩](#241%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9)
    - [2.4.2、预防和解决缓存雪崩问题](#242%E9%A2%84%E9%98%B2%E5%92%8C%E8%A7%A3%E5%86%B3%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E9%97%AE%E9%A2%98)
  - [2.5、缓存降级](#25%E7%BC%93%E5%AD%98%E9%99%8D%E7%BA%A7)
- [3、缓存热点 key 重建优化](#3%E7%BC%93%E5%AD%98%E7%83%AD%E7%82%B9-key-%E9%87%8D%E5%BB%BA%E4%BC%98%E5%8C%96)
  - [3.1、缓存热点key问题](#31%E7%BC%93%E5%AD%98%E7%83%AD%E7%82%B9key%E9%97%AE%E9%A2%98)
  - [3.2、解决思路](#32%E8%A7%A3%E5%86%B3%E6%80%9D%E8%B7%AF)
  - [3.3、解决方案](#33%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88)
    - [3.3.1、使用互斥锁](#331%E4%BD%BF%E7%94%A8%E4%BA%92%E6%96%A5%E9%94%81)
    - [3.3.2、永远不过期](#332%E6%B0%B8%E8%BF%9C%E4%B8%8D%E8%BF%87%E6%9C%9F)
- [4.缓存最佳实践](#4%E7%BC%93%E5%AD%98%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5)
- [参考文章](#%E5%8F%82%E8%80%83%E6%96%87%E7%AB%A0)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

# 1、缓存

# 2、高并发环境下缓存场景问题

## 2.1、缓存一致性

- 更新数据库成功，更新缓存失败 -> 数据不一致
- 更新缓存成功，更是数据库失败 -> 数据不一致
- 更新数据库成功，淘汰缓存失败 -> 数据不一致
- 淘汰缓存成功，更新数据库失败 -> 查询缓存miss

### 2.1.1、缓存一般使用流程

![](image/缓存一般用法.png)

但是在更新缓存方面，对于更新完数据库，是更新缓存呢，还是删除缓存。又或者是先删除缓存，再更新数据库，其实没有一个确定的方案

### 2.1.1、缓存与数据库双写一致性问题

从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。这种方案下，我们可以对存入缓存的数据设置过期时间，所有的写操作以数据库为准，对缓存操作只是尽最大努力即可。也就是说如果数据库写成功，缓存更新失败，那么只要到达过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存；

缓存的三种更新策略：

- **1、先更新数据库，再更新缓存**

    这个方案存在比较大问题，原因：
    - 从线程安全角度看：同时有请求A和请求B进行更新操作，那么会出现：
        - （1）线程A更新了数据库；
        - （2）线程B更新了数据库；
        - （3）线程B更新了缓存
        - （4）线程A更新了缓存

        **这就出现请求A更新缓存应该比请求B更新缓存早才对，但是因为网络等原因，B却比A更早更新了缓存。这就导致了脏数据**
    - 从业务场景角度看：
        - （1）如果你是一个写数据库场景比较多，而读数据场景比较少的业务需求，采用这种方案就会导致，数据压根还没读到，缓存就被频繁的更新，浪费性能
        - （2）如果你写入数据库的值，并不是直接写入缓存的，而是要经过一系列复杂的计算再写入缓存。那么，每次写入数据库后，都再次计算写入缓存的值，无疑是浪费性能的

    显然，更新缓存在比较多的问题，删除缓存更为适合；

- **2、先删除缓存，再更新数据库**

    其会导致不一致的原因，同时有一个请求A进行更新操作，另一个请求B进行查询操作：
    - （1）请求A进行写操作，删除缓存；
    - （2）请求B查询发现缓存不存在
    - （3）请求B去数据库查询得到旧值
    - （4）请求B将旧值写入缓存
    - （5）请求A将新值写入数据库

    上述情况就会导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据

    可以采用延时双删策略，伪代码如下：
    ```java
    public void write(String key, Object data) {
        redis.delKey(key);
        db.update(data);
        Thread.sleep(1000);
        redis.delKey(key);
    }
    ```
    先淘汰缓存、再写数据库(这两步和原来一样)、休眠1秒，再次淘汰缓存这么做，可以将1秒内所造成的缓存脏数据，再次删除；

    如果读写分离的架构，在这种情况下造成不一致的原因：一个请求A进行更新操作，另一个请求B进行查询操作
    - （1）请求A进行写操作，删除缓存；
    - （2）请求A将数据写入数据库了；
    - （3）请求B查询缓存发现，缓存没有值；
    - （4）请求B去从库查询，这时，还没有完成主从同步，因此查询到的是旧值；
    - （5）请求B将旧值写入缓存；
    - （6）数据库完成主从同步，从库变为新值上述情形，就是数据不一致的原因；

    延时双删策略会存在第二次删除缓存失败，会再次数显缓存和数据库不一致的情况

- **3、先更新数据库，再删除缓存**
    
    最经典的缓存+数据库读写的模式：Cache Aside Pattern
    - 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。
    - 更新的时候，先更新数据库，然后再删除缓存。

    这种情况下也可能会发生并发问题，假设这会有两个请求，一个请求A做查询操作，一个请求B做更新操作，那么会有如下情形产生：
    - （1）缓存刚好失效
    - （2）请求A查询数据库，得一个旧值
    - （3）请求B将新值写入数据库
    - （4）请求B删除缓存
    - （5）请求A将查到的旧值写入缓存

    如果发生上述情况，确实是会发生脏数据；但是这种情况发生的概率很小，发生上述情况存在一个先天条件：就是`步骤（3）`的写数据库操作比`步骤（2）`的读操作耗时更短，才有可能使得步骤`步骤（4）`先于`步骤（5）`发生。但实际上数据库的读操作的速度远远快于写操作。

    还会存在缓存删除失败的情况：
    - 请求A更新了数据A；
    - 请求A删除数据A的缓存失败；
    - 请求B读到的数据A缓存的旧数据；

    解决方案：
    - 设置缓存过期时间：
        - 优点：简单、易操作；
        - 缺点：会存在短时间的旧数据；如果数据量太多，缓存有效时间短，容易发生一段时间内缓存大量失效，此时的数据库压力突然剧增，引发缓存雪崩现象（缓存有效时间为随机值减少发生缓存雪崩的可能性）
    - 消息队列步骤：
        - 更新数据库；
        - 删除缓存失败；
        - 将需要删除的Key发送到消息队列；
        - 隔断时间从消息队列中拉取要删除的key；
        - 继续删除，直至成功为止

        优点：不会引发缓存雪崩、只删除需要删除的缓存；

        缺点：引入了消息队列

## 2.2、缓存并发

### 2.2.1、产生原因

如果网站并发访问高，一个缓存如果失效，可能出现多个进程同时查询DB，同时设置缓存的情况，如果并发确实很大，这也可能造成DB压力过大，还有缓存频繁更新的问题；

## 2.3、缓存穿透

### 2.3.1、什么是缓存穿透

缓存穿透是指缓存没有发挥作用，业务系统虽然去缓存中查询数据，但缓存中没有数据，业务系统需要再次去存储系统查询数据；通常存在两种情况：
- 查询一个的数据确实不存在，缓存层和存储层都不会命中；
- 存储系统中存在数据，但缓存数据生成需要耗费大量的时间和资源，如果刚好在业务访问的时候缓存失效了，出现缓存未生效的情况；

但是出于容错的考虑，如果从存储层查不到数据则不写入缓存层，整个过程分为如下 3 步：
- 缓存层不命中
- 存储层不命中，所以不将空结果写回缓存
- 返回空结果

### 2.3.2、缓存穿透造成后果

可能会使后端存储负载加大，由于很多后端存储不具备高并发性，甚至可能造成后端存储宕掉；可能在程序中分别统计总调用数，缓存层命中数，存储层命中数，如果发现大量存储空命中，可能出现了缓存穿透现象.

### 2.3.3、缓存穿透产生原因

- 业务自身代码或者数据出现问题
- 一些恶意攻击、爬虫等造成大量空命中

### 2.3.4、缓存穿透的解决方法

- 缓存空对象：当下列第二步存储层不命中后，仍然将空对象保留到缓存层中，之后再访问这个数据时将会从缓存中获取，保护后端数据源

    ![image](image/缓存穿透-空对象.png)

    缓存空对象存在两个问题:
    * 空值做了缓存，意味着缓存层中存了更多的键，需要更多的内存空间。比较有效的方法是针对这类数据设置一个较短的过期时间，让其自动剔除；或者可以将空值放在其他的缓存空间，否则当空间不足时，缓存系统的LRU算法可能会先剔除正常值，再剔除空值。
    * 缓存层和存储层的数据会有一段时间窗口的不一致，可能会对业务有一定的影响。可以利用消息系统或者其他方式清除掉缓存层中的空对象。

    缓存空对象伪代码：
    ```java
    String get(String key){
        // 从缓存中获取数据
        String cacheValue = cache.get(key);
        if(StringUtils.isBlank(cacheValue)){
            // 从存储中获取数据
            String storageValue = storage.get(key);
            cache.set(key， storageValue);
            // 如果存储数据为空，需要设置一个过期时间
            if(storageValue == null){
                cache.expire(key， 60*5);
            }
            return storageValue;
        } else {
            // 缓存非空
            return cacheValue;
        }
    }
    ```
- 布隆过滤器拦截：如图所示，在访问缓存层很存储层之前，将存在的key 用布隆过滤器提前保存起来，做第一层拦截.

    ![image](image/缓存穿透-布隆过滤器.png)

    这种方法适用于数据命中不高，数据相对固定实时性低(通常是数据集较大)的应用场景，代码维护较为复杂，但是缓存空间占用少；

- 两中解决方案对比:

|解决缓存穿透|适用场景|维护成本|
|----------|-------|------|
|缓存空对象|数据命中不高; 数据频繁变化实时性高|代码维护简单; 需要过多的缓存空间; 数据不一致|
|布隆过滤器|数据命中不高; 数据相对固定实时性低|代码维护复杂; 缓存空间占用少|

### 2.3.5、缓存击穿

在平常高并发的系统中，大量的请求同时查询一个 key 时，此时这个key正好失效了，就会导致大量的请求都打到数据库上面去。这种现象我们称为缓存击穿；

存在问题：会造成某一时刻数据库请求量过大，压力剧增；

多个线程同时去查询数据库的这条数据，那么我们可以在第一个查询数据的请求上使用一个 互斥锁来锁住它

## 2.4、缓存雪崩

### 2.4.1、缓存雪崩

由于缓存承载着大量请求，有效的保护了存储层，但是如果缓存层由于某些原因整体不能提供服务或者在重新生成缓存，于是所有的请求都会到达存储层，存储层的调用量会暴增，造成存储层宕机问题。

### 2.4.2、预防缓存雪崩问题

可以从如下三个方面着手
- 保证缓存层服务高可用性： 缓存层设计成高可用的，即使个别节点，个别机器，甚至机房宕机，依然可以提供服务.
- 依赖隔离组件为后端限流并降级：无论是缓存层还是存储层都会有出错的概率，可以将他们视同为资源。在实际项目中，我们需要对重要的资源(Redis，mysql)都进行隔离，让每种资源都单独运行在自己的线程池中
    * Hystrix 是解决依赖的利器，限流、降级等
- 提前演练：在项目上线前，演练缓存层宕机后，应用以及后端的负载情况以及可能出现的问题，在此基础上 做一些预案.

### 2.4.3、解决缓存雪崩

更新锁机制和后台更新机制
- 更新锁：对缓存更新进行加锁保护，保证只有一个线程能够更新缓存，未能获取更新锁的线程要么等待锁释放后重新读取缓存，要么返回空值或默认值；
- 后台更新：后台定时去更新，而不是由业务线程来更新；
- 发生缓存雪崩后，利用redis持久化机制，尽快回复缓存集群，一旦重启，自动从磁盘上加载数恢复内存中的数据；
- 双key策略：要缓存的key过期时间是t，key1没有过期时间。每次缓存读取不到key时就返回key1的内容，然后触发一个事件。这个事件会同时更新key和key1。

## 2.5、缓存降级

# 3、缓存热点 key 重建优化

## 3.1、缓存热点key问题

通常使用 "缓存 + 过期时间"的策略来帮助加速接口的访问速度，减少了后端负载，同时保证数据的更新。但是如果同时出现两个问题，会对系统造成致命的危害：

- 当前key是一个热点key(例如热门的娱乐新闻)，并发量非常大;
- 缓存的构建\重建不能在短时间内完成，可能是一个复杂的计算，例如复杂的sql，多次IO，多个依赖等。于是就出现问题:在缓存失效的瞬间，需要大量线程来构建缓存，造成后端负载过大，甚至导致系统崩溃。
- 瞬间有几十万的请求去访问redis上某个固定的key，从而压垮缓存服务的情情况

发现热点key：
- 根据实际经验，预估哪些是热点key。但是并非所有业务都能预估热点key；
- 在客户端进行收集：这个方式就是在操作redis之前，加入一行代码进行数据统计。那么这个数据统计的方式有很多种，也可以是给外部的通讯系统发送一个通知信息。缺点就是对客户端代码造成入侵。
- 在Proxy层做收集：
- 用redis自带命令：
    - monitor命令，该命令可以实时抓取出redis服务器接收到的命令，然后写代码统计出热key是啥。当然，也有现成的分析工具可以给你使用，比如redis-faina。但是该命令在高并发的条件下，有内存增暴增的隐患，还会降低redis的性能。
    - hotkeys参数，redis 4.0.3提供了redis-cli的热点key发现功能，执行redis-cli时加上–hotkeys选项即可。但是该参数在执行的时候，如果key比较多，执行起来比较慢；
- 抓包评估：Redis客户端使用TCP协议与服务端进行交互，通信协议采用的是RESP。自己写程序监听端口，按照RESP协议规则解析数据，进行分析。缺点就是开发成本高，维护困难，有丢包可能性

## 3.2、解决思路

- 减少缓存重建的次数；
- 数据尽可能一致；
- 减少的潜在的危险；

## 3.3、解决方案

### 3.3.1、使用互斥锁

- 思路:只让一个线程构建缓存，其他线程等待构建缓存的线程执行完毕，重新从缓存获取数据即可。如果单机环境，可以synchronized 或者lock来操作，如果是分布式环境可以用分布式锁

```java
String get(String key) {  
   String value = redis.get(key);  
   if (value  == null) {  
    if (redis.setnx(key_mutex， "1")) {  
        // 3 min timeout to avoid mutex holder crash  
        redis.expire(key_mutex， 3 * 60)  
        value = db.get(key);  
        redis.set(key， value);  
        redis.delete(key_mutex);  
    } else {  
        //其他线程休息50毫秒后重试  
        Thread.sleep(50);  
        get(key);  
    }  
  }  
}
```
- 优点：
    * 思路简单;
    * 保证一致性

- 缺点：
    * 代码复杂度增大;
    * 存在死锁风险;
    * 存在线程池阻塞的风险

### 3.3.2、永远不过期

- 永不过期包含两层意思：
    * 从缓存层面来看，确实没有设置过期时间，所以不会出现热点key过期后产生的问题，也就是物理不过期；
    * 从功能层面来看，为每个value设置一个逻辑过期时间，当发现超过逻辑过期时间后，会使用单独的线程去构建缓存；

- 实际来看，此方法杜绝了热点key产生的问题，但唯一不足的就是重构缓存期间，会出现数据不一致。

- 优点：基本杜绝热点key问题

- 缺点：
    * 不保证一致性
    * 逻辑过期时间增加代码维护成本和内存成本

### 3.3.3、使用二级缓存

使用本地缓存，比如HashMap、ehcache。在你发现热key以后，把热key加载到系统的JVM中。针对这种热key请求，会直接从jvm中取，而不会走到redis层

### 3.3.4、备份热key

不要让key走到同一台redis上不就行了

# 4、缓存最佳实践

- 缓存系统主要消耗的是服务器的内存，因此，在使用缓存时必须先对应用需要缓存的数据大小进行评估，包括缓存的数据结构、缓存大小、缓存数量、缓存的失效时间，然后根据业务情况自行推算未来一段时间容量的使用情况，根据容量评估的结果来申请和分配缓存资源，否则会造成资源浪费或者缓存空间不够；
- 将使用缓存的业务进行分离，核心业务和非核心业务使用不同的缓存实例，从物理上进行隔离，如果有条件，则请对么个业务使用单独的实例或者集群，以减少应用之间互相影响的可能性。
- 根据缓存实例提供的内存大小推送应用需要使用的缓存实例数量；
- 缓存一般是用来加速数据库的读材质的，一般先访问缓存后访问数据库，所以缓存的超时时间设置很重要。有可能缓存超时设置较长，从而拖垮服务的线程池，最终导致服务雪崩；
- 所有的缓存实例都需要添加监控，需要对慢查询，大对象，内存使用情况做可靠的监控；
- 如果多个业务共享一个缓存实例，需要通过规范来限制各个应用使用的key一定要有唯一的前缀，并进行隔离设计，避免缓存互相覆盖的问题产生；
- 任何缓存的ke都必须设定缓存失效时间，且失效时间不能集中在某一点，否则会导致缓存占满内存或者缓存穿透。
- 低频访问的数据不要放在缓存中；
- 缓存的数据不易过大，尤其是redis，因为redi使用的是单线程模型，单个缓存key的数据过大时，会阻塞其他请求处理；
- 对于存储较多value饿key，尽量不要使用HGETALL等集合操作，该操作会造成请求阻塞，影响其他应用的访问；
- 缓存一般用于交易系统中加速查询的场景，有大量的更新数据时，尤其是批量处理，请使用批量模式；
- 如果对性能要求不是非常高，尽量使用分布式缓存，不要使用本地缓存，因为本地缓存在服务的各个节点之间复制，在某一时刻副本之间的是不一致的；
- 写缓存时一定写入完全正确的数据，如果缓存数据一部分有效，一部分无效，则宁可放弃缓存，也不要把部分数据写入缓存，否则会造成空指针，程序异常等；
- 在通常情况下，读的顺序是先缓存、后数据库；写的顺序是先数据库、后缓存。
- 当使用本地缓存时，一定要严格控制缓存对象的个数和生命周期。由于JVM特性，过多的缓存对象会极大影响JVM性能，甚至导致内存溢出等问题出现。
- 在使用缓存时，一定有降级处理，尤其对关键业务环节，缓存有问题或者失效也要能回溯到数据库进行处理。

# 参考文章

* [高性能网站设计之缓存更新的套路](http://blog.csdn.net/tTU1EvLDeLFq5btqiK/article/details/78693323)
* [缓存穿透、雪崩](https://segmentfault.com/a/1190000008931971)
* [缓存穿透、缓存并发、热点缓存之最佳招式](http://blog.didispace.com/chengchao-huancun-zuijiazhaoshi/)
* [分布式缓存击穿](http://www.cnblogs.com/rjzheng/p/8908073.html)
* [缓存那些事](https://tech.meituan.com/cache_about.html)
* [AutoLoadCache:高效的缓存管理解决方案](https://github.com/qiujiayu/AutoLoadCache)
