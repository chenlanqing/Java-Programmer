
# 一、秒杀系统

## 1、一些概念

- 热点隔离：秒杀系统设计的第一个原则就是将这种热点数据隔离出来，不要让1%的请求影响到另外的99%，隔离出来后也更方便对这1%的请求做针对性优化；
- 业务隔离：把秒杀做成一种营销活动，卖家要参加秒杀这种营销活动需要单独报名，从技术上来说，卖家报名后对我们来说就是已知热点，当真正开始时我们可以提前做好预热；
- 系统隔离：系统隔离更多是运行时的隔离，可以通过分组部署的方式和另外99%分开。秒杀还申请了单独的域名，目的也是让请求落到不同的集群中；
- 数据隔离： 秒杀所调用的数据大部分都是热数据，比如会启用单独cache集群或MySQL数据库来放热点数据，目前也是不想0.01%的数据影响另外99.99%；

## 2、秒杀的两个问题

- 并发读：并发读的核心优化理念是尽量减少用户到服务端来读取数据，或者读更少的数据；
- 并发写：要求在数据库层面独立出来一个库，做特殊处理；

还需要针对秒杀系统做一些保护，针对意料之外的情况设计兜底方案，以防止最坏的情况发生；

## 3、设计原则

秒杀系统的本质就是：一个满足大并发、高性能和高可用的分布式系统

架构原则总结为“4要1不要”

- 数据尽量要少
    - 首先是指用户请求的数据能少就少。因为这些数据在网络上传输需要时间，其次不管是请求数据还是返回数据都需要服务器做处理，而服务器在写网络时通常都要做压缩和字符编码；
    - 其实是还要求系统以来的数据能少就少，包括系统完成某些业务逻辑需要读取和保存的数据。而且数据库本身也容易成为一个瓶颈；

- 请求数要尽量少
    
    用户请求的页面返回后，浏览器渲染这个页面还要包含其他的额外请求，比如依赖的Css/JavaScript、图片，以及ajax请求等，这些额外的请求应该尽量少；

    减少请求数最常用的一个实践是合并css和JavaScript文件；这种方式在服务端仍然是单个文件各自存储，只是服务端会有一个组件解析这个URL，然后动态把这些文件合并在一起返回；

- 路径要尽量短

    “路径”，就是用户发出请求到返回数据这个过程中，需求经过的中间的节点数；通常这些节点可以表示为一个系统或者一个新的Socket连接。每经过一个节点，一般都会产生一个新的Socket连接；

    缩短请求路径不仅可以增加可用性，同样可以有效提升性能，并减少延时；要缩短访问路径有一种办法，就是多个相互强依赖的应用合并部署在一起，把远程过程调用变成JVM内部之间的方法调用；

- 依赖尽量少

    所谓依赖指的是要完成一次用户请求必须依赖的系统或者服务，这里的依赖指的是强依赖；

    要减少依赖，可以给系统进行分级，比如0级系统、1级系统、2级系统、3级系统，0级系统如果是最重要的系统，那么0级系统强依赖的系统也同样是最重要的系统；

- 不要有单点：应用无状态化

## 4、秒杀实现关键技术

### 4.1、动静分离

所谓动静分离其实是把用户请求的数据划分为`动态数据`和`静态数据`；简而言之，`动态数据`和`静态数据`的主要区别就是看页面中输出的数据是否和URL、浏览者、时间、地域相关，以及是否包含有cookie等私密数据；主要一点是数据中是否含有和访问者相关的个性化数据

- 静态数据缓存
    - 将静态数据缓存到离用户最近的地方；常见的有浏览器、CDN、服务端的cache中；
    - 静态化改造就是要直接缓存HTTP连接

### 4.2、热点数据

- 热点操作：大量的刷新页面、大量的添加购物车、双十一零点下单；这些操作可以抽象为读请求、写请求；读请求的优化空间大些，写请求的瓶颈在存储层；
- 热点数据：
    - 静态热点数据：能够提前预测的热点数据，根据大数据分析的历史成交记录、用户的购物记录等，还可以由卖家报名方式提前筛选出来
    - 动态热点数据：不能被提前预测的数据

处理热点数据的思路：一是优化、二是限制、三是隔离

- 优化：最有效的办法是缓存热点数据，如果热点数据做了动静分离，那么可以长期缓存数；
- 限制：保护机制，例如对被访问的商品做一致性hash，然后根据hash做分桶，每个分桶设置一个处理队列，可以把热点商品限制在一个请求队列中；
- 隔离：秒杀系统的第一原则就是将热点数据隔离出来；
     - 业务隔离：可以把秒杀做成营销活动，卖家要参加秒杀需要单独报名，可以做好提前预热；
     - 系统隔离：更多的是运行时隔离，可以通过分组部署的方式另外的分开；秒杀可以申请单独的域名，让请求落到不同的集群中；
     - 数据隔离：秒杀系统所用的数据大部分是热点数据，可以启用单独的cache或者mysql数据库来放热点数据；


- 基于时间分片削峰：增加秒杀答题，既可以防止秒杀器也可以把峰值的下单请求给拉长了，从以前的1s之内延长到2~10s左右，请求峰值基于时间分片了，这个时间的分片对服务端处理并发非常重要；
- 数据分层校验：所谓分层校验就是对大量的请求做成“漏斗”式设计，在不同层次尽可能把无效的请求过滤，“漏斗”的最末端才是有效的请求，要达到这个效果必须对数据做分层的校验，把大量静态不需要检验的数据放在离用户最近的地方；
- 实时热点发现：

### 4.3、流量削峰

**为什么要削峰：**

服务器的处理资源是恒定的，出现峰值的情况下，很容易导致服务器崩溃。削峰的存在：
- 可以让服务端处理变的更加平稳；
- 节省服务器的资源成本

削峰的思路包括：排队、答题、分层过滤

**排队**

使用消息队列来缓冲瞬时流量，把同步的直接调用转换成异步的间接推送。

除了消息队列外，还有一些其他的排队方式：
- 利用线程池加锁等待；
- 先进先出、先进后出等常用的内存排队算法；
- 把请求序列化到文件中，然后在顺序的读文件来恢复请求，类似mysql的binlog同步机制；

**答题**

主要是为了增加购买的复杂度，从而达到两个目的：
- 防止部分买家使用秒杀器参加秒杀时作弊；
- 延缓请求，起到对请求流量进行削峰的作用。其主要是把峰值的下单请求拉长。

秒杀答题的设计思路：

![](秒杀答题设计思路.png)

整个秒杀答题逻辑主要分为三个部分：
- 题库生成模块
- 题库的推送模块
- 题库的图片生成模块

**分层过滤**

分层过滤就是采用漏斗式设计来处理请求。分层过滤的核心思想是：在不同的层次尽可能地过滤无效请求，让“漏斗”最末端的才是有效的请求。

分层校验的基本原则：
- 将动态请求的数据缓存在web端，过滤到无效的数据读；
- 对读数据不做强一致性校验，减少因为一致性校验产生的瓶颈的问题；
- 对写数据进行基于时间的合理分片，过滤掉过期的失效请求；
- 对写数据做限流包含，将超出系统承载能力的请求过滤掉；
- 对写数据进行强一致性校验，只保留最后有效的数据

## 5、优化系统

- 减少编码
- 减少序列化
- Java极致优化：使用原生的servlet处理请求，不要使用传统的MVC框架，可以绕过一堆复杂且用处不大的处理逻辑；直接输出流数据
- 并发读优化

## 6、减库存

### 6.1、减库存的方式

- 下单减库存：即当买家下单后，在商品的总库存中减去买家购买数量；是最简单的方式，也是控制最精确的方式，这样的情况下一定不会超卖；但是存在用户下单未付款单的情况；
- 付款减库存：即卖家下单后，并不立即减库存，而是等到用户付款后才真正减库存，否则库存一直保留给其他买家；因为付款才减库存，如果并发比较高，有可能出现买家下单后付不了款的情况；
- 预扣库存：买家下单后，库存为其保留一定的时间（如 10 分钟），超过这个时间，库存会自动释放，释放后其他买家可以继续购买；买家付款前，会去校验该订单的库存是否有保留，如果没有保留则再次尝试预扣；如果库存不足，则不允许继续付款；

### 6.2、减库存可能存在的问题

- 如果采用下单减库存的方式，即用户下单后就去减库存，正常情况下，买家下单后付款的概率很高；有一种场景例外，如果有竞争对手恶意下单将卖家的商品全部下单，让这款的商品库存减为零，那这款商品就不能正常售卖了，因为恶意下的单是不会付款的；这是下单减库存的不足之处；
- 付款减库存可能存在超卖的情况：因为下单不会减库存，所以可能会出现下单成功数远远超过真正库存数的情况；会导致很多用户下单成功但是付不了款，买家的购物体验很差；
- 预扣库存：如果把有效的付款时间设置为10分钟，但是恶意买家完全可以10分钟后再次下单，又会减完库存；针对这种情况，解决办法还是结合安全和反作弊的措施来防止；

- 给经常下单不付款的买家进行识别打标（可以在被打标的买家下单时不减库存）

### 6.3、超卖问题

- 在数据表上设置乐观锁字段；
- 利用Redis防止超售；

# 二、延迟消息

## 1、业务描述

在一段时间之后，完成一个工作任务，比如：
- 滴滴打车订单完成后，如果用户一直不评价，48小时后会将自动评价为5星
- 天猫订单未支付时24小时后失效；
- 电商平台如何设置一个在买家下订单后的”第60秒“发短信通知卖家发货，您需要考虑的是像淘宝一样的大并发量的订单

## 2、定时任务

启动一个cron定时任务，每小时跑一次，将完成时间超过48小时的订单取出，置为5星，并把评价状态置为已评价

方案的不足：
- （1）轮询效率比较低
- （2）每次扫库，已经被执行过记录，仍然会被扫描（只是不会出现在结果集中），有重复计算的嫌疑
- （3）时效性不够好，如果每小时轮询一次，最差的情况下，时间误差会达到1小时
- （4）如果通过增加cron轮询频率来减少（3）中的时间误差，（1）中轮询低效和（2）中重复计算的问题会进一步凸显

## 3、DelayQueue延迟队列

这种方式也比较方便，而且几乎没有延迟，对内存占用也不大；

主要是通过实现Delayed接口。存放到DelayDeque的元素必须继承Delayed接口。Delayed接口使对象成为延迟对象，它使存放在DelayQueue类中的对象具有了激活日期

缺点也比较明显，因为订单是存放在内存的，一旦服务器挂了，就麻烦了

## 4、Redis-ZSet

Sorted set是set的一个升级版本。它在set的基础上增加了一个顺序属性，这一属性在添加修改元素时候可以指定，每次指定后，zset会自动重新按新的值调整顺序

通过过ZRANGEBYSCORE命令，我们可以取得score在指定区间内的元素。将集合中的元素做为消息，score视为延迟的时间，这便是一个延迟队列的模型

具体过程：
- 生产者通过ZADD将消息发送到队列中；
- 消费者通过ZRANGEBYSCORE获取消息。如果时间未到，将得不到消息；当时间已到或已超时，都可以得到消息；
- 使用ZRANGEBYSCORE取得消息后，消息并没有从集合中删出。需要调用ZREM删除消息

缺点：消费者组合使用ZRANGEBYSCORE和ZREM的过程不是原子的，当有多个消费者时会存在竞争，可能使得一条消息被消费多次。此时需要使用Lua脚本保证消费操作的原子性

## 5、消息队列

### 5.1、RabbitMQ

延迟任务通过消息的TTL和Dead Letter Exchange来实现。需要建立2个队列，一个用于发送消息，一个用于消息过期后的转发目标队列。延时相同的消息必须扔在同一个队列

### 5.2、RocketMQ

- 延迟消息：消息发送到Broker之后，要特定的时间才会被Consumer消费；
- 目前只支持固定精度的定时消息：RocketMQ 支持发送延迟消息，但不支持任意时间的延迟消息的设置，仅支持内置预设值的延迟时间间隔的延迟消息。预设值的延迟时间间隔为：1s、 5s、 10s、 30s、 1m、 2m、 3m、 4m、 5m、 6m、 7m、 8m、 9m、 10m、 20m、 30m、 1h、 2h
- MessageStoreConfig配置类、ScheduleMessageService 任务类；
- 在消息创建的时候，调用 setDelayTimeLevel(int level) 方法设置延迟时间。broker在接收到延迟消息的时候会把对应延迟级别的消息先存储到对应的延迟队列中，等延迟消息时间到达时，会把消息重新存储到对应的topic的queue里面


# 三、双十一场景业务

## 1、业务分析


## 2、常见解决方案

- 前端DNS解析、软硬负载均衡设施进行分流/限流
- 缓存的业务维度拆分
- 微服务流控：微服务熔断、降级、兜底；
- 微服务接口的幂等性保障
- 数据库分库分表策略：设计契合业务维度的负载均衡算法
- 冷热数据、读写分离
- 对有效业务数据的过滤和业务的解耦
- 顺序消息机制
- 分布式事务


## 参考资料

- [有赞-延迟队列](https://tech.youzan.com/queuing_delay/)
- [实现延迟队列](https://mp.weixin.qq.com/s/eDMV25YqCPYjxQG-dvqSqQ)
- [Springboot与RabbitMQ实现延迟消息](https://juejin.im/entry/5aea9c58f265da0b851cb0c7)
- [MQ中实现延迟消息](https://www.cnblogs.com/hzmark/p/mq-delay-msg.html)
- [延时任务之Redis篇](https://mp.weixin.qq.com/s/dw1eCSh49vQDwPzvu5omCg)















