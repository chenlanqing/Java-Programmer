## 1、关于定时任务

在做定时任务时，如果定时任务时周期性的，比如5分钟执行一次，需要考虑如果某次定时任务运行时间超过了5分钟，下次定时任务执行时需要控制是否执行，具体方案：
- 使用锁控制，比如redis锁，注意一点要释放redis锁、设置锁超时时间；
- 使用对应数据的状态，比如说：查询的是失败的记录，那么处理中的数据状态变为处理中；

## 2、系统压力

注意跨系统调用时考虑对接系统的压力

## 3、慢SQL的问题

## 4、死锁问题

- 批量处理数据时，注意在更新数据时对需要更新的数据进行排序，防止并发造成数据库死锁；
- 批量更新数据时，最好是按照主键来更新，如果更新的where条件的字段不带索引，或者是多个条件，也可能造成死锁；mysql中最常用的引擎是Innodb，Innodb默认使用的是行锁。而行锁是基于索引的，因此要想加上行锁，在加锁时必须命中索引，否则将使用表锁

## 5、关于多线程处理

有表 table_a 有个字段count，需要根据原有数量更新最新数量，更新的量m，如果直接从事数据库查询会存在并发问题，可以直接在sql中：count = count + m;

## 6、关于长事务

处理逻辑要有很长的处理事务逻辑
- 不要一次性地用 delete 语句删除太多数据。其实，这就是一个典型的大事务场景。一些归档类的数据，平时没有注意删除历史数据，等到空间快满了，业务开发人员要一次性地删掉大量历史数据。同时，又因为要避免在高峰期操作会影响业务（至少有这个意识还是很不错的），所以会在晚上执行这些大量数据的删除操作；
- 大表 DDL

## 7、关于时间

终端的时间需要保持跟服务端的时间一致；


## 8、发布时，服务器CPU使用率飙升，发布完成后回归正常


## 9、多数据源事务问题

- [Spring多数据源@DS和@Transactional冲突问题](https://www.kuangstudy.com/bbs/1391998670748057601)

多数据源配置信息：
```xml
<dependency>
	<groupId>com.baomidou</groupId>
	<artifactId>dynamic-datasource-spring-boot-starter</artifactId>
	<version>3.5.1</version>
</dependency>
```
基本配置：
```yaml
spring:
  datasource:
    dynamic:
      hikari:
        connection-timeout: 5000
        idle-timeout: 30000 # 经过idle-timeout时间如果连接还处于空闲状态, 该连接会被回收
        min-idle: 5 # 池中维护的最小空闲连接数, 默认为 10 个
        max-pool-size: 16 # 池中最大连接数, 包括闲置和使用中的连接, 默认为 10 个
        max-lifetime: 60000 # 如果一个连接超过了时长，且没有被使用, 连接会被回收
        is-auto-commit: true
      primary: master #设置默认的数据源或者数据源组,默认值即为master
      strict: true #严格匹配数据源,默认false. true未匹配到指定数据源时抛异常,false使用默认数据源
      datasource:
        master: # 数据源名称
          url: 
          username: 
          password: 
          driver-class-name: com.mysql.cj.jdbc.Driver
# 如下，如果你是确定的几个数据源，可以直接都在yaml配置写死即可
#        slave_1:
#          url: 
#          username: 
#          password: 
#          driver-class-name: com.mysql.cj.jdbc.Driver
其中数据库连接池，所有的数据库统一配置，也可以单独配置，例如：
datasource:
        master: # 数据源名称
          url: 
          username: 
          password: 
          driver-class-name: com.mysql.cj.jdbc.Driver
          hikari:
            connection-timeout: 5000
            idle-timeout: 30000 # 经过idle-timeout时间如果连接还处于空闲状态, 该连接会被回收
            min-idle: 5 # 池中维护的最小空闲连接数, 默认为 10 个
            max-pool-size: 16 # 池中最大连接数, 包括闲置和使用中的连接, 默认为 10 个
            max-lifetime: 60000 # 如果一个连接超过了时长，且没有被使用, 连接会被回收
            is-auto-commit: true
```
**问题：@Transactional使用不当会照成@DS失效。**
- 1.实现层上面加@Transactional，数据源没有切换
- 2.开启事务的同时，会从数据库连接池获取数据库连接；
- 3.如果内层的service使用@DS切换数据源，只是又做了一层拦截，但是并没有改变整个事务的连接;
- 4.在这个事务内的所有数据库操作，都是在事务连接建立之后，所以会产生数据源没有切换的问题;
- 5.为了使@DS起作用，必须替换数据库连接，也就是改变事务的传播机智，产生新的事务，获取新的数据库连接

解决方法：
- 去除MasterService.upload上面的@Transactional，数据源切换正常，虽然可以解决，但是事务无效。
- BookService的save上面加@Transactional(propagation =Propagation.REQUIRES_NEW)，数据源切换，且事务有效。
完美解决。它会重新创建新事务，获取新的数据库连接，从而得到@DS的数据源

## 10、图片上传问题

在有用户图片上传的功能时，用户上传的图片需要第一时间显示，但是由于浏览器端有缓存，所以当用户上传后，需要在图片后面加一个时间戳，以此刷新客户端的图片缓存，否则用户在上传成功后依然显示老的图片；

另外上传时需要对图片进行校验：
- 基本校验：图片后缀名的校验；
- 深度校验：图片格式校验，通过文件的二进制流进行判断，每个文件都有独有的二进制流；

## 11、关于线上数据删除

账号分离。这样做的目的是，避免写错命令：
- 只给业务开发同学 DML 权限，而不给 truncate/drop 权限。而如果业务开发人员有 DDL 需求的话，也可以通过开发管理系统得到支持；
- 即使是 DBA 团队成员，日常也都规定只使用只读账号，必要的时候才使用有更新权限的账号；

制定操作规范。这样做的目的，是避免写错要删除的表名：
- 在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响以后再删除这张表。
- 改表名的时候，要求给表名加固定的后缀（比如加 _to_be_deleted)，然后删除表的动作必须通过管理系统执行。并且，管理系删除表的时候，只能删除固定后缀的表

备份脚本、执行脚本、验证脚本和回滚脚本

## 12、CPU某个时段突然飙高，数据连接池连接数飙升?

- 原因有两个
    - 管理后台导出数据引起的，导出的数据量太大(大概600万)，导出是异步的，但是后台需要去计算count，每个excel文件限制是5000条数据，计算文件数量有1200个excel文件，还需要将文件打包，涉及到很多磁盘IO，而且由于前端没有限制点击次数，导致用户频繁点击，从而实际导出的数据量远大于600万；
    - 另一个是数据库查询SQL慢问题

- 临时解决方案
    - 对慢SQL进行相应的优化操作；
    - 限制用户导出次数，只能导出一次.
    - 限制每次导出的数据量不能超过10万条数据；

- 后续解决方案:
   - 数据库读写分离；
    - 应用分离：之前所有应用都是部署在一台服务器上，把管理后台与移动终端应用分开部署，管理后天与移动终端后台互不影响

## 13、tomcat参数设置问题

之前在一个群里，有人返回说：HTTP调用 使老年代爆满，有人提出了一个思路：是否有修改： max-http-header-size

该网友设置的参数是：
```
server:
  max-http-header-size: 209715200
```
也就说：tomcat并发线程*200M，以100个并发算就要你20G的内存了