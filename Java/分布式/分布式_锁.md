## 1、分布式锁

在分布式环境下；保证一个方法在同一时间只有一个线程能调用一个方法；或者多个客户端同时对一个服务请求时；需要使用分布式锁

分布式锁经常出现哪些问题，以及如何解决：
- 可用问题：无论何时都要保证锁服务的可用性（这是系统正常执行锁操作的基础）；
- 死锁问题：客户端一定可以获得锁，即使锁住某个资源的客户端在释放锁之前崩溃或者网络不可达（这是避免死锁的设计原则）。
- 脑裂问题：集群同步时产生的数据不一致，导致新的进程有可能拿到锁，但之前的进程以为自己还有锁，那么就出现两个进程拿到了同一个锁的问题

### 1.1、分布式锁应该是怎样的

* 在分布式系统环境下，一个方法在同一时间只能被一个机器的一个线程执行；
* 高可用的获取锁与释放锁；
* 高性能的获取锁与释放锁；
* 具备可重入特性；
* 具备锁失效机制；防止死锁；
* 具备非阻塞锁特性，即没有获取到锁将直接返回获取锁失败。

### 1.2、分布式锁的实现方案

* 基于数据库实现分布式锁
* 基于缓存(redis；tair)等
* 基于zookeeper实现分布式锁

## 2、数据库分布式锁

### 2.1、基于数据库表

#### 2.1.1、实现方式

要实现分布式锁，最简单的方式可能就是直接创建一张锁表；然后通过操作该表中的数据来实现。当要锁住某个方法或者资源时；就在该表中增加一条记录；如果要释放锁就删除该记录
```sql
-- 创建表
CREATE TABLE `methodLock` (
  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '主键'；
  `method_name` varchar(64) NOT NULL DEFAULT '' COMMENT '锁定的方法名'；
  `desc` varchar(1024) NOT NULL DEFAULT '备注信息'；
  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '保存数据时间，自动生成'；
  PRIMARY KEY (`id`)；
  UNIQUE KEY `uidx_method_name` (`method_name `) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='锁定中的方法';
-- 获取锁
insert into methodLock(method_name；desc) values (‘method_name’；‘desc’);
-- 释放锁
delete from methodLock where method_name ='method_name';
```

#### 2.1.2、上述实现存在问题

- 该锁强依赖数据库的可用性：数据库是一个单点的；一旦数据库挂掉；会导致业务系统不可用；
- 该锁没有失效时间：一旦解锁失败；就会导致数据记录一直在数据库中；其他线程无法再获取得到锁；
- 该锁只能是非阻塞的：因为数据库的insert操作一旦插入失败就会直接报错；没有获得锁的线程并不会进入排队队列；要想再次获取锁就得再次出发获得锁操作；
- 该锁是非重入的：同一个线程在没有释放锁之前无法再次获得该锁；因为数据库中数据已存在；

#### 2.1.3、上述问题的解决方式

- 数据库单点：可以有两个数据库；数据之前是双向同步。一旦挂掉快速切换到备库上；
- 失效时间：定义定时任务；每隔一定时间把数据库中超时的数据清理一遍；
- 非阻塞：使用while循环；直到insert成功再返回成功；
- 非重入：在数据库表中加入字段；记录当前获得锁的机器主机信息和线程信息；那么下次再获取锁的时候先查询数据库；如果当前机器的主机信息和线程信息在数据库中可以查到；直接把锁分配给该线程即可；

### 2.2、基于数据库排他锁

借助数据库自带的锁来实现分布式锁

#### 2.2.1、实现

通过数据库排他锁来实现分布式锁；基于mysql的Innodb引擎.可以使用如下方法来实现：
```java
public boolean lock(){
	connection.setAutoCommit(false);
	while(true){
		try{
			result = "select * from methodLock where method_name=xxx for update";
			if(result == null){
				return true;
			}
		} catch(Exception e){
		}
		sleep(1000);
	}
	return false;
}
public void unlock(){
	connection.commit();
}
```
- 在查询语句后面增加for update；数据库会在查询过程中给数据库表增加排它锁【注意：innodb引擎在加锁的时候；只有通过索引进行检索的时候才会使用行级锁；否则会使用表级锁;该索引一旦要创建成唯一索引；否则会出现多个重载方法之间无法被同时访问的问题】;

- 通过connection.commit()来释放锁

如果是通过Spring来管理事务，需要注意事务提交自动提交；

#### 2.2.2、解决问题与存在的问题

- 可以有效的解决无法释放锁和阻塞锁的问题
	* for update语句会在执行成功后立即返回；在执行失败时一直处于阻塞状态；直到成功；
	* 使用这种方式；服务宕机后数据库会自己把锁释放掉；
- 无法解决数据库单点和可冲入问题；
- mysql会对查询进行优化；即便在条件中使用了索引字段；但是否使用索引来检索数据时mysql通过判断不同执行计划代价来决定的；如果mysql认为全表扫描效率高；这种情况下innodb使用表级锁而不是行级锁；
- 如果使用排它锁来进行分布式锁的lock；那么一个排他锁长时间不提交；就会占用数据库连接，一旦类似连接变多；可能把数据库连接池撑爆；

### 2.3、总结

- 数据库分布式锁的优点：直接借助数据库；容易理解
- 数据库分布式锁的缺点：
	* 会有各种各样的问题；在解决问题的过程中会使整个方案变的越来越复杂;
	* 操作数据库需要一定的开销；性能问题需要考虑;
	* 使用数据库的行级锁并不一定靠谱；尤其是当表不大的时候;

## 3、基于Redis实现分布式锁

### 3.1、使用Redis原因

- Redis有很高的性能;
- Redis命令对此支持很好；实现起来比较方便

### 3.2、Redis实现分布式锁涉及命令

- setnx：setnx key val：当且仅当key不存在时，set一个key为val的字符串，返回1；若key存在，则什么都不做，返回0；
- expire：expire key timeout：为key设置一个超时时间；单位为second；超过这个时间锁会自动是否；避免死锁；
- delete：delele key：删除key

### 3.3、基本思路

- 获取锁的时候，使用setnx加锁，并使用expire命令为锁添加一个超时时间；超过该时间则自动释放锁；锁的value值为一个随机的UUID；通过此在释放锁的时候进行判断；
- 获取锁的时候还设置一个超时时间，若超过这个时间则放弃获取锁；
- 释放锁的时候，通过UUID判断是不是该锁；若是该锁，则执行delete释放锁；

### 3.4、上述实现存在的问题

上述实现中存在几个问题：
- setnx和expire的非原子性
- del 导致误删
- 出现并发的可能性
- 不合理设置超时时间

#### 3.5.1、setnx和expire的非原子性

设想一个极端场景：当某线程执行setnx，成功得到了锁，setnx刚执行成功，还未来得及执行expire指令，获取锁的节点 Duang的一声挂掉了。这样一来，这把锁就没有设置过期时间，变得“长生不老”，别的线程再也无法获得锁了；setnx指令本身是不支持传入超时时间的，在redis2.6.12版本后为set指令增加了可选参数：`set(key，1，30，NX)`，这样就可以取代setnx指令

#### 3.5.2、不合理设置超时时间导致误删

不合理设置超时时间：
- 超时时间过短：假如某线程成功得到了锁，并且设置的超时时间是30秒；如果某些原因导致线程A执行的很慢很慢，过了30秒都没执行完，这时候锁过期自动释放，线程B得到了锁；随后，线程A执行完了任务，线程A接着执行del指令来释放锁。但这时候线程B还没执行完，线程A实际上删除的是线程B加的锁；怎么避免这种情况呢？可以在del释放锁之前做一个判断，验证当前的锁是不是自己加的锁；可以在加锁的时候把当前的线程ID当做value，并在删除之前验证key对应的value是不是自己线程的ID。但是，这样做又隐含了一个新的问题，判断和释放锁是两个独立操作，不是原子性，可以通过lua脚本处理；

那么如何合理设置超时时间呢？可以基于续约的方式设置超时时间：先给锁设置一个超时时间，然后启动一个守护线程，让守护线程在一段时间后，重新设置这个锁的超时时间。实现方式就是：写一个守护线程，然后去判断锁的情况，当锁快失效的时候，再次进行续约加锁，当主线程执行完成后，销毁续约锁即可

#### 3.5.3、出现并发的可能性

还是刚才上述所描述的场景，虽然我们避免了线程A误删掉key的情况，但是同一时间有A，B两个线程在访问代码块，仍然是不完美的。怎么办呢？我们可以让获得锁的线程开启一个守护线程，用来给快要过期的锁“续航”。

使用Redisson可以解决问题：redisson中获取锁成功就会开启一个定时任务，也就是watchdog，定时任务会定期检查去续期`renewExpirationAsync(threadId)`；这里使用的是netty中的HashedWheelTimer；该定时调度每次调用的时间差是`internalLockLeaseTime / 3`，也就10秒；

默认情况下，加锁的时间是30秒。如果加锁的业务没有执行完，那么到 `30-10 = 20`秒的时候，就会进行一次续期，把锁重置成30秒（watchDogs）；业务的机器万一宕机了呢？宕机了定时任务跑不了,就续不了期，那自然30秒之后锁就解开；

#### 3.5.4、Redis哨兵问题

一般使用 setnx 方法，通过 Redis 实现锁和超时时间来控制锁的失效时间。但是在极端的情况下，当 Redis 主节点挂掉，但锁还没有同步到从节点时，根据哨兵机制，从就变成了主，继续提供服务。这时，另外的线程可以再来请求锁，此时就会出现两个线程拿到了锁的情况；

如何解决呢？Redis 官方已经设计了一个分布式锁算法 Redlock 解决了这个问题，解决思路：为了避免 Redis 实例故障导致锁无法工作的问题，Redis 的开发者 Antirez 设计了分布式锁算法 Redlock。Redlock 算法的基本思路，是让客户端和多个独立的 Redis 实例依次请求申请加锁，如果客户端能够和半数以上的实例成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁，否则加锁失败；这样一来，即使有某个 Redis 实例发生故障，因为锁的数据在其他实例上也有保存，所以客户端仍然可以正常地进行锁操作，锁的数据也不会丢失

> 根据对 CAP 理论的理解，Redis 的设计模型是 AP 模型，而分布式锁是一个 CP 场景，那么很明显，将 Redis 这种 AP 模型的架构应用于 CP 的场景，在底层的技术选型上就是错误的；

### 3.6、使用Redisson实现

[Redisson](https://github.com/redisson/redisson) 封装了锁的实现，其继承了`java.util.concurrent.locks.Lock`的接口，可以向操作本地Lock一样去操作Redisson的Lock；Redisson不仅提供了Java自带的一些方法(lock,tryLock)，还提供了异步加锁，对于异步编程更加方便

- [基于Redisson锁](https://blog.csdn.net/caiguoxiong0101/article/details/104730973)

#### 3.6.1、tryLock方法

- （1）尝试加锁：首先会尝试进行加锁，由于需要兼容老版本的Redis，所以不能直接使用`ex、nx`原子操作的API，那么就只能使用lua脚本
	```java
	return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, command,
		"if (redis.call('exists', KEYS[1]) == 0) then " +
						"redis.call('hset', KEYS[1], ARGV[2], 1); " +
						"redis.call('pexpire', KEYS[1], ARGV[1]); " +
						"return nil; " +
		"end; " +
		"if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then " +
						"redis.call('hincrby', KEYS[1], ARGV[2], 1); " +
						"redis.call('pexpire', KEYS[1], ARGV[1]); " +
						"return nil; " +
		"end; " +
		"return redis.call('pttl', KEYS[1]);",
		Collections.<Object>singletonList(getName()), internalLockLeaseTime, getLockName(threadId));
	```
	其并没有使用我们的`setNx`来进行操作，而是使用的`hash`结构，我们的每一个需要锁定的资源都可以看做是一个`HashMap`，锁定资源的节点信息是Key，锁定次数是value。通过这种方式可以很好的实现可重入的效果，只需要对value进行加1操作，就能进行可重入锁；
- （2）如果尝试加锁失败，判断是否超时，如果超时则返回`false`；
- （3）如果加锁失败之后，没有超时，那么需要在名字为`redisson_lock__channel+lockName`的channel上进行订阅，用于订阅解锁消息，然后一直阻塞直到超时，或者有解锁消息；
- （4）重试步骤1，2，3，直到最后获取到锁，或者某一步获取锁超时

#### 3.6.2、unlock()

unlock方法比较简单也是通过lua脚本进行解锁，如果是可重入锁，只是减1。如果是非加锁线程解锁，那么解锁失败
```java
return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN,
"if (redis.call('exists', KEYS[1]) == 0) then " +
				"redis.call('publish', KEYS[2], ARGV[1]); " +
				"return 1; " +
"end;" +
"if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then " +
				"return nil;" +
"end; " +
"local counter = redis.call('hincrby', KEYS[1], ARGV[3], -1); " +
"if (counter > 0) then " +
				"redis.call('pexpire', KEYS[1], ARGV[2]); " +
				"return 0; " +
"else " +
				"redis.call('del', KEYS[1]); " +
				"redis.call('publish', KEYS[2], ARGV[1]); " +
				"return 1; "+
"end; " +
"return nil;",
Arrays.<Object>asList(getName(), getChannelName()), LockPubSub.unlockMessage, internalLockLeaseTime, getLockName(threadId));
```

#### 3.6.3、公平锁

Redisson还有公平锁的实现，对于公平锁其利用了list结构和hashset结构分别用来保存我们排队的节点，和我们节点的过期时间，用这两个数据结构帮助我们实现公平锁

#### 3.6.4、使用


### 3.7、RedLock

有如下场景：当机器A申请到一把锁之后，如果Redis主节点宕机了，这个时候从节点并没有同步到这一把锁，那么机器B再次申请的时候就会再次申请到这把锁；

为了解决上述问题提出了`RedLock红锁`的算法，在Redisson中也对RedLock进行了实现；可以需要实现多个Redis集群，然后进行红锁的加锁，解锁；具体步骤：
```java
RLock lock1 = RedissonInstance1.getLock("lock1");
RLock lock2 = RedissonInstance2.getLock("lock2");
RLock lock3 = RedissonInstance3.getLock("lock3");
RedissonRedLock lock = new RedissonRedLock(lock1, lock2, lock3);
lock.lock();
...
lock.unlock();
```
- （1）首先生成多个Redis集群的Rlock，并将其构造成RedLock；
- （2）依次循环对三个集群进行加锁，加锁的过程和使用Redisson加锁一致；
- （3）如果循环加锁的过程中加锁失败，那么需要判断加锁失败的次数是否超出了最大值，这里的最大值是根据集群的个数，比如三个那么只允许失败一个，五个的话只允许失败两个，要保证多数成功；
- （4）加锁的过程中需要判断是否加锁超时，有可能我们设置加锁只能用3ms，第一个集群加锁已经消耗了3ms了。那么也算加锁失败；
- （5）上面3，4步里面加锁失败的话，那么就会进行解锁操作，解锁会对所有的集群在请求一次解锁

RedLock基本原理是利用多个Redis集群，用多数的集群加锁成功，减少Redis某个集群出故障，造成分布式锁出现问题的概率

## 4、Zookeeper分布式锁

* [ZooKeeper分布式锁的实现原理](https://mp.weixin.qq.com/s/MuWafD3PP9czRgNFUdwYAw)

基于zookeeper临时有序节点可以实现分布式锁

### 4.1、实现逻辑

每个客户端对某个方法加锁时；在zookeeper上的与该方法对应指定节点的目录下；生成一个唯一的瞬时有序节点。

判断是否获取锁的方式很简单：只需要判断有序节点中序号最小的一个。当释放锁的时候；只需要将这个瞬时节点删除即可。同时可以避免服务宕机导致的锁无法释放而产生的死锁问题

基本思路
- 1、加锁，申请创建临时节点。
- 2、创建成功，则加锁成功；完成自己的业务逻辑后，删除此节点，释放锁。
- 3、创建失败，则证明节点已存在，当前锁被别人持有；注册watcher，监听最小数据节点的变化；
- 4、监听到数据节点被删除后，证明锁已被释放。重复步骤1，再次尝试加锁；

上述实现存在问题：惊群效应。惊群问题是计算机科学中，当许多进程等待一个事件，事件发生后这些进程被唤醒，但只有一个进程能获得CPU执行权，其他进程又得被阻塞，这造成了严重的系统上下文切换代价。改进思路：
- 1、加锁，在`/lock`锁节点下创建临时顺序节点并返回，比如：test0000000235；
- 2、获取`/lock`节点下全部子节点，并排序；
- 3、判断当前线程创建的节点，是否在全部子节点中顺序最小；
- 4、如果是，则代表获取锁成功；完成自己的业务逻辑后释放锁；
- 5、如果不是最小，找到比自己小一位的节点，比如test0000000234；对它进行监听；
- 6、当上一个节点删除后，证明前面的客户端已释放锁；然后尝试去加锁，重复以上步骤；

### 4.3、如何解决前面数据库分布式锁中存在的问题

- 锁无法释放：使用zookeeper可以有效的解决锁无法释放的问题；因为在创建锁的时候；客户端会在ZK中创建一个临时节点；一旦获取到之后突然挂掉；那么这个临时节点就会自动删除.其他客户端可以再次获取锁；

- 非阻塞锁：使用zookeeper实现阻塞的锁；客户端可以通过在ZK中创建顺序节点；并且在节点上绑定监听器；一旦节点有变化；zookeeper会通知客户端；客户端可以检查自己创建的节点是不是当前所有节点中序号最小的；如果是；那么自己将获取到锁；

- 不可重入：客户端在创建节点的时候；把当前客户端的主机信息和线程信息直接写入节点中；下次想要获取锁时直接和当前最小的节点数据对比.如果是一样的；那么可以直接获取到锁；如果不一样；就再创建一个临时有序节点；参与排队；

- 单点问题：ZK是集群部署的；只要集群中半数以上的机器存活；就可以对外提供服务

### 4.4、存在问题

- zookeeper实现的分布式锁在性能上可能没有缓冲服务那么高；因为每次在创建锁和释放锁的过程中吗；都要动态创建和销毁瞬时节点来实现锁功能
- 可能带来并发问题：考虑这样的情况，由于网络抖动，客户端和ZK集群的session连接断了，那么zk以为客户端挂了，就会删除临时节点，这时候其他客户端就可以获取到分布式锁了。就可能产生并发问题。这个问题不常见是因为zk有重试机制，一旦zk集群检测不到客户端的心跳，就会重试，Curator客户端支持多种重试策略。多次重试之后还不行的话才会删除临时节点。（所以，选择一个合适的重试策略也比较重要，要在锁的粒度和并发之间找一个平衡。）

## 5、Consul实现分布式锁

基于Consul的分布式锁主要利用Key/Value存储API中的acquire和release操作来实现。acquire和release操作是类似Check-And-Set的操作：
- acquire操作只有当锁不存在持有者时才会返回true，并且set设置的Value值，同时执行操作的session会持有对该Key的锁，否则就返回false；
- release操作则是使用指定的session来释放某个Key的锁，如果指定的session无效，那么会返回false，否则就会set设置Value值，并返回true

https://www.consul.io/

## 6、方案比较

- 从理解难以程度角度（从低到高）： 数据库 > 缓存 > zookeeper
- 从实现的复杂性解读（从低到高）：zookeeper >= 缓存 > 数据库
- 从性能角度（从高到低）：缓存 > zookeeper >= 数据库
- 从可靠性角度：zookeeper > 缓存 > 数据库

## 7、分布式安全问题

### 7.1、长时间的GC pause

在GC的时候会发生STW(stop-the-world)，例如CMS垃圾回收器，他会有两个阶段进行STW防止引用继续进行变化，client1获取了锁并且设置了锁的超时时间，但是client1之后出现了STW，这个STW时间比较长，导致分布式锁进行了释放，client2获取到了锁，这个时候client1恢复了锁，那么就会出现client1，2同时获取到锁，这个时候分布式锁不安全问题就出现了。这个其实不仅仅局限于RedLock,对于我们的ZK,Mysql一样的有同样的问题

### 7.2、时钟发生跳跃

对于Redis服务器如果其时间发生了时钟跳跃，那么肯定会影响我们锁的过期时间，那么我们的锁过期时间就不是我们预期的了，也会出现client1和client2获取到同一把锁，那么也会出现不安全，这个对于Mysql也会出现。但是ZK由于没有设置过期时间，那么发生跳跃也不会受影响

### 7.3、长时间的网络I/O

获取了锁之后我们进行网络调用，其调用时间由可能比我们锁的过期时间都还长，那么也会出现不安全的问题，这个Mysql也会有，ZK也不会出现这个问题

Chubby

## 8、分布式锁优化

### 8.1、分段锁

比如在电商下单的环节中，有个扣库存的步骤，为了防止超卖的情况，会使用分布式锁，但是在高并发环境下，怎么会优化这个分布式锁呢？

可以使用分段加锁的方法，假如你现在iphone有1000个库存，那么你完全可以给拆成20个库存段，要是你愿意，可以在数据库的表里建20个库存字段，比如stock_01，stock_02，类似这样的，也可以在redis之类的地方放20个库存key；

总之，就是把你的1000件库存给他拆开，每个库存段是50件库存，比如stock_01对应50件库存，stock_02对应50件库存。接着，每秒1000个请求过来了，好！此时其实可以是自己写一个简单的随机算法，每个请求都是随机在20个分段库存里，选择一个进行加锁

一旦对某个数据做了分段处理之后，有一个点大家一定要注意：就是如果某个下单请求，咔嚓加锁，然后发现这个分段库存里的库存不足了，此时咋办？

这时你得自动释放锁，然后立马换下一个分段库存，再次尝试加锁后尝试处理。这个过程一定要实现；

**分段锁的存在不足：**
- 首先，你得对一个数据分段存储，一个库存字段本来好好的，现在要分为20个分段库存字段；
- 其次，你在每次处理库存的时候，还得自己写随机算法，随机挑选一个分段来处理；
- 最后，如果某个分段中的数据不足了，你还得自动切换到下一个分段数据去处理；

### 8.2、细粒度

### 8.3、前置限流

## 参考资料

* [分布式锁的几种实现方式](http://www.hollischuang.com/archives/1716)
* [分布式RedLock](https://mp.weixin.qq.com/s/M-1MB7AleL-WRSxrCfwrqQ)
* [基于zookeeper分布式锁](https://juejin.im/post/5c6e2615518825629d07674b)
* [程序员小灰：分布式锁](https://mp.weixin.qq.com/s?__biz=MzIxMjE5MTE1Nw==&mid=2653194065&idx=1&sn=1baa162e40d48ce9b44ea5c4b2c71ad7&chksm=8c99f58bbbee7c9d5b5725da5ee38fe0f89d7a816f3414806785aea0fe5ae766769600d3e982&scene=21#wechat_redirect)
* [Redisson实现Redis分布式锁](https://mp.weixin.qq.com/s/iaZcc7QGbGHkZkfLeYp1yg)