- 分布式系统如何负载均衡？如何确定访问的资源在哪个服务器上？
- 设计一个分布式负载均衡缓冲系统，如何快速定位到是那个服务

由一个独立的统一入口来收敛流量，再做二次分发的过程就是负载均衡

负载均衡有两方面的含义：
- 首先，大量的并发访问或数据流量分担到多台节点设备上分别处理，减少用户等待响应的时间；
- 其次，单个重负载的运算分担到多台节点设备上做并行处理，每个节点设备处理结束后，将结果汇总，返回给用户，系统处理能力得到大幅度提高

## 1、四层、七层、DNS负载均衡

所谓四层就是基于IP+端口的负载均衡；七层就是基于URL等应用层信息的负载均衡；同理，还有基于MAC地址的二层负载均衡和基于IP地址的三层负载均衡。 换句换说，二层负载均衡会通过一个虚拟MAC地址接收请求，然后再分配到真实的MAC地址；三层负载均衡会通过一个虚拟IP地址接收请求，然后再分配到真实的IP地址；四层通过虚拟IP+端口接收请求，然后再分配到真实的服务器；七层通过虚拟的URL或主机名接收请求，然后再分配到真实的服务器

### 1.1、四层负载均衡

- **概念：**基于传输层，主要针对TCP和UDP；通过虚拟IP+端口接收请求，然后再分配到真实的服务器
- **原理：**通过发布三层的IP地址，然后加四层的端口号，来决定哪些流量需要做负载均衡，对需要处理的流量进行NAT处理，转发至后台服务器，并记录下这个TCP或者UDP的流量是由哪台服务器处理的，后续这个连接的所有流量都同样转发到同一台服务器处理
- **常见**

Nginx1.9版本后又新的模块支持四层负载均衡

### 1.2、七层负载均衡

七层的负载均衡，就是在四层的基础上（没有四层是绝对不可能有七层的），再考虑应用层的特征，比如同一个Web服务器的负载均衡，除了根据VIP加80端口辨别是否需要处理的流量，还可根据七层的URL、浏览器类别、语言来决定是否要进行负载均衡。举个例子，如果你的Web服务器分成两组，一组是中文语言的，一组是英文语言的，那么七层负载均衡就可以当用户来访问你的域名时，自动辨别用户语言，然后选择对应的语言服务器组进行负载均衡处理

### 1.3、四层、七层负载均衡区别

**技术原理上的区别：**

- 所谓四层负载均衡，也就是主要通过报文中的目标地址和端口，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。

	以常见的TCP为例，负载均衡设备在接收到第一个来自客户端的SYN 请求时，即通过上述方式选择一个最佳的服务器，并对报文中目标IP地址进行修改(改为后端服务器IP），直接转发给该服务器。TCP的连接建立，即三次握手是客户端和服务器直接建立的，负载均衡设备只是起到一个类似路由器的转发动作。在某些部署情况下，为保证服务器回包可以正确返回给负载均衡设备，在转发报文的同时可能还会对报文原来的源地址进行修改；

- 所谓七层负载均衡，也称为“内容交换”，也就是主要通过报文中的真正有意义的应用层内容，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。

	以常见的TCP为例，负载均衡设备如果要根据真正的应用层内容再选择服务器，只能先代理最终的服务器和客户端建立连接(三次握手)后，才可能接受到客户端发送的真正应用层内容的报文，然后再根据该报文中的特定字段，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。负载均衡设备在这种情况下，更类似于一个代理服务器。负载均衡和前端的客户端以及后端的服务器会分别建立TCP连接。所以从这个技术原理上来看，七层负载均衡明显的对负载均衡设备的要求更高，处理七层的能力也必然会低于四层模式的部署方式

**应用场景的需求：**

- 七层应用负载的好处，是使得整个网络更”智能化
- 安全性角度：从技术原理上也可以看出，四层模式下这些SYN Flood攻击都会被转发到后端的服务器上；而七层模式下这些SYN攻击自然在负载均衡设备上就截止，不会影响后台服务器的正常运营
- 现在的7层负载均衡，主要还是着重于应用HTTP协议，所以其应用范围主要是众多的网站或者内部信息平台等基于B/S开发的系统。 4层负载均衡则对应其他TCP应用；

**七层应用需要考虑的问题：**

- 是否真的必要：七层应用的确可以提高流量智能化，同时必不可免的带来设备配置复杂，负载均衡压力增高以及故障排查上的复杂性等问题；
- 是否真的可以提高安全性：例如SYN Flood攻击，七层模式的确将这些流量从服务器屏蔽，但负载均衡设备本身要有强大的抗DDoS能力，否则即使服务器正常而作为中枢调度的负载均衡设备故障也会导致整个应用的崩溃；
- 是否有足够的灵活度：七层应用的优势是可以让整个应用的流量智能化，但是负载均衡设备需要提供完善的七层功能，满足客户根据不同情况的基于应用的调度。最简单的一个考核就是能否取代后台Nginx或者Apache等服务器上的调度功能。能够提供一个七层应用开发接口的负载均衡设备，可以让客户根据需求任意设定功能，才真正有可能提供强大的灵活性和智能性

### 1.4、DNS负载均衡

DNS 是最简单也是最常见的负载均衡方式，一般用来实现地理级别的均衡；**DNS 负载均衡的本质是 DNS 解析同一个域名可以返回不同的 IP 地址**

DNS 负载均衡实现简单、成本低，但也存在粒度太粗、负载均衡算法少等缺点；

*优点*：
- 简单、成本低：负载均衡工作交给 DNS 服务器处理，无须自己开发或者维护负载均衡设备；
- 就近访问，提升访问速度：DNS 解析时可以根据请求来源 IP，解析成距离用户最近的服务器地址，可以加快访问速度，改善性能

*缺点*：
- 更新不及时：DNS 缓存的时间比较长，修改 DNS 配置后，由于缓存的原因，还是有很多用户会继续访问修改前的 IP，访问会失败，达不到负载均衡效果，也影响用户正常使用业务。
- 扩展性差：DNS 负载均衡的控制权在域名商那里，无法根据业务特点针对其做更多的定制化功能和扩展特性；
- 分配策略比较简单：DNS 负载均衡支持的算法少；不能区分服务器的差异；

## 2、硬件负载均衡

硬件负载均衡解决方案是直接在服务器和外部网络间安装负载均衡设备，这种设备我们通常称之为负载均衡器，由于专门的设备完成专门的任务，独立于操作系统，整体性能得到大量提高，加上多样化的负载均衡策略，智能化的流量管理，可达到最佳的负载均衡需求；

一般而言，硬件负载均衡在功能、性能上优于软件方式，不过成本昂贵

常见的有：
- F5
- Array

硬件负载均衡的缺点是：
- 价格昂贵：最普通的一台 F5 就是一台“马 6”，好一点的就是“Q7”了。
- 扩展能力差：硬件设备，可以根据业务进行配置，但无法进行扩展和定制。

## 3、软件负载均衡

软件负载均衡解决方案是指在一台或多台服务器相应的操作系统上安装一个或多个附加软件来实现负载均衡，如DNS Load Balance，CheckPoint Firewall-1 ConnectControl等，它的优点是基于特定环境，配置简单，使用灵活，成本低廉，可以满足一般的负载均衡需求；

软件解决方案缺点也较多，因为每台服务器上安装额外的软件运行会消耗系统不定量的资源，越是功能强大的模块，消耗得越多，所以当连接请求特别大的时候，软件本身会成为服务器工作成败的一个关键；软件可扩展性并不是很好，受到操作系统的限制；由于操作系统本身的Bug，往往会引起安全问题

常见的有：
- Nginx
- LVS
- HAProxy

如果是中小型的Web应用，比如日PV小于1000万，用Nginx就完全可以了；如果机器不少，可以用DNS轮询，LVS所耗费的机器还是比较多的；大型网站或重要的服务，且服务器比较多时，可以考虑用LVS

### 3.1、Nginx

**优点：**

- 工作在网络的7层之上，可以针对http应用做一些分流的策略，比如针对域名、目录结构，它的正则规则比HAProxy更为强大和灵活，这也是它目前广泛流行的主要原因之一，Nginx单凭这点可利用的场合就远多于LVS了。其在1.9版本之后也支持四层负载均衡了；
- Nginx对网络稳定性的依赖非常小，理论上能ping通就就能进行负载功能，这个也是它的优势之一；相反LVS对网络稳定性依赖比较大；
- Nginx安装和配置比较简单，测试起来比较方便，它基本能把错误用日志打印出来。LVS的配置、测试就要花比较长的时间了，LVS对网络依赖比较大；
- 可以承担高负载压力且稳定，在硬件不差的情况下一般能支撑几万次的并发量，负载度比LVS相对小些；
- Nginx可以通过端口检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点，不过其中缺点就是不支持url来检测；LVS就直接断掉了，如果是上传一个很大的文件或者很重要的文件的话，用户可能会因此而不满；
- Nginx不仅仅是一款优秀的负载均衡器/反向代理软件，它同时也是功能强大的Web应用服务器；
- Nginx现在作为Web反向加速缓存越来越成熟了，速度比传统的Squid服务器更快，可以考虑用其作为反向代理加速器；
- Nginx可作为中层反向代理使用；
- Nginx也可作为静态网页和图片服务器；

**缺点：**

- Nginx仅能支持http、https和Email协议；
- 对后端服务器的健康检查，只支持通过端口来检测，不支持通过url来检测。不支持Session的直接保持，但能通过ip_hash来解决；

### 3.2、LVS

使用Linux内核集群实现一个高性能、高可用的负载均衡服务器，它具有很好的可伸缩性（Scalability)、可靠性（Reliability)和可管理性（Manageability)

**优点：**

- 抗负载能力强、是工作在网络4层之上仅作分发之用，没有流量的产生，这个特点也决定了它在负载均衡软件里的性能最强的，对内存和cpu资源消耗比较低；
- 配置性比较低，这是一个缺点也是一个优点，因为没有可太多配置的东西，所以并不需要太多接触，大大减少了人为出错的几率；
- 工作稳定，因为其本身抗负载能力很强，自身有完整的双机热备方案，如LVS+Keepalived；
- 无流量，LVS只分发请求，而流量并不从它本身出去，这点保证了均衡器IO的性能不会受到大流量的影响；
- 应用范围比较广，因为LVS工作在4层，所以它几乎可以对所有应用做负载均衡，包括http、数据库、在线聊天室等等；

**缺点：**

- 软件本身不支持正则表达式处理，不能做动静分离；而现在许多网站在这方面都有较强的需求，这个是Nginx/HAProxy+Keepalived的优势所在；
- 如果是网站应用比较庞大的话，LVS/DR+Keepalived实施起来就比较复杂了，特别后面有 Windows Server的机器的话，如果实施及配置还有维护过程就比较复杂了，相对而言，Nginx/HAProxy+Keepalived就简单多了

### 3.3、HAProxy

- HAProxy也是支持虚拟主机的；
- HAProxy的优点能够补充Nginx的一些缺点，比如支持Session的保持，Cookie的引导；同时支持通过获取指定的url来检测后端服务器的状态；
- HAProxy跟LVS类似，本身就只是一款负载均衡软件；单纯从效率上来讲HAProxy会比Nginx有更出色的负载均衡速度，在并发处理上也是优于Nginx的；
- HAProxy支持TCP协议的负载均衡转发，可以对MySQL读进行负载均衡，对后端的MySQL节点进行检测和负载均衡，大家可以用LVS+Keepalived对MySQL主从做负载均衡

HAProxy负载均衡策略非常多，HAProxy的负载均衡算法现在具体有如下8种：
- ① roundrobin，表示简单的轮询，这个不多说，这个是负载均衡基本都具备的；
- ② static-rr，表示根据权重，建议关注；
- ③ leastconn，表示最少连接者先处理，建议关注；
- ④ source，表示根据请求源IP，这个跟Nginx的IP_hash机制类似，我们用其作为解决session问题的一种方法，建议关注；
- ⑤ ri，表示根据请求的URI；
- ⑥ rl_param，表示根据请求的URl参数’balance url_param’ requires an URL parameter name；
- ⑦ hdr(name)，表示根据HTTP请求头来锁定每一次HTTP请求；
- ⑧ rdp-cookie(name)，表示根据据cookie(name)来锁定并哈希每一次TCP请求

### 3.4、软件负载均衡架构选择

第一阶段：利用Nginx或HAProxy进行单点的负载均衡，这一阶段服务器规模刚脱离开单服务器、单数据库的模式，需要一定的负载均衡，但是仍然规模较小没有专业的维护团队来进行维护，也没有需要进行大规模的网站部署。这样利用Nginx或HAproxy就是第一选择，此时这些东西上手快， 配置容易，在七层之上利用HTTP协议就可以。这时是第一选择。

第二阶段：随着网络服务进一步扩大，这时单点的Nginx已经不能满足，这时使用LVS或者商用Array就是首要选择，Nginx此时就作为LVS或者Array的节点来使用，具体LVS或Array的是选择是根据公司规模和预算来选择，Array的应用交付功能非常强大，本人在某项目中使用过，性价比也远高于F5，商用首选，但是一般来说这阶段相关人才跟不上业务的提升，所以购买商业负载均衡已经成为了必经之路。

第三阶段：这时网络服务已经成为主流产品，此时随着公司知名度也进一步扩展，相关人才的能力以及数量也随之提升，这时无论从开发适合自身产品的定制，以及降低成本来讲开源的LVS，已经成为首选，这时LVS会成为主流。

最终形成比较理想的基本架构为：Array/LVS — Nginx/Haproxy — Squid/Varnish — AppServer。

> DNS 负载均衡用于实现地理级别的负载均衡；硬件负载均衡用于实现集群级别的负载均衡；软件负载均衡用于实现机器级别的负载均衡。

## 4、负载均衡策略

### 4.1、轮询-默认的负载策略

每一次来自网络的请求轮流分配给内部中的服务器，从1至N然后重新开始。此种均衡算法适合于服务器组中的所有服务器都有相同的软硬件配置并且平均服务请求相对均衡的情况

### 4.2、加权轮询

在轮询的基础上，增加了一个权重的概念。权重是一个泛化后的概念，可以用任意方式来体现，本质上是一个能者多劳思想。此种均衡算法能确保高性能的服务器得到更多的使用率，避免低性能的服务器负载过重；

在加权算法里面，有一个改进叫做平滑的加权轮询算法。

每个节点会有两个权重，初始权重（weight）和当前权重（currrentWeight）。算法的过程稍微有点复杂，每一次挑选节点都执行这些步骤。
- 对每一个节点，执行 currrentWeight = currrentWeight + weight。
- 挑选最大 currrentWeight 的节点作为目标节点。
- 将目标节点的 currrentWeight 修改为 currrentWeight = currrentWeight - sum(weight)。

对于一个节点来说，每次被挑选之后，它的 currrentWeight 就会下降，那么下一次就不会选中它

### 4.3、随机

把来自网络的请求随机分配给内部中的多个服务器

**对比轮询：**轮询算法和随机算法，从统计学角度来看，最终效果是一样的。但是轮询算法天然的就会比随机算法更平滑，可以避免连读多次请求打到一个节点上

### 4.4、加权随机

此种均衡算法类似于权重轮循算法，不过在处理请求分担时是个随机选择的过程

### 4.5、最快响应

负载均衡设备对内部各服务器发出一个探测请求（例如Ping），然后根据内部中各服务器对探测请求的最快响应时间来决定哪一台服务器来响应客户端的服务请求。此种均衡算法能较好的反映服务器的当前运行状态，但这最快响应时间仅仅指的是负载均衡设备与服务器间的最快响应时间，而不是客户端与服务器间的最快响应时间

### 4.6、最少连接数

这是一种根据实时的负载情况，进行动态负载均衡的方式。维护好活动中的连接数量，然后取最小的返回即可。最少连接数均衡算法对内部中需负载的每一台服务器都有一个数据记录，记录当前该服务器正在处理的连接数量，当有新的服务连接请求时，将把当前请求分配给连接数最少的服务器，使均衡更加符合实际情况，负载更加均衡。此种均衡算法适合长时处理的请求服务，如FTP

### 4.7、Hash法

hash法的负载均衡与之前的几种不同在于，它的结果是由客户端决定的。通过客户端带来的某个标识经过一个标准化的散列函数进行打散分摊
- IP哈希：将相同来源IP的请求转发到同一个上游服务器，可用于session保持等场景
- URL哈希：与IP哈希策略蕾西，使用请求URL进行哈希计算，将相同哈希值的请求转发到相同的上游服务器；

**一致性哈希负载均衡：**一致性哈希负载均衡引入了一个哈希环的概念，服务端节点会落在环的某些位置上。客户端根据请求参数，计算一个哈希值。这个哈希值会落在哈希环的某个位置。从这个位置出发，顺时针查找，遇到的第一个服务端节点就是目标节点；

### 4.8、其他策略

- 最小会话策略：根据当前的session报错情况，将请求分发给会话；
- 趋势分析策略：根据一段时间内的请求分发情况、连接数、会话、服务器状态等信息判断出每个上游服务器未来的流量上升和下降趋势，将请求转发给趋势上升的服务器；

### 4.9、负载均衡策略比较

策略 | 优点 | 缺点 | 适用场景
----|-----|------|-------
顺序轮询|静态、稳定|不关系服务端负载，服务端处理能力的波动可能产生堵塞|服务端处理能力相同且稳定性高
加权轮询|静态、稳定、允许服务端性能差异|不关系服务端负载，服务端处理能力的波动可能产生堵塞|服务端处理能力符合预期且稳定性高
最少连接|动态、实时变化|复杂度提升，每次开关连接时需要计数|服务端处理能力有波动
最快响应|动态、实时变化，支持到请求级别比最少连接更灵敏|复杂度提升，需要计算请求的响应时间|服务端处理能力有波动
Hash|算法稳定|由客户端决定分布，可能导致分布不均|同一个客户端和服务端反复通信

### 4.10、权重的设置和调整

一般来说，加权类的算法都要考虑权重的设置和调整。

比如轮询，可能偶发性的负载不均衡，可能原因是`大请求`，有可能线上会有类似的场景，响应时间总体来说是非常均匀的，但是每隔一段时间就会出现响应时间特别慢的情况。而且时间间隔是不固定的，慢的程度也不一样，所以就很奇怪；其实这有可能就是`大请求`；当一个`大请求`落到一个节点的时候，它会占据大量的内存和 CPU。如果这时候再有请求打到同一个节点上，这部分请求的响应时间就会非常慢；

可以从两个角度解决：业务拆分或者业务隔离：
- 比如对大请求进行拆分；
- 可以根据实际的业务场景来进行隔离；将大请求和正常请求进行业务隔离；

**如何设置权重或者怎么调整权重**

一般来说，加权类的负载均衡算法都会考虑根据调用结果来动态调整权重。如果调用成功了，那么就增加权重；如果调用失败了，那么就减少权重；

这里调用成功与否是一种非业务相关的概念，也就是说即便拿到了一个失败的响应，但是本身也算是调用成功了。`调用失败了大多数时候是指网络错误、超时等`。而在实际落地的时候，也可以考虑如果是网络引起的失败，那么权重下调就多一点，因为这一类的错误意味着问题更加严重。如果是超时这种，那么权重就下调少一点，因为这种错误是比较容易恢复过来的；

另外，**权重的调整要设置好上限和下限**，调整权重的算法都要考虑安全问题，即权重的调整应该有上限和下限。比如说一般下限不能为 0，因为一个节点的权重为 0 的话，它可能永远也不会被选中，又或者和 0 的数学运算会出现问题导致负载均衡失败。上限一般不超过初始权重的几倍，比如说两倍或者三倍，防止该节点一直被连续选中

### 4.11、哈希与本地缓存

在性能非常苛刻的时候，有可能会考虑使用本地缓存。但是使用本地缓存的数据一致性问题会非常严重，而我们可以尝试将一致性哈希负载均衡算法和本地缓存结合在一起，以提高缓存命中率，并且降低本地缓存的总体内存消耗。比如说针对用户的本地缓存，我们可以使用用户 ID 来计算哈希值，那么可以确保同一个用户的本地缓存必然在同一个节点上。不过即便是采用了一致性哈希负载均衡算法，依旧不能彻底解决数据一致性的问题，只能缓解一下；当整个集群的节点数量发生变化的时候，就难免会导致同样的数据缓存在多个节点上。

## 5、客户端负载与服务端负载

**客户端负载**

需要将服务端的地址列表保存在客户端，客户端通过负载均衡策略调用具体的机器；

**服务端负载**

客户端访问负载均衡（Nginx、F5等）组件，负载均衡组件选择具体的服务，客户端并不知道具体调用的是哪台机器；

**区别：**
- 客户端负载开发团队能够灵活修改；服务端的负载一般是由运维来管理的；
- 客户端运维成本低；服务端负载运维成本高；
- 客户端强依赖注册中心；服务端通常不依赖注册中心；
- 客户端一般在微服务架构；服务端tomcat等传统应用：F5等；

## 6、健康探测机制

- HTTP探测

- TCP探测

- UDP探测