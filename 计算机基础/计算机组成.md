![](image/计算机组成原理-知识地图.png)

# 1、冯·诺依曼体系结构

## 1.1、计算机的基本硬件组成

三大件：
- CPU：中央处理器（Central Processing Unit）
- 内存：存放在内存里的程序和数据，需要被 CPU 读取，CPU 计算完之后，还要把数据写回到内存
- 主板：CPU 要插在主板上，内存也要插在主板上。主板的芯片组（Chipset）和总线（Bus）解决了 CPU 和内存之间如何通信的问题。芯片组控制了数据传输的流转，也就是数据从哪里到哪里的问题。总线则是实际数据传输的高速公路。因此，总线速度（Bus Speed）决定了数据能传输得多快

最后配上电源、输入输出设备；

另外还有一个特殊设备显卡，图形操作系统少不了这个，显卡之所以特殊，是因为显卡里有除了 CPU 之外的另一个“处理器”，也就是GPU（Graphics Processing Unit，图形处理器），GPU 一样可以做各种“计算”的工作；

### 1.2、冯·诺依曼体系结构

冯·诺依曼在[First Draft](https://en.wikipedia.org/wiki/First_Draft_of_a_Report_on_the_EDVAC)里面描述了一台计算机应该有哪些部分组成
- 首先是一个包含算术逻辑单元（Arithmetic Logic Unit，ALU）和处理器寄存器（Processor Register）的`处理器单元（Processing Unit）`，用来完成各种算术和逻辑运算。因为它能够完成各种数据的处理或者计算工作，因此也有人把这个叫作数据通路（Datapath）或者运算器；
- 然后是一个包含指令寄存器（Instruction Reigster）和程序计数器（Program Counter）的`控制器单元（Control Unit/CU）`，用来控制程序的流程，通常就是不同条件下的分支和跳转。在现在的计算机里，上面的算术逻辑单元和这里的控制器单元，共同组成了我们说的 CPU；
- 接着是用来存储数据（Data）和指令（Instruction）的`内存`，以及更大容量的`外部存储`，在过去，可能是磁带、磁鼓这样的设备，现在通常就是硬盘；
- 最后就是各种`输入和输出设备`，以及对应的输入和输出机制。个人电脑的鼠标键盘是输入设备，显示器是输出设备。我们用的智能手机，触摸屏既是输入设备，又是输出设备。而跑在各种云上的服务器，则是通过网络来进行输入和输出。这个时候，网卡既是输入设备又是输出设备；

任何一台计算机的任何一个部件都可以归到`运算器/处理器单元`、`控制器`、`存储器`、`输入设备`和`输出设备`中，而所有的现代计算机也都是基于这个基础架构来设计开发的；

而所有的计算机程序，也都可以抽象为从输入设备读取输入信息，通过运算器和控制器来执行存储在存储器里的程序，最终把结果输出到输出设备中；

冯·诺依曼体系结构确立了我们现在每天使用的计算机硬件的基础架构

冯·诺依曼体机与图灵机两者比较：两者有交叉但是不同
- 图灵机是一种思想模型（计算机的基本理论基础），是一种有穷的、构造性的问题的问题求解思路，图灵认为凡是能用算法解决的问题也一定能用图灵机解决；
- 冯诺依曼提出了“存储程序”的计算机设计思想，并“参照”图灵模型设计了历史上第一台电子计算机，即冯诺依曼机

# 2、计算机性能和功耗

对于计算机的性能，我们需要有个标准来衡量。这个标准中主要有两个指标：
- 第一个是响应时间（Response time）或者叫执行时间（Execution time）：让计算机跑的更快，响应时间指的就是，我们执行一个程序，到底需要花多少时间。花的时间越少，自然性能就越好
- 第二个是吞吐率（Throughput）或者带宽（Bandwidth）：让计算机搬的更多；吞吐率是指我们在一定的时间范围内，到底能处理多少事情

一般把性能定义成响应时间的倒数：`性能 = 1 / 响应时间`，响应时间越短，性能的数值就越大
 
## 2.1、CPU 时钟

用时间来衡量性能，存在两个问题：
- 第一个就是时间不“准”
- 其次，即使我们已经拿到了 CPU 时间，也不一定可以直接“比较”出两个程序的性能差异，即使在同一台计算机上，CPU 可能满载运行也可能降频运行，降频运行的时候自然花的时间会多一些

**时间不准**

为什么不准？首先，统计时间是用类似于“掐秒表”一样，记录程序运行结束的时间减去程序开始运行的时间。这个时间也叫 Wall Clock Time 或者 Elapsed Time，就是在运行程序期间，挂在墙上的钟走掉的时间；

但是，计算机可能同时运行着好多个程序，CPU 实际上不停地在各个程序之间进行切换。在这些走掉的时间里面，很可能 CPU 切换去运行别的程序了。而且，有些程序在运行的时候，可能要从网络、硬盘去读取数据，要等网络和硬盘把数据读出来，给到内存和 CPU。**所以说，要想准确统计某个程序运行时间，进而去比较两个程序的实际性能，得把这些时间给刨除掉。**

Linux 下有一个叫 time 的命令，可以统计出来：同样的 Wall Clock Time 下，程序实际在 CPU 上到底花了多少时间；它会返回三个值：
```bash
[root@bluefish ~]# time seq 1000000 |wc -l
1000000
real    0m0.013s
user    0m0.011s
sys     0m0.012s
```
- 第一个是real time，也就是前面说的 Wall Clock Time，也就是运行程序整个过程中流逝掉的时间；
- 第二个是user time，也就是 CPU 在运行你的程序，在用户态运行指令的时间；
- 第三个是sys time，是 CPU 在运行你的程序，在操作系统内核里运行指令的时间。而程序实际花费的 CPU 执行时间（CPU Time），就是 user time 加上 sys time；

除了 CPU 之外，时间这个性能指标还会受到主板、内存这些其他相关硬件的影响。所以，需要对“时间”这个可以感知的指标进行拆解，把程序的 CPU 执行时间变成` CPU 时钟周期数（CPU Cycles）`和 `时钟周期时间（Clock Cycle）`的乘积：

<p align="center">程序的CPU执行时间 = CPU时钟周期数 × 时钟周期时间</p>

**时钟周期**

比如电脑的CPU描述：`Intel Core-i7 2.8GHz`，这里的 `2.8GHz` 就是电脑的主频（Frequency/Clock Rate），`2.8GHz` 就代表，我们 CPU 的一个“钟表”能够识别出来的最小的时间间隔；

而在 CPU 内部，和电子石英表类似，有一个叫晶体振荡器（Oscillator Crystal）的东西，简称为晶振。把晶振当成 CPU 内部的电子表来使用。**晶振带来的每一次“滴答”，就是时钟周期时间**

在这个 2.8GHz的CPU上，时间周期时间就是：`1/2.8G`；CPU，是按照这个“时钟”提示的时间来进行自己的操作。主频越高，意味着这个表走得越快，我们的 CPU 也就“被逼”着走得越快；

根据前面计算程序CPU执行时间的公式，最简单的提升性能方案，自然缩短时钟周期时间，也就是提升主频。换句话说，就是换一块好一点的 CPU；

**CPU 时钟周期数**

前面提到提升性能的简单方案是缩短时钟周期时间，即提升主频，也就是换一块好的CPU；除了这个，还可以减少程序需要的 CPU 时钟周期数量，一样能够提升程序性能；

对于 CPU 时钟周期数，可以再做一个分解，把它变成“`指令数×每条指令的平均时钟周期数（Cycles Per Instruction，简称 CPI）`”。不同的指令需要的 Cycles 是不同的，加法和乘法都对应着一条 CPU 指令，但是乘法需要的 Cycles 就比加法要多，自然也就慢。在这样拆分了之后，程序的 CPU 执行时间就可以变成这样三个部分的乘积：

<p align="center">程序的 CPU 执行时间 = 指令数 × CPI × Clock Cycle Time</p>

因此想要解决性能问题，其实是优化这三者：
- 时钟周期时间，就是计算机主频，这个取决于计算机硬件。摩尔定律就一直在不停地提高我们计算机的主频。
- 每条指令的平均时钟周期数 CPI，就是一条指令到底需要多少 CPU Cycle。
- 指令数，代表执行我们的程序到底需要多少条指令、用哪些指令。这个一般交给了编译器。同样的代码，编译成计算机指令时候，就有各种不同的表示方式；

如果要提升计算机的性能，可以从指令数、CPI 以及 CPU 主频这三个地方入手。要搞定指令数或者 CPI，就在 CPU 上多放一点晶体管，不断提升 CPU 的时钟频率，这样就能让 CPU 变得更快，程序的执行时间就会缩短
 
## 2.2、功耗

早期提升CPU性能，就是堆晶体管；

*为什么奔腾 4 的主频没能超过 3.8GHz 的障碍呢？*因为功耗

功耗问题的直观例子：一个 3.8GHz 的奔腾 4 处理器，满载功率是 130 瓦。这个 130 瓦是什么概念呢？机场允许带上飞机的充电宝的容量上限是 100 瓦时。如果我们把这个 CPU 安在手机里面，不考虑屏幕内存之类的耗电，这个 CPU 满载运行 45 分钟，充电宝里面就没电了。而 iPhone X 使用 ARM 架构的 CPU，功率则只有 4.5 瓦左右；

CPU，一般都被叫作`超大规模集成电路（Very-Large-Scale Integration，VLSI）`。这些电路，实际上都是一个个晶体管组合而成的。CPU 在计算，其实就是让晶体管里面的“开关”不断地去“打开”和“关闭”，来组合完成各种运算和功能，想要计算得快：
- 一方面，我们要在 CPU 里，同样的面积里面，多放一些晶体管，也就是`增加密度`；
- 另一方面，我们要让晶体管“打开”和“关闭”得更快一点，也就是`提升主频`。
 
而这两者，都会增加功耗，带来耗电和散热的问题，因此，在 CPU 里面，能够放下的晶体管数量和晶体管的“开关”频率也都是有限的。一个 CPU 的功率，可以用这样一个公式来表示：

<p align="center"> 功耗 ~= 1/2 × 负载电容 × 电压的平方 × 开关频率 × 晶体管数量 </p>

为了要提升性能：
- 需要不断地增加晶体管数量。同样的面积下，想要多放一点晶体管，就要把晶体管造得小一点。这个就是平时所说的提升“制程”。从 28nm 到 7nm，相当于晶体管本身变成了原来的 1/4 大小；
- 还提升主频，让开关的频率变快；
- 功耗增加太多，就会导致 CPU 散热跟不上，这时，就需要降低电压；在整个功耗的公式里面，功耗和电压的平方是成正比的。这意味着电压下降到原来的 1/5，整个的功耗会变成原来的 1/25；

## 2.3、并行优化与阿姆达尔定律

随着技术的发展，面向[摩尔定律](https://en.wikipedia.org/wiki/Moore%27s_law)编程越来越行不通了，Intel 意识到通过提升主频比较“难”去实现性能提升，边开始推出 Core Duo 这样的多核 CPU，通过提升“吞吐率”而不是“响应时间”，来达到目的；这是一个常见的性能提升方式：通过并行提高性能；

能够使用并行计算，需要满足如下条件：
- 要进行的计算，本身可以分解成几个可以并行的任务。好比上面的乘法和加法计算，几个人可以同时进行，不会影响最后的结果。
- 需要能够分解好问题，并确保几个人的结果能够汇总到一起。
- 在“汇总”这个阶段，是没有办法并行进行的，还是得顺序执行，一步一步来；
 
在进行性能优化中，常常用到的一个经验定律，[阿姆达尔定律（Amdahl’s Law）](https://en.wikipedia.org/wiki/Amdahl%27s_law)。这个定律说的就是，对于一个程序进行优化之后，处理器并行运算之后效率提升的情况。具体可以用这样一个公式来表示：
<p align="center">优化后的执行时间 = 受优化影响的执行时间 / 加速倍数 + 不受影响的执行时间</p>

## 2.4、提升性能原则

- 加速大概率事件；
- 通过流水线提高性能：把 CPU 指令执行的过程进行拆分，细化运行，也是现代 CPU 在主频没有办法提升那么多的情况下，性能仍然可以得到提升的重要原因之一；
- 通过预测提高性能：通过预先猜测下一步该干什么，而不是等上一步运行的结果，提前进行运算，也是让程序跑得更快一点的办法；比如数组的访问；“分支和冒险”、“局部性原理”这些 CPU 和存储系统设计方法，其实都是在利用我们对于未来的“预测”，提前进行相应的操作，来提升我们的程序性能

# 3、指令和运算

## 3.1、计算机指令

- [Instruction Set Architecture](https://en.wikipedia.org/wiki/Instruction_set_architecture)

### 3.1、CPU做了啥

CPU 的全称是 Central Processing Unit，中文是中央处理器：
- 从硬件的角度来看，CPU 就是一个超大规模集成电路，通过电路实现了加法、乘法乃至各种各样的处理逻辑；
- 从软件工程师的角度来讲，CPU 就是一个执行各种计算机指令（Instruction Code）的逻辑机器。这里的计算机指令，就好比一门 CPU 能够听得懂的语言，也可以把它叫作机器语言（Machine Language）

**计算机指令集（ Instruction Set）：**不同的 CPU 能够听懂的语言不太一样，比如，个人电脑用的是 Intel 的 CPU，苹果手机用的是 ARM 的 CPU。这两者能听懂的语言就不太一样。类似这样两种 CPU 各自支持的语言，就是两组不同的计算机指令集；

**存储程序型计算机（Stored-program Computer）：**一个计算机程序，不可能只有一条指令，而是由成千上万条指令组成的。但是 CPU 里不能一直放着所有指令，所以计算机程序平时是存储在存储器中的。这种程序指令存储在存储器里面的计算机，就叫存储程序型计算机

### 3.2、代码如何编程机器码

下面是一段简单的C语言代码：
```c
// test.c
int main()
{
  int a = 1; 
  int b = 2;
  a = a + b;
}
```
如何让这段程序在计算中运行起来：
- 要让这段程序在一个 Linux 操作系统上跑起来，需要把整个程序翻译成一个**汇编语言（ASM，Assembly Language）**的程序，这个过程一般叫**编译（Compile）成汇编代码**；
- 针对汇编代码，可以再用汇编器（Assembler）翻译成机器码（Machine Code）。这些机器码由“0”和“1”组成的机器语言表示。这一条条机器码，就是一条条的**计算机指令**，这样一串串的 16 进制数字，就是CPU 能够真正认识的计算机指令；

**如何生成汇编代码和机器码**

在一个 Linux 操作系统上，可以简单地使用 gcc 和 objdump 这样两条命令，把对应的汇编代码和机器码都打印出来：
```bash
[root@bluefish language]# gcc -g -c test.c
[root@bluefish language]# objdump -d -M intel -S test.o
test.o:     file format elf64-x86-64
Disassembly of section .text:
0000000000000000 <main>:
int main()
{
   0:   55                      push   rbp
   1:   48 89 e5                mov    rbp,rsp
  int a = 1; 
   4:   c7 45 fc 01 00 00 00    mov    DWORD PTR [rbp-0x4],0x1
  int b = 2;
   b:   c7 45 f8 02 00 00 00    mov    DWORD PTR [rbp-0x8],0x2
  a = a + b;
  12:   8b 45 f8                mov    eax,DWORD PTR [rbp-0x8]
  15:   01 45 fc                add    DWORD PTR [rbp-0x4],eax
}
  18:   5d                      pop    rbp
  19:   c3                      ret    
```
左侧有一堆数字，这些就是一条条机器码；右边有一系列的 push、mov、add、pop 等，这些就是对应的汇编代码。一行 C 语言代码，有时候只对应一条机器码和汇编代码，有时候则是对应两条机器码和汇编代码。汇编代码和机器码之间是一一对应的；

汇编代码其实就是“给程序员看的机器码”，也正因为这样，机器码和汇编代码是一一对应的。人类很容易记住 `add、mov` 这些用英文表示的指令，而 `8b 45 f8` 这样的指令，由于很难一下子看明白是在干什么，所以会非常难以记忆

### 3.3、解析指令和机器码

日常用的Intel的CPU大概有2000条左右的CPU指令，常见的指令可以分为如下5类：

指令类型 | 指令描述 | 示例指令 | 示例汇编代码 | 含义 | 注释
--------|----------|---------|-------------|--------|--------
算术类指令|加减乘除，在 CPU 层面，都会变成一条条算术类指令|`add` | `add $s1,$s2,$s3` | `$s1=$s2+$s3`|将s2和s3寄存器中的数相加后的结果放到寄存器s1中
逻辑类指令|逻辑上的与或非，都是这一类指令|`or`|`or $s1,$s2,$s3` | `$s1=$s2\|$s3` | 将s2和s3寄存器中的数按位或后的结果放到寄存器s1中
数据传输类指令|给变量赋值、在内存里读写数据，用的都是数据传输类指令|`load word` | `load $s1,10($s2)` | `$1=memory[$s2+10]`|取s2寄存器中的数，加上10偏移量之后，存入到s2的寄存器中
条件分支类指令|日常我们写的“if/else”，其实都是条件分支类指令|`branch no equal`|`beq $s1,$s2,10`|`if($s1==$s2) go to PC+4+10`|如果s1和s2寄存器的值相等，从程序计数器往后跳10
无条件跳转指令|在调用函数的时候，其实就是发起了一个无条件跳转指令|`jump`|`j 1000`|`go to 1000`|跳转到1000这个目标地址；

**汇编器是怎么把对应的汇编代码，翻译成为机器码的**

- [MIPS指令集-指令学习](https://www.cnblogs.com/Roboduster/p/16158413.html)

不同的 CPU 有不同的指令集，也就对应着不同的汇编语言和不同的机器码，这里采用最简单的[MIPS指令集](https://en.wikipedia.org/wiki/MIPS_architecture)，看看机器码是如何生成的

MIPS 的指令是一个 32 位的整数，高 6 位叫操作码（Opcode），也就是代表这条指令具体是一条什么样的指令，剩下的 26 位有三种格式，分别是 R、I 和 J：

![](image/MIPS指令集-指令类型.png)

- `R 指令`是一般用来做算术和逻辑操作，里面有读取和写入数据的寄存器的地址。如果是逻辑位移操作，后面还有位移操作的位移量，而最后的功能码，则是在前面的操作码不够的时候，扩展操作码表示对应的具体指令的。
- `I 指令`，则通常是用在数据传输、条件分支，以及在运算的时候使用的并非变量还是常数的时候。这个时候，没有了位移量和操作码，也没有了第三个寄存器，而是把这三部分直接合并成了一个地址值或者一个常数。
- `J 指令`就是一个跳转指令，高 6 位之外的 26 位都是一个跳转后的地址；

### 3.4、演示MIPS指令集生成机器码

有指令：`add $t0, $s1, $s2`，转换成机器码，遵循以下步骤，首先确定这是一个R类型指令，其字段如下所示：
- `opcode`（操作码）: 对于所有R类型指令，`opcode`是`000000`。
- `rs`（第一个源寄存器）: `$s1`的编号是17，二进制表示为`10001`。
- `rt`（第二个源寄存器）: `$s2`的编号是18，二进制表示为`10010`。
- `rd`（目标寄存器）: `$t0`的编号是8，二进制表示为`01000`。
- `shamt`（位移量）: 对于`add`指令，这是`00000`，因为这不是位移指令。
- `funct`（功能码）: 对于`add`指令，这是`100000`。

把这些信息组合起来，我们得到这条指令的二进制表示：
```
000000 10001 10010 01000 00000 100000
```
现在，将这个二进制表示转换成十六进制：
- 二进制：`000000 10001 10010 01000 00000 100000`
- 分组（每4位一组，从右到左）：`0000 0010 0011 0010 0100 0000 0010 0000`
- 转换为十六进制：`0x02324020`

因此，MIPS指令 `add $t0, $s1, $s2` 对应的机器码是 `0x02324020`。

## 3.2、CPU如何执行指令

CPU内部是有数以亿计的晶体管组成的，一条条计算机指令的执行非常麻烦，但CPU在软件层面已经封装了，对于软件开发程序员来说，写好的代码变成指令之后，是一条一条顺序执行的；

在逻辑上，可以认为 CPU 其实就是由一堆`寄存器`组成的。而`寄存器`就是 CPU 内部，由多个`触发器（Flip-Flop）`或者`锁存器（Latches）`组成的简单电路，其中`触发器`和`锁存器`是两种不同原理的[数字电路组成的逻辑门](https://en.wikipedia.org/wiki/Logic_gate)；

`N 个触发器或者锁存器`，就可以组成一个 `N 位（Bit）的寄存器`，能够保存 N 位的数据。比方说，用的 64 位 Intel 服务器，寄存器就是 64 位的

![](image/CPU寄存器.png)

一个 CPU 里面会有很多种不同功能的寄存器，下面是三种比较特殊的：
- （1）`PC 寄存器（Program Counter Register）`，也叫`指令地址寄存器（Instruction Address Register）`。顾名思义，它就是用来存放下一条需要执行的计算机指令的内存地址。
- （2）`指令寄存器（Instruction Register）`，用来存放当前正在执行的指令。
- （3）`条件码寄存器（Status Register）`，用里面的一个一个标记位（Flag），存放 CPU 进行算术或者逻辑计算的结果；

除了这些特殊的寄存器，CPU 里面还有更多用来存储数据和内存地址的寄存器。这样的寄存器通常一类里面不止一个。通常根据存放的数据内容来给它们取名字，
- 比如整数寄存器、浮点数寄存器、向量寄存器和地址寄存器等等。
- 有些寄存器既可以存放数据，又能存放地址，我们就叫它通用寄存器

![](image/CPU寄存器与指令对应.png)

**CPU是如何执行指令的？**
- 一个程序执行的时候，CPU 会根据 PC 寄存器里的地址，从内存里面把需要执行的指令读取到指令寄存器里面执行，然后根据指令长度自增，开始顺序读取下一条指令。可以看到，一个程序的一条条指令，在内存里面是连续保存的，也会一条条顺序加载；
- 有些特殊指令，比如 J 类指令，也就是跳转指令，会修改 PC 寄存器里面的地址值。这样，下一条要执行的指令就不是从内存里面顺序加载的了。事实上，这些跳转指令的存在，也是可以在写程序的时候，使用 `if…else` 条件语句和 `while/for` 循环语句的原因；

## 3.3、指令跳转

### 3.3.1、if...else 的指令跳转

看一段简单的代码
```c
// test.c
#include <time.h>
#include <stdlib.h>
int main()
{
  srand(time(NULL));
  int r = rand() % 2;
  int a = 10;
  if (r == 0)
  {
    a = 1;
  } else {
    a = 2;
  }
}
// 执行如下命令
$ gcc -g -c test.c
$ objdump -d -M intel -S test.o 
```
编译之后，忽略除 if...else之外的汇编代码：
```c
    if (r == 0)
  3b:   83 7d fc 00             cmp    DWORD PTR [rbp-0x4],0x0
  3f:   75 09                   jne    4a <main+0x4a>
    {
        a = 1;
  41:   c7 45 f8 01 00 00 00    mov    DWORD PTR [rbp-0x8],0x1
  48:   eb 07                   jmp    51 <main+0x51>
    }
    else
    {
        a = 2;
  4a:   c7 45 f8 02 00 00 00    mov    DWORD PTR [rbp-0x8],0x2
  51:   b8 00 00 00 00          mov    eax,0x0
    } 
```
分析上述汇编代码：
（1）这里对于 `r == 0` 的条件判断，被编译成了 `cmp` 和 `jne` 这两条指令：
- cmp 指令比较了前后两个操作数的值，这里的 `DWORD PTR` 代表操作的数据类型是 32 位的整数，而 `[rbp-0x4]` 则是一个寄存器的地址。所以，第一个操作数就是从寄存器里拿到的变量 r 的值。第二个操作数 `0x0` 就是设定的常量 0 的 16 进制表示。`cmp` 指令的比较结果，会存入到`条件码寄存器`当中去；<br/>
  如果比较的结果是 True，也就是 r == 0，就把`零标志条件码`（对应的条件码是 ZF，`Zero Flag`）设置为 1。除了零标志之外，Intel 的 CPU 下还有`进位标志`（CF，Carry Flag）、`符号标志`（SF，Sign Flag）以及`溢出标志`（OF，Overflow Flag），用在不同的判断条件下；

- cmp 指令执行完成之后，PC 寄存器会自动自增，开始执行下一条 jne 的指令； jne 指令，是` jump if not equal` 的意思，它会查看对应的零标志位。
  - 如果为 0，会跳转到后面跟着的操作数 4a 的位置。这个 4a，对应这里汇编代码的行号，也就是上面设置的 else 条件里的第一条指令。当跳转发生的时候，PC 寄存器就不再是自增变成下一条指令的地址，而是被直接设置成这里的 4a 这个地址。这个时候，CPU 再把 4a 地址里的指令加载到指令寄存器中来执行；

    跳转到执行地址为 4a 的指令，实际是一条 mov 指令，第一个操作数和前面的 cmp 指令一样，是另一个 32 位整型的寄存器地址，以及对应的 2 的 16 进制值 0x2。mov 指令把 2 设置到对应的寄存器里去，相当于一个赋值操作。然后，PC 寄存器里的值继续自增，执行下一条 mov 指令； mov 指令的第一个操作数 eax，代表累加寄存器，第二个操作数 0x0 则是 16 进制的 0 的表示。这条指令其实没有实际的作用，它的作用是一个占位符

  - 如果if条件满足的话，在赋值的 mov 指令（位置：41）执行完成之后，有一个 jmp 的无条件跳转指令。跳转的地址就是这一行的地址 51。 main 函数没有设定返回值，而 mov eax, 0x0 其实就是给 main 函数生成了一个默认的为 0 的返回值到累加器里面。if 条件里面的内容执行完成之后也会跳转到这里，和 else 里的内容结束之后的位置是一样的

![](image/CPU指令-if-else指令执行过程.png)

### 3.3.2、如何实现循环

CPU指令来实现循序一般是通过  `if…else` 和 `goto` 来实现循环，如何实现？看一段代码：
```c
int main()
{
    int a = 0;
    for (int i = 0; i < 3; i++)
    {
        a += i;
    }
}
```
编译成汇编代码之后：
```c
    for (int i = 0; i < 3; i++)
   b:   c7 45 f8 00 00 00 00    mov    DWORD PTR [rbp-0x8],0x0
  12:   eb 0a                   jmp    1e <main+0x1e>
    {
        a += i;
  14:   8b 45 f8                mov    eax,DWORD PTR [rbp-0x8]
  17:   01 45 fc                add    DWORD PTR [rbp-0x4],eax
    for (int i = 0; i < 3; i++)
  1a:   83 45 f8 01             add    DWORD PTR [rbp-0x8],0x1
  1e:   83 7d f8 02             cmp    DWORD PTR [rbp-0x8],0x2
  22:   7e f0                   jle    14 <main+0x14>
  24:   b8 00 00 00 00          mov    eax,0x0
    }
```
对应的循环也是用 1e 这个地址上的 cmp 比较指令，和紧接着的 `jle` 条件跳转指令来实现的。主要的差别在于，这里的 jle 跳转的地址，在这条指令之前的地址 `14`，而非 `if…else` 编译出来的跳转指令之后。往前跳转使得条件满足的时候，PC 寄存器会把指令地址设置到之前执行过的指令位置，重新执行之前执行过的指令，直到条件不满足，顺序往下执行 jle 之后的指令，整个循环才结束

![](image/CPU指令-循环指令执行过程.png)

jle 和 jmp 指令，有点像程序语言里面的 goto 命令，直接指定了一个特定条件下的跳转位置；想要在硬件层面实现这个 goto 语句，除了本身需要用来保存下一条指令地址，以及当前正要执行指令的 PC 寄存器、指令寄存器外，只需要再增加一个`条件码寄存器`，来保留条件判断的状态。这样简简单单的三个寄存器，就可以实现条件判断和循环重复执行代码的功能

## 3.4、函数调用

- [程序栈压栈和出栈](https://manybutfinite.com/post/journey-to-the-stack/)
- [程序栈压栈和出栈](https://manybutfinite.com/post/epilogues-canaries-buffer-overflows/)

### 3.4.1、为什么需要程序栈

先看一段代码：
```c
// function_example.c
#include <stdio.h>
int static add(int a, int b)
{
    return a+b;
}
int main()
{
    int x = 5;
    int y = 10;
    int u = add(x, y);
}
```
把这个程序编译之后，objdump 出来。我们来看一看对应的汇编代码
```
$ gcc -g -c function_example.c
$ objdump -d -M intel -S function_example.o
```
对应的汇编代码如下：
```c
function_example.o:     file format elf64-x86-64
Disassembly of section .text:
0000000000000000 <add>:
// function_example.c
int static add(int a, int b)
{
   0:   55                      push   rbp
   1:   48 89 e5                mov    rbp,rsp
   4:   89 7d fc                mov    DWORD PTR [rbp-0x4],edi
   7:   89 75 f8                mov    DWORD PTR [rbp-0x8],esi
    return a+b;
   a:   8b 55 fc                mov    edx,DWORD PTR [rbp-0x4]
   d:   8b 45 f8                mov    eax,DWORD PTR [rbp-0x8]
  10:   01 d0                   add    eax,edx
}
  12:   5d                      pop    rbp
  13:   c3                      ret    
0000000000000014 <main>:
int main()
{
  14:   55                      push   rbp
  15:   48 89 e5                mov    rbp,rsp
  18:   48 83 ec 10             sub    rsp,0x10
    int x = 5;
  1c:   c7 45 fc 05 00 00 00    mov    DWORD PTR [rbp-0x4],0x5
    int y = 10;
  23:   c7 45 f8 0a 00 00 00    mov    DWORD PTR [rbp-0x8],0xa
    int u = add(x, y);
  2a:   8b 55 f8                mov    edx,DWORD PTR [rbp-0x8]
  2d:   8b 45 fc                mov    eax,DWORD PTR [rbp-0x4]
  30:   89 d6                   mov    esi,edx
  32:   89 c7                   mov    edi,eax
  34:   e8 c7 ff ff ff          call   0 <add>
  39:   89 45 f4                mov    DWORD PTR [rbp-0xc],eax
  3c:   b8 00 00 00 00          mov    eax,0x0
}
  41:   c9                      leave  
  42:   c3                      ret 
```
跟前面的汇编代码主要区别是：把 `jump` 指令换成了函数调用的 `call` 指令。 `call` 指令后面跟着的，仍然是跳转后的程序地址

先看add函数，add 函数编译之后，代码先执行了一条 push 指令和一条 mov 指令；在函数执行结束的时候，又执行了一条 pop 和一条 ret 指令。这四条指令的执行，其实就是在进行要讲`压栈（Push）`和`出栈（Pop）`操作。

函数调用和 `if…else` 和 `for/while` 循环有点像，它们两个都是在原来顺序执行的指令过程里，执行了一个内存地址的跳转指令，让指令从原来顺序执行的过程里跳开，从新的跳转后的位置开始执行；
- `if…else` 和 `for/while` 的跳转，是跳转走了就不再回来了，就在跳转后的新地址开始顺序地执行指令；
- 函数调用的跳转，在对应函数的指令执行完了之后，还要再回到函数调用的地方，继续执行 call 之后的指令；

  思考：有没有一个可以不跳转回到原来开始的地方，来实现函数的调用呢？可以把调用的函数指令，直接插入在调用函数的地方，替换掉对应的 call 指令，然后在编译器编译代码的时候，直接就把函数调用变成对应的指令替换掉；不过，仔细琢磨一下，会发现这个方法有些问题：如果函数 A 调用了函数 B，然后函数 B 再调用函数 A，就得面临在 A 里面插入 B 的指令，然后在 B 里面插入 A 的指令，这样就会产生无穷无尽地替换。就好像两面镜子面对面放在一块儿，任何一面镜子里面都会看到无穷多面镜子

函数的跳转是单独在内存中开辟一块空间，用栈这个后进先出（LIFO，Last In First Out）的数据结构，栈就像一个乒乓球桶：
- 每次程序调用函数之前，都把调用返回后的地址写在一个乒乓球上，然后塞进这个球桶。这个操作其实就是常说的`压栈`。
- 如果函数执行完了，就从球桶里取出最上面的那个乒乓球，很显然，这就是`出栈`；

在真实的程序里，压栈的不只有函数调用完成后的返回地址。比如函数 A 在调用 B 的时候，需要传输一些参数数据，这些参数数据在寄存器不够用的时候也会被压入栈中。整个函数 A 所占用的所有内存空间，就是函数 A 的`栈帧（Stack Frame）`

而实际的程序栈布局，顶和底与我们的乒乓球桶相比是倒过来的。底在最上面，顶在最下面，这样的布局是因为栈底的内存地址是在一开始就固定的。而一层层压栈之后，栈顶的内存地址是在逐渐变小而不是变大；

![](image/CPU指令-函数调用-压栈出栈过程.png)

对应上面的汇编代码，main 函数调用 add 函数时，add 函数入口在 0～1 行，add 函数结束之后在 12～13 行：
- 调用第 34 行的 call 指令时，会把当前的 PC 寄存器里的下一条指令的地址压栈，保留函数调用结束后要执行的指令地址；而 add 函数的第 0 行，`push rbp` 这个指令，就是在进行`压栈`。这里的` rbp 又叫栈帧指针（Frame Pointer）`，是一个存放了`当前栈帧位置的寄存器`。`push rbp` 就把之前调用函数，也就是 main 函数的栈帧的栈底地址，压到栈顶；
- 接着，第 1 行的一条命令 `mov rbp, rsp` 里，则是把 `rsp` 这个栈指针（Stack Pointer）的值复制到 `rbp` 里，而 `rsp 始终会指向栈顶`。这个命令意味着，`rbp 这个栈帧指针指向的地址`，变成当前最新的栈顶，也就是 add 函数的栈帧的栈底地址了；
- 在函数 add 执行完成之后，又会分别调用第 12 行的 pop rbp 来将当前的栈顶出栈，这部分操作维护好了我们整个栈帧。然后，我们可以调用第 13 行的 ret 指令，这时候同时要把 call 调用的时候压入的 PC 寄存器里的下一条指令出栈，更新到 PC 寄存器中，将程序的控制权返回到出栈后的栈顶

**如何构造一个 stack overflow**

通过引入栈，可以看到，无论有多少层的函数调用，或者在函数 A 里调用函数 B，再在函数 B 里调用 A，这样的递归调用，都只需要通过维持 rbp 和 rsp，这两个维护栈顶所在地址的寄存器，就能管理好不同函数之间的跳转。不过，栈的大小也是有限的。如果函数调用层数太多，往栈里压入它存不下的内容，程序在执行的过程中就会遇到栈溢出的错误，这就是“stack overflow”

### 3.4.2、如何利用函数内联进行性能优化

前面提到把一个实际调用的函数产生的指令，直接插入到的位置，来替换对应的函数调用指令。尽管这个通用的函数调用方案，不适用，但是如果被调用的函数里，没有调用其他函数，这个方法还是可以行得通的；

这就是一个常见的编译器进行自动优化的场景，我们通常叫函数内联（Inline）；只要在 GCC 编译的时候，加上对应的一个让编译器自动优化的参数 -O，编译器就会在可行的情况下，进行这样的指令替换
```c
// function_example_inline.c
#include <stdio.h>
#include <time.h>
#include <stdlib.h>
 
int static add(int a, int b)
{
    return a+b;
}
int main()
{
    srand(time(NULL));
    int x = rand() % 5;
    int y = rand() % 10;
    int u = add(x, y);
    printf("u = %d\n", u)
}
// 编译命令：
$ gcc -g -c -O function_example_inline.c
$ objdump -d -M intel -S function_example_inline.o
```
汇编代码：上面的 function_example_inline.c 的编译出来的汇编代码，没有把 add 函数单独编译成一段指令顺序，而是在调用 u = add(x, y) 的时候，直接替换成了一个 add 指令。
```c
 return a+b;
  4c:   01 de                   add    esi,ebx
```
内联带来的优化是，CPU 需要执行的指令数变少了，根据地址跳转的过程不需要了，压栈和出栈的过程也不用了。

不过内联并不是没有代价，内联意味着，把可以复用的程序指令在调用它的地方完全展开了。如果一个函数在很多地方都被调用了，那么就会展开很多次，整个程序占用的空间就会变大了，这样没有调用其他函数，只会被调用的函数，我们一般称之为**叶子函数（或叶子过程）**。

## 3.5、ELF和静态链接

既然程序最终都被变成了一条条机器码去执行，那为什么同一个程序，在同一台计算机上，在 Linux 下可以运行，而在 Windows 下却不行呢？反过来，Windows 上的程序在 Linux 上也是一样不能执行的。可是CPU 并没有换掉，它应该可以识别同样的指令呀？

### 3.5.1、编译、链接和装载

C语言程序是如何变成一个可执行程序的？有如下两段代码：
```c
// add_lib.c
int add(int a, int b)
{
    return a+b;
}
// link_example.c
#include <stdio.h>
int main()
{
    int a = 10;
    int b = 5;
    int c = add(a, b);
    printf("c = %d\n", c);
}
```
通过 gcc 来编译这两个文件，然后通过 objdump 命令看看它们的汇编代码
```bash
[root@bluefish language]# gcc -g -c add_lib.c link_example.c
[root@bluefish language]# objdump -d -M intel -S add_lib.o
add_lib.o:     file format elf64-x86-64
Disassembly of section .text:
0000000000000000 <add>:
   0:   55                      push   rbp
   1:   48 89 e5                mov    rbp,rsp
   4:   89 7d fc                mov    DWORD PTR [rbp-0x4],edi
   7:   89 75 f8                mov    DWORD PTR [rbp-0x8],esi
   a:   8b 55 fc                mov    edx,DWORD PTR [rbp-0x4]
   d:   8b 45 f8                mov    eax,DWORD PTR [rbp-0x8]
  10:   01 d0                   add    eax,edx
  12:   5d                      pop    rbp
  13:   c3                      ret    
[root@bluefish language]# objdump -d -M intel -S link_example.o
link_example.o:     file format elf64-x86-64
Disassembly of section .text:
0000000000000000 <main>:
   0:   55                      push   rbp
   1:   48 89 e5                mov    rbp,rsp
   4:   48 83 ec 10             sub    rsp,0x10
   8:   c7 45 fc 0a 00 00 00    mov    DWORD PTR [rbp-0x4],0xa
   f:   c7 45 f8 05 00 00 00    mov    DWORD PTR [rbp-0x8],0x5
  16:   8b 55 f8                mov    edx,DWORD PTR [rbp-0x8]
  19:   8b 45 fc                mov    eax,DWORD PTR [rbp-0x4]
  1c:   89 d6                   mov    esi,edx
  1e:   89 c7                   mov    edi,eax
  20:   b8 00 00 00 00          mov    eax,0x0
  25:   e8 00 00 00 00          call   2a <main+0x2a>
  2a:   89 45 f4                mov    DWORD PTR [rbp-0xc],eax
  2d:   8b 45 f4                mov    eax,DWORD PTR [rbp-0xc]
  30:   89 c6                   mov    esi,eax
  32:   48 8d 3d 00 00 00 00    lea    rdi,[rip+0x0]        # 39 <main+0x39>
  39:   b8 00 00 00 00          mov    eax,0x0
  3e:   e8 00 00 00 00          call   43 <main+0x43>
  43:   b8 00 00 00 00          mov    eax,0x0
  48:   c9                      leave  
  49:   c3                      ret    
```
既然代码已经“编译”成了指令，不妨尝试运行一下 `./link_example.o`。不幸的是，文件没有执行权限，遇到一个 Permission denied 错误。即使通过 chmod 命令赋予 link_example.o 文件可执行的权限，运行`./link_example.o` 仍然只会得到一条 `cannot execute binary file: Exec format error` 的错误；objdump出来的两个程序的地址都是从 0开始的，如果地址是一样的，程序如果需要通过 call 指令调用函数的话，它怎么知道应该跳转到哪一个文件里呢？

无论是这里的运行报错，还是 objdump 出来的汇编代码里面的重复地址，都是因为 add_lib.o 以及 link_example.o 并不是一个`可执行文件（Executable Program）`，而是·。只有通过链接器（Linker）把多个目标文件以及调用的各种函数库链接起来，才能得到一个可执行文件：
```bash
$ gcc -o link-example add_lib.o link_example.o
$ ./link_example
c = 15
```
**C 语言代码 - 汇编代码 - 机器码** 这个过程，在计算机上进行的时候是由两部分组成的：
- 第一个部分由编译（Compile）、汇编（Assemble）以及链接（Link）三个阶段组成。在这三个阶段完成之后，就生成了一个可执行文件；
- 第二部分，通过装载器（Loader）把可执行文件装载（Load）到内存中。CPU 从内存中读取指令和数据，来开始真正执行程序

![](image/C语言装载-执行过程.png)

### 3.5.2、ELF 格式和链接

程序最终是通过装载器变成指令和数据的，所以其实生成的可执行代码也并不仅仅是一条条的指令。通过 objdump 指令，把`可执行文件`的内容拿出来看看：
```bash
[root@bluefish language]# objdump -d -M intel -S link-example
link-example:     file format elf64-x86-64

Disassembly of section .init:
...
Disassembly of section .plt:
...
Disassembly of section .text:
...

000000000040052d <add>:
int add(int a, int b)
{
  40052d:	55                   	push   rbp
  40052e:	48 89 e5             	mov    rbp,rsp
  400531:	89 7d fc             	mov    DWORD PTR [rbp-0x4],edi
  400534:	89 75 f8             	mov    DWORD PTR [rbp-0x8],esi
    return a+b;
  400537:	8b 45 f8             	mov    eax,DWORD PTR [rbp-0x8]
  40053a:	8b 55 fc             	mov    edx,DWORD PTR [rbp-0x4]
  40053d:	01 d0                	add    eax,edx
}
  40053f:	5d                   	pop    rbp
  400540:	c3                   	ret    

0000000000400541 <main>:
#include <stdio.h>
int main()
{
  400541:	55                   	push   rbp
  400542:	48 89 e5             	mov    rbp,rsp
  400545:	48 83 ec 10          	sub    rsp,0x10
    int a = 10;
  400549:	c7 45 fc 0a 00 00 00 	mov    DWORD PTR [rbp-0x4],0xa
    int b = 5;
  400550:	c7 45 f8 05 00 00 00 	mov    DWORD PTR [rbp-0x8],0x5
    int c = add(a, b);
  400557:	8b 55 f8             	mov    edx,DWORD PTR [rbp-0x8]
  40055a:	8b 45 fc             	mov    eax,DWORD PTR [rbp-0x4]
  40055d:	89 d6                	mov    esi,edx
  40055f:	89 c7                	mov    edi,eax
  400561:	b8 00 00 00 00       	mov    eax,0x0
  400566:	e8 c2 ff ff ff       	call   40052d <add>
  40056b:	89 45 f4             	mov    DWORD PTR [rbp-0xc],eax
    printf("c = %d\n", c);
  40056e:	8b 45 f4             	mov    eax,DWORD PTR [rbp-0xc]
  400571:	89 c6                	mov    esi,eax
  400573:	bf 20 06 40 00       	mov    edi,0x400620
  400578:	b8 00 00 00 00       	mov    eax,0x0
  40057d:	e8 8e fe ff ff       	call   400410 <printf@plt>
}
  400582:	c9                   	leave  
  400583:	c3                   	ret    
  400584:	66 2e 0f 1f 84 00 00 	nop    WORD PTR cs:[rax+rax*1+0x0]
  40058b:	00 00 00 
  40058e:	66 90                	xchg   ax,ax
...

Disassembly of section .fini:
...
```
在 Linux 下，可执行文件和目标文件所使用的都是一种叫`ELF（Execuatable and Linkable File Format）`的文件格式，中文名字叫`可执行与可链接文件格式`，这里面不仅存放了编译成的汇编指令，还保留了很多别的数据；

**符号表：** 像 add、main 等等，乃至自己定义的全局可以访问的变量名称，都存放在这个 ELF 格式文件里。这些名字和它们对应的地址，在 ELF 文件里面，存储在一个叫作`符号表（Symbols Table）`的位置里。符号表相当于一个地址簿，把名字和地址关联了起来；

main 函数里调用 add 的跳转地址，不再是下一条指令的地址了，而是 add 函数的入口地址了，这就是 EFL 格式和链接器的功劳；

![](image/Linux-ELF文件格式.png)

**ELF文件格式**

ELF 文件格式把各种信息，分成一个一个的 Section 保存起来。ELF 有一个基本的文件头（File Header），用来表示这个文件的基本属性，比如是否是可执行文件，对应的 CPU、操作系统等等。除了这些基本属性之外，大部分程序还有这么一些 Section：
- 首先是`.text Section`，也叫作`代码段`或者指令段（Code Section），用来保存程序的代码和指令；
- 接着是`.data Section`，也叫作`数据段`（Data Section），用来保存程序里面设置好的初始化数据信息；
- 然后就是`.rel.text Secion`，叫作`重定位表`（Relocation Table）。重定位表里，保留的是当前的文件里面，哪些跳转地址其实是不知道的。比如上面的 link_example.o 里面，在 main 函数里面调用了 add 和 printf 这两个函数，但是在链接发生之前，并不知道该跳转到哪里，这些信息就会存储在重定位表里；
- 最后是`.symtab Section`，叫作`符号表`（Symbol Table）。符号表保留了当前文件里面定义的函数名称和对应地址的地址簿。

**可执行文件生成过程：**
- 链接器会扫描所有输入的目标文件，然后把所有符号表里的信息收集起来，构成一个全局的符号表。
- 然后再根据重定位表，把所有不确定要跳转地址的代码，根据符号表里面存储的地址，进行一次修正。
- 最后，把所有的目标文件的对应段进行一次合并，变成了最终的可执行代码。这也是为什么，可执行文件里面的函数调用的地址都是正确的；

在链接器把程序变成可执行文件之后，要装载器去执行程序就容易多了。装载器不再需要考虑地址跳转的问题，只需要解析 ELF 文件，把对应的指令和数据，加载到内存里面供 CPU 执行就可以了

![](image/Linux-ELF文件-生成链接过程.png)

**为什么同样一个程序，在 Linux 下可以执行而在 Windows 下不能执行了。其中一个非常重要的原因就是，两个操作系统下可执行文件的格式不一样**

## 3.6、程序分页装载

### 3.6.1、程序装载的挑战

可执行文件运行时，实际上是通过一个装载器，解析 ELF 或者 PE 格式的可执行文件。装载器会把对应的指令和数据加载到内存里面来，让 CPU 去执行；

**装载器需要满足两个要求：**
- 执行程序加载后占用的内存空间应该是连续的：执行指令的时候，程序计数器是顺序地一条一条指令执行下去。这也就意味着，这一条条指令需要连续地存储在一起；
- 需要同时加载很多个程序，并且不能让程序自己规定在内存中加载的位置，虽然编译出来的指令里已经有了对应的各种各样的内存地址，但是实际加载的时候，没有办法确保，这个程序一定加载在哪一段内存地址上。因为现在的计算机通常会同时运行很多个程序，可能你想要的内存地址已经被其他加载了的程序占用了；

**如何满足上述条件：**

可以在内存里面，找到一段连续的内存空间，然后分配给装载的程序，然后把这段连续的内存空间地址，和整个程序指令里指定的内存地址做一个映射：
- 指令里用到的内存地址叫作`虚拟内存地址`（Virtual Memory Address）；
- 实际在内存硬件里面的空间地址，叫`物理内存地址`（Physical Memory Address；

程序里有指令和各种内存地址，只需要关心虚拟内存地址就行了。对于任何一个程序来说，它看到的都是同样的内存地址。

维护一个虚拟内存到物理内存的映射表，这样实际程序指令执行的时候，会通过虚拟内存地址，找到对应的物理内存地址，然后执行。因为是连续的内存地址空间，所以只需要维护映射关系的`起始地址`和`对应的空间大小`即可

### 3.6.2、内存分段

找出一段连续的物理内存和虚拟内存地址进行映射的方法，叫**分段（Segmentation）**。这里的段，就是指系统分配出来的那个连续的`内存空间`；

![](image/内存分段.png)

分段的优缺点：
- 优点：解决了程序本身不需要关心具体的物理内存地址的问题；
- 缺点：其中一个就是内存碎片（Memory Fragmentation）的问题

比如：我现在手头的这台电脑，有 1GB 的内存。<br/>
（1）我们先启动一个图形渲染程序，占用了 512MB 的内存，接着启动一个 Chrome 浏览器，占用了 128MB 内存，再启动一个 Python 程序，占用了 256MB 内存。<br/>
（2）这个时候，关掉 Chrome，于是空闲内存还有 1024 - 512 - 256 = 256MB。按理来说，我们有足够的空间再去装载一个 200MB 的程序。但是，这 256MB 的内存空间不是连续的，而是被分成了两段 128MB 的内存。因此，实际情况是，我们的程序没办法加载进来；

![](image/内存分段的问题.png)

上面问题的解决办法：`内存交换（Memory Swapping）` —— 可以把 Python 程序占用的那 256MB 内存写到硬盘上，然后再从硬盘上读回来到内存里面。不过读回来的时候，不再把它加载到原来的位置，而是紧紧跟在那已经被占用了的 512MB 内存后面。这样，就有了连续的 256MB 内存空间，就可以去加载一个新的 200MB 的程序

**总结：**

`虚拟内存`、`分段`，再加上`内存交换`，看起来似乎已经解决了计算机同时装载运行很多个程序的问题。不过，这三者的组合仍然会遇到一个性能瓶颈：硬盘的访问速度要比内存慢很多，而每一次内存交换，都需要把一大段连续的内存数据写到硬盘上。
> 所以，如果内存交换的时候，交换的是一个很占内存空间的程序，这样整个机器都会显得卡顿；

### 3.6.2、内存分页

解决问题的思路：问题出在内存碎片和内存交换的空间太大上，解决问题的办法：
- 少出现一些内存碎片；
- 当需要进行内存交换的时候，让需要交换写入或者从磁盘装载的数据更少一点

上面解决问题的办法：在现在计算机的内存管理里面，就叫作`内存分页（Paging）`，和分段这样分配一整段连续的空间给到程序相比，`分页是把整个物理内存空间切成一段段固定尺寸的大小`，对应的程序所需要占用的虚拟内存空间，也会同样切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间，叫`页（Page）`；

![](image/内存分页.png)

从虚拟内存到物理内存的映射，不再是拿整段连续的内存的物理地址，而是按照一个一个页来的。页的尺寸一般远远小于整个程序的大小。

在 Linux 下，通常只设置成 4KB。可以通过命令看看 Linux 系统设置的页的大小：
```bash
[root@bluefish ~]# getconf PAGE_SIZE
4096
```
- 由于内存空间都是预先划分好的，也就没有了不能使用的碎片，而只有被释放出来的很多 4KB 的页。即使内存空间不够，需要让现有的、正在运行的其他程序，通过内存交换释放出一些内存的页出来，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，让整个机器被内存交换的过程给卡住；
- 分页的方式使得在加载程序的时候，不再需要一次性都把程序加载到物理内存中。完全可以在进行虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存里，而是只在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去；

**缺页错误：**

操作系统也是这么干的：当要读取特定的页，却发现数据并没有加载到物理内存里的时候，就会触发一个来自于 CPU 的缺页错误（Page Fault）。操作系统会捕捉到这个错误，然后将对应的页，从存放在硬盘上的虚拟内存里读取出来，加载到物理内存里。这种方式，使得我们可以运行那些远大于我们实际物理内存的程序。同时，这样一来，任何程序都不需要一次性加载完所有指令和数据，只需要加载当前需要用到就行了

通过虚拟内存、内存交换和内存分页这三个技术的组合，最终得到了一个让程序不需要考虑实际的物理内存地址、大小和当前分配空间的解决方案。这些技术和方法，对于程序的编写、编译和链接过程都是透明的。这也是我们在计算机的软硬件开发中常用的一种方法，就是`加入一个间接层`；

> 总结：通过引入虚拟内存、页映射和内存交换，程序本身不再需要考虑对应的真实的内存地址、程序加载、内存管理等问题了。任何一个程序，都只需要把内存当成是一块完整而连续的空间来直接使用

？在 Java 这样使用虚拟机的编程语言里面，我们写的程序是怎么装载到内存里面来的呢？jvm已经是上层应用，无需考虑物理分页，一般更直接是考虑对象本身的空间大小，物理硬件管理统一由承载jvm的操纵系统去解决吧

## 3.7、动态链接

程序的链接，是把对应的不同文件内的代码段，合并到一起，成为最后的可执行文件。这个链接的方式，在写代码的时候能做到“复用”。同样的功能代码只要写一次，然后提供给很多不同的程序进行链接就行了；

但是，如果有很多个程序都要通过装载器装载到内存里面，那里面链接好的同样的功能代码，也都需要再装载一遍，再占一遍内存空间

### 3.7.1、动态链接与静态链接

程序装载到内存的时候，最根本的问题是：**内存不够用**；如果能够让同样功能的代码，在不同的程序里面，不需要各占一份内存空间，那该有多好啊；

这个思路引入了一个新的链接方法：**动态链接（Dynamic Link）**。相应的，之前说的合并代码段的方法，就是**静态链接（Static Link）**

在动态链接的过程中，想要“链接”的，不是存储在硬盘上的目标文件代码，而是加载到内存中的**共享库（Shared Libraries）**。顾名思义，这里的共享库重在“共享“这两个字；这个加载到内存中的共享库会被很多个程序的指令调用到：
- 在 Windows 下，这些共享库文件就是`.dll` 文件，也就是 **Dynamic-Link Libary（DLL，动态链接库）**；
- 在 Linux 下，这些共享库文件就是`.so` 文件，也就是 **Shared Object（一般称之为动态链接库）**；

![](image/链接-动态链接示意图.png)

### 3.7.2、地址无关

要想要在程序运行的时候共享代码，也有一定的要求，就是这些机器码必须是**地址无关**的。也就是说，编译出来的共享库文件的指令代码，是**地址无关码（Position-Independent Code）**。换句话说就是，这段代码，无论加载在哪个内存地址，都能够正常执行。如果不是这样的代码，就是**地址相关**的代码；

举个例子：
- 如果我们有一个骑自行车的程序，要“前进 500 米，左转进入天安门广场，再前进 500 米”。它在 500 米之后要到天安门广场了，这就是**地址相关**的；
- 如果程序是“前进 500 米，左转，再前进 500 米”，无论你在哪里都可以骑车走这 1000 米，没有具体地点的限制，这就是**地址无关**的

![](image/链接-动态链接地址无关.png)

**地址相关**和**地址无关**：
- 部分函数库其实都可以做到地址无关，因为它们都接受特定的输入，进行确定的操作，然后给出返回结果就好了；
- 常见的地址相关的代码，比如绝对地址代码（Absolute Code）、利用重定位表的代码等等，都是地址相关的代码；

**共享库的物理地址和虚拟地址：**
- 对于所有动态链接共享库的程序来讲，共享库用的都是同一段物理内存地址；
- 在不同的应用程序里，它所在的虚拟内存地址是不同的；
- 没办法、也不应该要求动态链接同一个共享库的不同程序，必须把这个共享库所使用的虚拟内存地址变成一致；

如何实现：动态共享库编译出来的代码指令，都是地址无关码呢？
- 动态代码库内部的变量和函数调用 只需要使用**相对地址（Relative Address）**就好了。
- 各种指令中使用到的内存地址，给出的不是一个绝对的地址空间，而是一个相对于当前指令偏移量的内存地址。因为整个共享库是放在一段连续的虚拟内存地址中的，无论装载到哪一段地址，不同指令之间的相对地址都是不变的;

### 3.7.3、动态链接的解决方案

看代码示例：
```c
// lib.h：定义了动态链接库的一个函数 show_me_the_money
#ifndef LIB_H
#define LIB_H
void show_me_the_money(int money);

#endif

// lib.c 包含了 lib.h 的实际实现
#include <stdio.h>
void show_me_the_money(int money)
{
    printf("Show me USD %d from lib.c \n", money);
}

// show_me_poor.c 调用了 lib 里面的函数
#include "lib.h"
int main()
{
    int money = 5;
    show_me_the_money(money);
}
// 把 lib.c 编译成了一个动态链接库，也就是 .so 文件
$ gcc lib.c -fPIC -shared -o lib.so
$ gcc -o show_me_poor show_me_poor.c ./lib.so
```
在编译的过程中，我们指定了一个 **`-fPIC`** 的参数。这个参数其实就是 `Position Independent Code` 的意思，也就是要把这个编译成一个地址无关代码；

再通过 gcc 编译 show_me_poor 动态链接了 lib.so 的可执行文件。在这些操作都完成了之后，把 show_me_poor 这个文件通过 objdump 出来看一下：
```bash
$ objdump -d -M intel -S show_me_poor
……
0000000000400540 <show_me_the_money@plt-0x10>:
  400540:       ff 35 12 05 20 00       push   QWORD PTR [rip+0x200512]        # 600a58 <_GLOBAL_OFFSET_TABLE_+0x8>
  400546:       ff 25 14 05 20 00       jmp    QWORD PTR [rip+0x200514]        # 600a60 <_GLOBAL_OFFSET_TABLE_+0x10>
  40054c:       0f 1f 40 00             nop    DWORD PTR [rax+0x0]
 
0000000000400550 <show_me_the_money@plt>:
  400550:       ff 25 12 05 20 00       jmp    QWORD PTR [rip+0x200512]        # 600a68 <_GLOBAL_OFFSET_TABLE_+0x18>
  400556:       68 00 00 00 00          push   0x0
  40055b:       e9 e0 ff ff ff          jmp    400540 <_init+0x28>
……
0000000000400676 <main>:
  400676:       55                      push   rbp
  400677:       48 89 e5                mov    rbp,rsp
  40067a:       48 83 ec 10             sub    rsp,0x10
  40067e:       c7 45 fc 05 00 00 00    mov    DWORD PTR [rbp-0x4],0x5
  400685:       8b 45 fc                mov    eax,DWORD PTR [rbp-0x4]
  400688:       89 c7                   mov    edi,eax
  40068a:       e8 c1 fe ff ff          call   400550 <show_me_the_money@plt>
  40068f:       c9                      leave  
  400690:       c3                      ret    
  400691:       66 2e 0f 1f 84 00 00    nop    WORD PTR cs:[rax+rax*1+0x0]
  400698:       00 00 00 
  40069b:       0f 1f 44 00 00          nop    DWORD PTR [rax+rax*1+0x0]
……
```
可以看到，在 main 函数调用 show_me_the_money 的函数的时候，对应的代码是这样的：`400550 <show_me_the_money@plt>`，这里后面有一个 `@plt` 的关键字，代表了需要从 `PLT`，也就是**程序链接表（Procedure Link Table）**里面找要调用的函数。对应的地址呢，则是 400550 这个地址:
```
400550:       ff 25 12 05 20 00       jmp    QWORD PTR [rip+0x200512]        # 600a68 <_GLOBAL_OFFSET_TABLE_+0x18>
```
在动态链接对应的共享库，在共享库的 data section 里面，保存了一张**全局偏移表（GOT，Global Offset Table**）。虽然共享库的代码部分的物理内存是共享的，但是数据部分是各个动态链接它的应用程序里面各加载一份的。所有需要引用当前共享库外部的地址的指令，都会查询 GOT，来找到当前运行程序的虚拟内存里的对应位置。而 GOT 表里的数据，则是在加载一个个共享库的时候写进去的

不同的进程，调用同样的 lib.so，各自 GOT 里面指向最终加载的动态链接库里面的虚拟内存地址是不同的。

![](image/链接-动态链接GOT.png)

**GOT表如何做到无地址：**

GOT 表位于共享库自己的数据段里。GOT 表在内存里和对应的代码段位置之间的偏移量，始终是确定的。这样，共享库就是地址无关的代码，对应的各个程序只需要在物理内存里面加载同一份代码。而又要通过各个可执行程序在加载时，生成的各不相同的 GOT 表，来找到它需要调用到的外部变量和函数的地址；

> 总结：通过**程序链接表（Procedure Link Table）** 和 **全局偏移表（GOT，Global Offset Table**） 实现了动态链接；

## 3.8、二进制编码

### 3.8.1、二进制

- [进制基础](../Java/Java基础/Java基础知识.md#三进制基础)

### 3.8.2、字符串表示

- [字符集和字符编码](../Java/Java基础/Java扩展.md#三字符集与字符编码)

## 3.9、理解电路：门电路

电报是现代计算机的一个最简单的原型。它和现在使用的现代计算机有很多相似之处。通过电路的“开”和“关”，来表示“1”和“0”。就像晶体管在不同的情况下，表现为导电的“1”和绝缘的“0”的状态；

如何通过“螺旋线圈 + 开关”，来构造基本的逻辑电路，也叫**门电路**：在计算机硬件层面最基本的单元
- 一方面，可以通过继电器或者中继，进行长距离的信号传输；
- 另一方面，也可以通过设置不同的线路和开关状态，实现更多不同的信号表示和处理方式，这些线路的连接方式其实就是在数字电路中所说的门电路。而这些**门电路**，也是创建 CPU 和内存的基本逻辑单元。各种对于计算机二进制的“0”和“1”的操作，其实就是来自于门电路，叫作**组合逻辑电路**

门电路标识：

![](image/门电路-标识.png)

这些基本的门电路，是计算机硬件端的最基本的“积木”

## 3.10、加法器

### 3.10.1、异或门和半加器

基础门电路，输入都是两个单独的 bit，输出是一个单独的 bit。如果要对 2 个 8 位（bit）的数，计算与、或、非这样的简单逻辑运算，其实很容易。只要连续摆放 8 个开关，来代表一个 8 位数。这样的两组开关，从左到右，上下单个的位开关之间，都统一用“与门”或者“或门”连起来，就是两个 8 位数的 AND 或者 OR 的运算了；

2 个 8 位整数的加法，就是 2 排 8 个开关。加法得到的结果也是一个 8 位的整数，所以又需要 1 排 8 位的开关。加法器就是想一个办法把这三排开关电路连起来：

![](image/门电路-加法器基本实现.png)

要做到上面这点，可以先看下人在计算加法一般怎么操作：二进制的加法和十进制没什么区别，所以一样可以用列竖式来计算。仍然是从右到左，一位一位进行计算，只是把从逢 10 进 1 变成逢 2 进 1：

![](image/二进制-列竖式加法.png)

加法计算之后的个位数是：
- 在输入的两位是 00 和 11 的情况下，对应的输出都应该是 0；
- 在输入的两位是 10 和 01 的情况下，输出都是 1；<br/>
这个输入和输出的对应关系，其实就是“**异或门（XOR）**”，`异或门`就是一个最简单的整数加法，所需要使用的基本门电路

算完个位的输出还不算完，输入的两位都是 11 的时候，还需要向更左侧的一位进行进位。那这个就对应一个与门，也就是有且只有在加数和被加数都是 1 的时候，进位才会是 1；

所以通过一个`异或门`计算出个位，通过一个`与门`计算出是否进位，就通过电路算出了一个`一位数的加法`。于是，把两个门电路打包，给它取一个名字，就叫作`半加器（Half Adder）`

![](image/加法器-半加器电路.png)

### 3.10.2、全加器

半加器可以解决个位的加法问题，但是如果放到二位上来说，就不够用了。这里的竖式是个二进制的加法，所以如果从右往左数，第二列不是十位，称之为“二位”。对应的再往左，就应该分别是四位、八位；

**为什么半加器计算二位？**
- 因为二位除了一个加数和被加数之外，还需要加上来自个位的进位信号，一共需要三个数进行相加，才能得到结果；
- 当前用到的，无论是最简单的门电路，还是用两个门电路组合而成的半加器，输入都只能是两个 bit，也就是两个开关；

**如何解决？**
- 用两个半加器和一个或门，就能组合成一个全加器；
- 第一个半加器，用和个位的加法一样的方式，得到是否进位 X 和对应的二个数加和后的结果 Y，这样两个输出；
- 把这个加和后的结果 Y，和个位数相加后输出的进位信息 U，再连接到一个半加器上，就会再拿到一个是否进位的信号 V 和对应的加和后的结果 W <br/>

![](image/加法器-全加器电路图.png)

这个 W 就是在二位上留下的结果。把两个半加器的进位输出，作为一个`或门`的输入连接起来，只要两次加法中任何一次需要进位，那么在二位上，就会向左侧的四位进一位。因为一共只有三个 bit 相加，即使 3 个 bit 都是 1，也最多会进一位。

这样，通过两个半加器和一个`或门`，就得到了一个，能够接受进位信号、加数和被加数，这样三个数组成的加法。就是需要的**全加器**

**如何实现两个8bit数加法？**

只要把 8 个全加器串联起来就好了。个位的全加器的进位信号作为二位全加器的输入信号，二位全加器的进位信号再作为四位的全加器的进位信号。这样一层层串接八层，就得到了一个支持 8 位数加法的算术单元。如果要扩展到 16 位、32 位，乃至 64 位，都只需要多串联几个输入位和全加器就好了

![](image/加法器-8bit加法电路.png)

注意：对于这个全加器，在个位，只需要用一个半加器，或者让全加器的进位输入始终是 0。因为个位没有来自更右侧的进位。而最左侧的一位输出的进位信号，表示的并不是再进一位，而是表示我们的加法是否溢出了

加法溢出问题：在整个加法器的结果中，其实有一个电路的信号，会标识出加法的结果是否溢出。可以把这个对应的信号，输出给到硬件中其他标志位里，让计算机知道计算的结果是否溢出。而现代计算机也正是这样做的。这就是为什么在撰写程序的时候，能够知道计算结果是否溢出在硬件层面得到的支持；

总结：门电路 -> 半加器 -> 全加器 -> 加法器 -> ALU，在硬件层面，通过门电路、半加器、全加器一层层搭出了加法器这样的功能组件。把这些用来做算术逻辑计算的组件叫作 `ALU`，也就是算术逻辑单元

补充：出于性能考虑，实际 CPU 里面使用的加法器，比起前面的电路还有些差别，会更复杂一些。真实的加法器，使用的是一种叫作**超前进位加法器**的东西

### 3.10.3、顺序乘法实现

二进制乘法，列竖式（比如 13 * 9 = 117）整个计算过程：

![](image/二进制乘法运算列竖式.png)

通过上面列竖式可以看到，单个位置上，乘数只能是 0 或者 1，所以实际的乘法，就退化成了`位移和加法`

在 13×9 这个例子里面，被乘数 13 表示成二进制是 1101，乘数 9 在二进制里面是 1001，步骤：
- 最右边的个位是 1，所以个位乘以被乘数，就是把被乘数 1101 复制下来。
- 因为二位和四位都是 0，所以乘以被乘数都是 0，那么保留下来的都是 0000。
- 乘数的八位是 1，仍然需要把被乘数 1101 复制下来。不过这里和个位位置的单纯复制有一点小小的差别，那就是要把复制好的结果向左侧移三位；
- 然后把四位单独进行乘法加位移的结果，再加起来，就得到了最终的计算结果；

可以用一个开关来决定，下面的输出是完全复制输入，还是将输出全部设置为 0：

![](image/门电路-乘法门电路.png)

至于位移也不麻烦，只要不是直接连线，把正对着的开关之间进行接通，而是斜着错开位置去接就好了。如果要左移一位，就错开一位接线；如果要左移两位，就错开两位接线

![](image/门电路-乘法门电路-位移.png)

其实只需要一组开关就可以实现：
- 先拿乘数最右侧的个位乘以被乘数；
- 然后把结果写入用来存放计算结果的开关里面；
- 然后，把被乘数左移一位，把乘数右移一位，仍然用乘数去乘以被乘数；
- 然后把结果加到刚才的结果上。反复重复这一步骤，直到不能再左移和右移位置。
- 这样，乘数和被乘数就像两列相向而驶的列车，仅仅需要简单的加法器、一个可以左移一位的电路和一个右移一位的电路，就能完成整个乘法<br/>
![](image/乘法器硬件结构示意图.png)

这里的控制测试，其实就是通过一个时钟信号，来控制左移、右移以及重新计算乘法和加法的时机。以计算 13×9，也就是二进制的 1101×1001 来具体看：

![](image/乘法器硬件结构示意图-1.png)

上述方法有一个很大缺点：慢，

在这个乘法器的实现过程里，其实就是把乘法展开，变成了“加法 + 位移”来实现。用的是 4 位数，所以要进行 4 组“位移 + 加法”的操作。而且这 4 组操作还不能同时进行。因为下一组的加法要依赖上一组的加法后的计算结果，下一组的位移也要依赖上一组的位移的结果。这样，整个算法是“顺序”的，每一组加法或者位移的运算都需要一定的时间；

### 3.10.4、并行加速方法

在涉及 CPU 和电路的时候，可以改电路来降低时间复杂度；

32 位数虽然是 32 次加法，但是可以让很多加法同时进行。前面把位移和乘法的计算结果加到中间结果里的方法，32 位整数的乘法，其实就变成了 32 个整数相加

**顺序乘法器硬件**的实现办法，就好像体育比赛里面的单败淘汰赛。只有一个擂台会存下最新的计算结果。每一场新的比赛就来一个新的选手，实现一次加法，实现完了剩下的还是原来那个守擂的，直到其余 31 个选手都上来比过一场。如果一场比赛需要一天，那么一共要比 31 场，也就是 31 天；

![](image/单败淘汰赛.png)

**加速的办法**，就是把比赛变成像世界杯足球赛那样的淘汰赛，32 个球队捉对厮杀，同时开赛。这样一天一下子就淘汰了 16 支队，也就是说，32 个数两两相加后，你可以得到 16 个结果。后面的比赛也是一样同时开赛捉对厮杀。只需要 5 天，也就是 `O(log2N)` 的时间，就能得到计算的结果。但是这种方式要求得有 16 个球场。因为在淘汰赛的第一轮，需要 16 场比赛同时进行。对应到 CPU 的硬件上，就是需要更多的晶体管开关，来放下中间计算结果。

![](image/捉对厮杀赛.png)

通过并联更多的 ALU，加上更多的寄存器，也能加速乘法；

### 3.10.5、电路并行

所以计算会慢，核心原因其实是“顺序”计算，也就是说，要等前面的计算结果完成之后，才能得到后面的计算结果。

**门延迟**

位数越多，越往高位走，等待前面的步骤就越多，这个等待的时间有个专门的名词，叫作**门延迟（Gate Delay）**，每通过一个门电路，就要等待门电路的计算结果，就是一层的门电路延迟，一般给它取一个“T”作为符号。

一个全加器，其实就已经有了 3T 的延迟（进位需要经过 3 个门电路）。而 4 位整数，最高位的计算需要等待前面三个全加器的进位结果，也就是要等 9T 的延迟。如果是 64 位整数，那就要变成 63×3=189T 的延迟。这可不是个小数字啊；

**时钟频率**

顺序乘法计算里面，如果想要用更少的电路，计算的中间结果需要保存在寄存器里面，然后等待下一个时钟周期的到来，控制测试信号才能进行下一次移位和加法，这个延迟比上面的门延迟更可观；

**如何解决？**

只要把进位部分的电路完全展开就好了。半加器到全加器，再到加法器，都是用最基础的门电路组合而成的。门电路的计算逻辑，像做数学里面的多项式乘法一样完全展开。在展开之后呢，可以把原来需要较少的，但是有较多层前后计算依赖关系的门电路，展开成需要较多的，但是依赖关系更少的门电路；

如果我们完全展开电路，高位的进位和计算结果，可以和低位的计算结果同时获得。这个的核心原因是电路是天然并行的，一个输入信号，可以同时传播到所有接通的线路当中

![](image/加法器-进位部分展开门电路.png)

这个优化，本质上是**利用了电路天然的并行性。电路只要接通，输入的信号自动传播到了所有接通的线路里面**，这其实也是硬件和软件最大的不同

无论是这里把对应的门电路逻辑进行完全展开以减少门延迟，还是乘法通过并行计算多个位的乘法，都是把完成一个计算的电路变复杂了。而**电路变复杂了，也就意味着晶体管变多了**。

**为什么晶体管的数量增加可以优化计算机的计算性能**。实际上，这里的门电路展开和并行计算乘法都是很好的例子。通过更多的晶体管，就可以拿到更低的门延迟，以及用更少的时钟周期完成一个计算指令。

> 总结：通过精巧地设计电路，用较少的门电路和寄存器，就能够计算完成乘法这样相对复杂的运算。是用更少更简单的电路，但是需要更长的门延迟和时钟周期；还是用更复杂的电路，但是更短的门延迟和时钟周期来计算一个复杂的指令，这之间的权衡，其实就是**计算机体系结构中 RISC 和 CISC 的经典历史路线之争**

## 3.11、浮点数和定点数

- [Floating Point Math:0.1 + 0.2 = 0.30000000000000004](https://0.30000000000000004.com/)
- [深入理解浮点数](https://polarisxu.studygolang.com/posts/basic/diagram-float-point/)
- [进制转化-支持浮点数](https://baseconvert.com/)

### 3.11.1、浮点数的不精确性

在Python控制台或者Chrome浏览器客户端，计算浮点数：0.3+0.6，出来的结果居然不是准确的 0.9，而是 0.8999999999999999 这么个结果。这是为什么呢？
```bash
[root@bluefish language]# python3.6
Python 3.6.8 (default, Nov 14 2023, 16:29:52) 
[GCC 4.8.5 20150623 (Red Hat 4.8.5-44)] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> 0.3+0.6
0.8999999999999999
>>> 
```
**用 32 个比特，能够表示所有实数吗？** 很显然是不能。32 个比特，只能表示 2 的 32 次方个不同的数，差不多是 40 亿个。如果表示的数要超过这个数，就会有两个不同的数的二进制表示是一样的。那计算机可就会一筹莫展，不知道这个数到底是多少；

如何让这40 亿个数映射到实数集合上的哪些数，在实际应用中才能产生最大效果？

### 3.11.2、定点数表示

**[BCD 编码](https://en.wikipedia.org/wiki/Binary-coded_decimal)**
- 用 4 个比特来表示 0～9 的整数，那么 32 个比特就可以表示 8 个这样的整数；
- 把最右边的 2 个 0～9 的整数，当成小数部分；
- 把左边 6 个 0～9 的整数，当成整数部分。
- 这样，就可以用 32 个比特，来表示从 0 到 999999.99 这样 1 亿个实数了

这种用二进制来表示十进制的编码方式，叫作**BCD 编码（Binary-Coded Decimal）**

这种表示方式的缺点：
- （1）这样的表示方式有点“浪费”：本来 32 个比特可以表示 40 亿个不同的数，但是在 BCD 编码下，只能表示 1 亿个数，如果要精确到分的话，那么能够表示的最大金额也就是到 100 万；
- （2）这样的表示方式没办法同时表示很大的数字和很小的数字：比如表示商品的金额，关心的是 9.99 这样小的数字；又比如进行物理学的运算，需要表示光速，也就是 $3×10^8$ 这样很大的数字

### 3.11.3、浮点数表示

上面提到定点数无法同时表示很大的数字和很小的数字，有没有既能够表示很小的数，又能表示很大的数呢？答案是：**浮点数（Floating Point）**，也就是**float 类型**。

宽度限制了我们能够表示的数的大小，如何在有限空间内表示很大的数？使用**科学计数法**，比如宇宙内的原子的数量，大概在 10 的 82 次方左右，我们就用 $1.0×{10}^{82}$ 这样的形式来表示这个数值，不需要写下 82 个 0；

**[IEEE标准](https://en.wikipedia.org/wiki/IEEE_754)**

浮点数的科学计数法的表示，有一个**IEEE的标准**，它定义了两个基本的格式：
- 一个是用 32 比特（4位）表示单精度的浮点数，也就是 float 或者 float32 类型。
- 另外一个是用 64 比特（8位）表示双精度的浮点数，也就是 double 或者 float64 类型

双精度类型和单精度类型差不多，这里，单精度类型，双精度自然也就明白了

s = 符号位 | e = 指数位 | f = 有效数位
----------|------------|-----------
1个比特    |  8个比特   | 23个比特

单精度的 32 个比特可以分成三部分：
- 第一部分是一个**符号位**，用来表示是正数还是负数。一般用**s**来表示。在浮点数里，不像正数分符号数还是无符号数，所有的浮点数都是有符号的；0表示整数，1表示负数
- 第二部分是一个 8 个比特组成的**指数位**，一般用**e**来表示，表示指数偏移值。8 个比特能够表示的整数空间，就是 0～255。在这里用 `1～254` 映射到 `-126～127` 这 254 个有正有负的数上。因为浮点数，不仅仅想要表示很大的数，还希望能够表示很小的数，所以指数位也会有负数；<br/>
  注意：没有用到 0 和 255。没错，这里的 0（也就是 8 个比特全部为 0） 和 255 （也就是 8 个比特全部为 1）另有它用；
- 最后，是一个 23 个比特组成的**有效数位**。用**f**来表示。

综合科学计数法，浮点数就可以表示成这样： $(-1)^s × 1.f × 2^e$ 

**0 和一些特殊数的表示：**

这里的浮点数，没有办法表示 0。的确，要表示 0 和一些特殊的数，就要用上在 e 里面留下的 0 和 255 这两个表示，这两个表示其实是两个标记位。**在 e 为 0 且 f 为 0 的时候，就把这个浮点数认为是 0**。至于其它的 e 是 0 或者 255 的特殊情况，可以看下面这个表格，分别可以表示出无穷大、无穷小、NAN 以及一个特殊的不规范数

![](image/浮点数-所有实数表示.png)

以 0.5 为例子。0.5 的符号为 s 应该是 0，f 应该是 0，而 e 应该是 -1，也就是： $0.5 = (-1)^0 × 1.0 × 2^{-1} = 0.5$ ，对应的浮点数表示，就是 32 个比特；

![](image/浮点数-0.5的表示.png)

$s=0，e=2^{−1}$ ，需要注意，e 表示从 -126 到 127 个，-1 是其中的第 126 个数，这里的 e 如果用整数表示，就是： $2^6+2^5+2^4+2^3+2^2+2^1=126 ,1.f=1.0$ 。 在这样的浮点数表示下，不考虑符号的话，浮点数能够表示的最小的数和最大的数，差不多是 $1.17×10^{−38}$ 和 $3.40×10^{38}$  。比前面的 BCD 编码能够表示的范围大多了;

> 总结：为什么用 0.3 + 0.6 不能得到 0.9 呢？这是因为，浮点数没有办法精确表示 0.3、0.6 和 0.9。事实上，拿出 0.1～0.9 这 9 个数，其中只有 0.5 能够被精确地表示成二进制的浮点数，也就是 s = 0、e = -1、f = 0 这样的情况； 就是浮点数无论是表示还是计算其实都是近似计算；

**双精度浮点数表示**

双精度浮点数由8字节64-bit组成

 s = 符号位 | e = 指数位 | f = 有效数位
----------|------------|-----------
1个比特    |  11位   | 52个比特

双精度浮点数的偏移量为 1023

### 3.11.4、浮点数的二进制转化

- [直接交互式地设置符号位、指数位和有效位数的操作](https://www.h-schmidt.net/FloatConverter/IEEE754.html)

十进制浮点数如何转化为二进制？输入一个任意的十进制浮点数，背后都会对应一个二进制表示，比如：输入了一个十进制浮点数 `9.1`。那么按照前面的说法，在二进制里面，应该把它变成一个**符号位 s+ 指数位 e+ 有效位数 f**的组合。第一步，要做的，就是把这个数变成二进制：
- 首先，把这个数的整数部分，变成一个二进制，这里的 9，换算之后就是 1001；
- 把对应的小数部分也换算成二进制:<br/>
  小数的二进制表示是怎么回事:：
  - 和上面的整数相反，把小数点后的每一位，都表示对应的 2 的 -N 次方。那么 `0.1001`，转化成十进制就是：<br/>
    $1 × 2^{-1} + 0 × 2 + 0 × 2^{-3}$ <br/>
    $1 × 2^{-4} = 0.5625$ <br/>
  - 小数部分转换成二进制是乘以 2，然后看看是否超过 1：
    - 如果超过 1，我们就记下 1，并把结果减去 1，进一步循环操作。在这里，就会看到，0.1 其实变成了一个无限循环的二进制小数，`0.000110011`。这里的“0011”会无限循环下去

    ![](image/浮点数-小数十进制转二进制.png)

- 然后，把整数部分和小数部分拼接在一起，`9.1` 这个十进制数就变成了 `1001.000110011…`这样一个二进制表示

浮点数其实是用**二进制的科学计数法**来表示的，可以把小数位数左移3位，就变成： $1.001000110011… × 2^3$ ，那这个二进制的科学计数法表示：
- 符号位 s = 0；
- 对应的有效位 `f=001000110011`…。因为 f 最长只有 23 位，那这里“0011”无限循环，最多到 23 位就截止了。于是，`f=00100011001100110011 001`，后的一个“0011”循环中的最后一个“1”会被截断掉；
- 指数为 e，代表的应该是 3，因为指数位有正又有负，所以指数位在 127 之前代表负数，之后代表正数；那 3 其实对应的是加上 127 的偏移量 130（单精度浮点数的偏移量为127，双精度浮点数为：1023），转化成二进制，对应的就是指数位的二进制，表示出来就是 10000010

![](image/浮点数-小数二进制科学计数法表示.png)

把“s+e+f”拼在一起，就可以得到浮点数 `9.1` 的二进制表示了。最终得到的二进制表示就变成了：`010000010 0010 0011001100110011 001`，如果再把这个浮点数表示换算成十进制， 实际准确的值是 `9.09999942779541015625`

再比如：$(112.5)_{10} = (1110000.1)_2$ 单精度浮点数表示
- 将该二进制数使用类似科学计数法表示： $1.1100001 × 2^6$ ；
- 这里 6 就是指数 e，小数点后的 1100001 就是有效位数；
- 32位浮点数表示法中，第一位为符号位，这里是正数，所以是：0
- 第2~9位是用来存放指数的，但浮点数再表示指数时，需要加上偏移量127， $(6+127 =133)_{10} = (1000 0101)_2$，所以这8位为：10000101；不足8位在左侧补0
- 最后的23位表示有效位数，有效位数为小数点后的位数，为： 1100001，其他位置补0；
- 最终 112.5 单精度浮点数表示：`0 10000101 11000010000000000000000`；


### 3.11.5、浮点数的加法和精度损失

浮点数的加法原理也很简单，六个字就行了：**先对齐、再计算** ：
- 先对齐：两个浮点数的指数位可能是不一样的，所以要把两个的指数位，变成一样的；
- 再计算：只去计算有效位的加法就好了；

比如计算：0.5+0.125 的浮点数运算：
- `0.5`，表示成浮点数，对应的指数位是 -1，有效位是 `00…`（后面全是 0，记住 f 前默认有一个 1）。
- `0.125` 表示成浮点数，对应的指数位是 -3，有效位也还是 00…（后面全是 0，记住 f 前默认有一个 1）；
- 对齐：首先要把两个的指数位对齐，也就是把指数位都统一成两个其中较大的 -1。对应的有效位 1.00…也要对应右移两位，因为 f 前面有一个默认的 1，所以就会变成 0.01；
- 计算：然后计算两者相加的有效位 1.f，就变成了有效位 1.01，而指数位是 -1；
 
实现这样一个加法，也只需要位移。和整数加法类似的半加器和全加器的方法就能够实现，在电路层面，也并没有引入太多新的复杂性

![](image/浮点数-加法运算.png)

**加法丢失精度：**
- 前面加法的过程中，其中指数位较小的数，需要在有效位进行右移，在右移的过程中，最右侧的有效位就被丢弃掉了
- 这会导致对应的指数位较小的数，在加法发生之前，就**丢失精度**；
- 两个相加数的指数位差的越大，位移的位数越大，可能丢失的精度也就越大；也有可能运气非常好，右移丢失的有效位都是 0。这种情况下，对应的加法虽然丢失了需要加的数字的精度，但是因为对应的值都是 0，实际的加法的数值结果不会有精度损失；

**32位数加法精度丢失成倍增长：**32 位浮点数的有效位长度一共只有 23 位，如果两个数的指数位差出 23 位，较小的数右移 24 位之后，所有的有效位就都丢失了。这也就意味着，虽然浮点数可以表示上到 $3.40×10^{38}$，下到 $1.17×10^{−38}$这样的数值范围。但是在实际计算的时候，只要两个数，差出 $2^{24}$，也就是差不多 1600 万倍，那这两个数相加之后，结果完全不会变化:

用一个简单的Java程序，让一个值为2000万的32位浮点数和1相加，会发现，+1这个过程因为精度损失，被“完全抛弃”了：
```java
public class FloatPrecision {
  public static void main(String[] args) {
    float a = 20000000.0f;
    float b = 1.0f;
    float c = a + b;
    System.out.println("c is " + c);
    float d = c - a;
    System.out.println("d is " + d);
  }
}
```

### 3.11.6、Kahan Summation算法

如何解决精度丢失的问题？

用一个循环相加 2000 万个 1.0f，最终的结果会是 1600 万左右，而不是 2000 万。这是因为，加到 1600 万之后的加法因为精度丢失都没有了。这个代码比起上面的使用 2000 万来加 1.0 更具有现实意义：
```java
public class FloatPrecision {
  public static void main(String[] args) {
    float sum = 0.0f;
    for (int i = 0; i < 20000000; i++) {
    	float x = 1.0f;
    	sum += x;    	
    }
    System.out.println("sum is " + sum);  // sum is 1.6777216E7
  }	
}
```
面对这个问题，聪明的计算机科学家们也想出了具体的解决办法。他们发明了一种叫作[Kahan Summation](https://en.wikipedia.org/wiki/Kahan_summation_algorithm)的算法来解决这个问题。算法的对应代码如下。从中可以看到，同样是 2000 万个 1.0f 相加，用这种算法得到了准确的 2000 万的结果：
```java
float sum = 0.0f;
float c = 0.0f;
for (int i = 0; i < 20000000; i++) {
    float x = 1.0f;
    float y = x - c;
    float t = sum + y;
    c = (t - sum) - y;
    sum = t;
}
System.out.println("sum is " + sum);
```
这个算法的原理是：就是在每次的计算过程中，都用一次减法，把当前加法计算中损失的精度记录下来，然后在后面的循环中，把这个精度损失放在要加的小数上，再做一次运算；

# 4、处理器

## 4.1、指令+计算=CPU

### 4.1.1、指令周期（Instruction Cycle）

计算机每执行一条指令的过程，可以分解成这样几个步骤：
- 1.**Fetch（取得指令）**，也就是从 PC 寄存器里找到对应的指令地址，根据指令地址从内存里把具体的指令，加载到指令寄存器中，然后把 PC 寄存器自增，好在未来执行下一条指令。
- 2.**Decode（指令译码）**，也就是根据指令寄存器里面的指令，解析成要进行什么样的操作，是 R、I、J 中的哪一种指令，具体要操作哪些寄存器、数据或者内存地址。
- 3.**Execute（执行指令）**，也就是实际运行对应的 R、I、J 这些特定的指令，进行算术逻辑操作、数据传输或者直接的地址跳转；
- 4.重复进行 1～3 的步骤。
- 
这样的步骤，其实就是一个永不停歇的“**Fetch - Decode - Execute**”的循环，我们把这个循环称之为**指令周期（Instruction Cycle）**；

在这个循环过程中，不同部分其实是由计算机中的不同组件完成的：
- 在取指令的阶段，指令是放在**存储器**里的，实际上，通过 PC 寄存器和指令寄存器取出指令的过程，是由**控制器（Control Unit）**操作的。
- 指令的解码过程，也是由**控制器**进行的。
- 一旦到了执行指令阶段，无论是进行算术操作、逻辑操作的 R 型指令，还是进行数据传输、条件分支的 I 型指令，都是由**算术逻辑单元（ALU）**操作的，也就是由**运算器**处理的。不过，如果是一个简单的无条件地址跳转，那么可以直接在**控制器**里面完成，不需要用到运算器

![](image/指令周期-不同步骤在不同组件之内完成.png)

除了 Instruction Cycle 这个指令周期，在 CPU 里面还有另外两个常见的 Cycle：
- 一个叫**Machine Cycle，机器周期或者CPU 周期**。CPU 内部的操作速度很快，但是访问内存的速度却要慢很多。每一条指令都需要从内存里面加载而来，所以一般把从内存里面读取一条指令的最短时间，称为 **CPU 周期**。
- 还有一个是Clock Cycle，也就是时钟周期以及机器的主频。一个 CPU 周期，通常会由几个时钟周期累积起来。一个 CPU 周期的时间，就是这几个 Clock Cycle 的总和；

这三个周期之间的关系：对于一个指令周期来说，取出一条指令，然后执行它，至少需要两个 CPU 周期。取出指令至少需要一个 CPU 周期，执行至少也需要一个 CPU 周期，复杂的指令则需要更多的 CPU 周期；

![](image/指令周期-CPU周期和时钟周期.png)

所以，一个指令周期，包含多个 CPU 周期，而一个 CPU 周期包含多个时钟周期；

### 4.1.2、建立数据通路

数据通路就是处理器单元。它通常由两类原件组成：
- 第一类叫操作元件，也叫**组合逻辑元件（Combinational Element）**，其实就是 ALU。在前面讲 ALU 的过程中可以看到，它们的功能就是在特定的输入下，根据下面的组合电路的逻辑，生成特定的输出。
- 第二类叫存储元件，也有叫**状态元件（State Element）**的。比如在计算过程中需要用到的寄存器，无论是通用寄存器还是状态寄存器，其实都是存储元件；

通过数据总线的方式，把它们连接起来，就可以完成数据的存储、处理和传输了，这就是所谓的建立数据通路了；

**控制器**：可以把它看成只是机械地重复“Fetch - Decode - Execute“循环中的前两个步骤，然后把最后一个步骤，通过控制器产生的控制信号，交给 ALU 去处理

控制器的电路：
- 一方面，所有 CPU 支持的指令，都会在控制器里面，被解析成不同的输出信号。我们之前说过，现在的 Intel CPU 支持 2000 个以上的指令。这意味着，控制器输出的控制信号，至少有 2000 种不同的组合；
- 运算器里的 ALU 和各种组合逻辑电路，可以认为是一个固定功能的电路。控制器“翻译”出来的，就是不同的控制信号。这些控制信号，告诉 ALU 去做不同的计算。可以说正是控制器的存在，让我们可以“编程”来实现功能，能让我们的“存储程序型计算机”名副其实；

指令译码器将输入的机器码，解析成不同的操作码和操作数，然后传输给 ALU 进行计算；

### 4.1.3、CPU 所需要的硬件电路

要想搭建出来整个 CPU，需要在数字电路层面，实现这样一些功能：
- ALU：它实际就是一个没有状态的，根据输入计算输出结果的第一个电路；
- 寄存器：要有一个能够进行状态读写的电路元件。需要有一个电路，能够存储到上一次的计算结果。这个计算结果并不一定要立刻拿到电路的下游去使用，但是可以在需要的时候拿出来用。常见的能够进行状态读写的电路：
  - 锁存器（Latch）
  - D 触发器（Data/Delay Flip-flop）；
- 自动数数的电路：需要有一个“自动”的电路，按照固定的周期，不停地实现 PC 寄存器自增，自动地去执行“**Fetch - Decode - Execute**“的步骤。程序的执行，并不是靠人去拨动开关来执行指令的。希望有一个“自动”的电路，不停地去一条条执行指令；
  看似写了各种复杂的高级程序进行各种函数调用、条件跳转。其实只是修改 PC 寄存器里面的地址。PC 寄存器里面的地址一修改，计算机就可以加载一条指令新指令，往下运行。实际上，PC 寄存器还有一个名字，就叫作程序计数器。顾名思义，就是随着时间变化，不断去数数。数的数字变大了，就去执行一条新指令；
- “译码”的电路：无论是对于指令进行 decode，还是对于拿到的内存地址去获取对应的数据或者指令，都需要通过一个电路找到对应的数据。这个对应的自然就是“译码器”的电路了；

要实现这四种电路中的中间两种，需要时钟电路的配合；

能够实现一个完整的 CPU 功能，除了加法器这样的电路之外，还需要实现其他功能的电路：其中有一些电路，和加法器一样，只需要给定输入，就能得到固定的输出。这样的电路，称之为**组合逻辑电路（Combinational Logic Circuit）**

**只有组合逻辑电路（Combinational Logic Circuit），CPU会怎样？**

电路输入是确定的，对应的输出自然也就确定了。那么，要进行不同的计算，就要去手动拨动各种开关，来改变电路的开闭状态。这样的计算机，不像现在每天用的功能强大的电子计算机，反倒更像古老的计算尺或者机械计算机，干不了太复杂的工作，只能协助完成一些计算工作

**时序逻辑电路（Sequential Logic Circuit）** 解决的问题：
- **自动运行**的问题：时序电路接通之后可以不停地开启和关闭开关，进入一个自动运行的状态。控制器不停地让 PC 寄存器自增读取下一条指令成为可能；
- **存储**的问题：通过时序电路实现的触发器，能把计算结果存储在特定的电路里面，而不是像组合逻辑电路那样，一旦输入有任何改变，对应的输出也会改变；
- 本质上解决了各个功能按照**时序协调**的问题。无论是程序实现的软件指令，还是到硬件层面，各种指令的操作都有先后的顺序要求。时序电路使得不同的事件按照时间顺序发生；

### 4.1.4、时钟信号的硬件实现



# 参考资料

- [计算机科学速成课](https://github.com/chenlanqing/Crash-Course-Computer-Science-Chinese)
- [图解计算机基础](https://xiaolincoding.com/)
- [如何开发操作系统](http://osdev.foofun.cn/index.php?title=Expanded_Main_Page)
- [计算机底层资料分享](https://github.com/liuyubobobo/cool-open-sharings)
- [计算机学习路线](https://csguide.cn/roadmap/)
- [计算机专业学习路线](https://hackway.org/docs/cs/intro)
