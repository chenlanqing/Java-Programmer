![](image/计算机组成原理-知识地图.png)

# 1、冯·诺依曼体系结构

## 1.1、计算机的基本硬件组成

三大件：
- CPU：中央处理器（Central Processing Unit）
- 内存：存放在内存里的程序和数据，需要被 CPU 读取，CPU 计算完之后，还要把数据写回到内存
- 主板：CPU 要插在主板上，内存也要插在主板上。主板的芯片组（Chipset）和总线（Bus）解决了 CPU 和内存之间如何通信的问题。芯片组控制了数据传输的流转，也就是数据从哪里到哪里的问题。总线则是实际数据传输的高速公路。因此，总线速度（Bus Speed）决定了数据能传输得多快

最后配上电源、输入输出设备；

另外还有一个特殊设备显卡，图形操作系统少不了这个，显卡之所以特殊，是因为显卡里有除了 CPU 之外的另一个“处理器”，也就是GPU（Graphics Processing Unit，图形处理器），GPU 一样可以做各种“计算”的工作；

### 1.2、冯·诺依曼体系结构

冯·诺依曼在[First Draft](https://en.wikipedia.org/wiki/First_Draft_of_a_Report_on_the_EDVAC)里面描述了一台计算机应该有哪些部分组成
- 首先是一个包含算术逻辑单元（Arithmetic Logic Unit，ALU）和处理器寄存器（Processor Register）的`处理器单元（Processing Unit）`，用来完成各种算术和逻辑运算。因为它能够完成各种数据的处理或者计算工作，因此也有人把这个叫作数据通路（Datapath）或者运算器；
- 然后是一个包含指令寄存器（Instruction Reigster）和程序计数器（Program Counter）的`控制器单元（Control Unit/CU）`，用来控制程序的流程，通常就是不同条件下的分支和跳转。在现在的计算机里，上面的算术逻辑单元和这里的控制器单元，共同组成了我们说的 CPU；
- 接着是用来存储数据（Data）和指令（Instruction）的`内存`，以及更大容量的`外部存储`，在过去，可能是磁带、磁鼓这样的设备，现在通常就是硬盘；
- 最后就是各种`输入和输出设备`，以及对应的输入和输出机制。个人电脑的鼠标键盘是输入设备，显示器是输出设备。我们用的智能手机，触摸屏既是输入设备，又是输出设备。而跑在各种云上的服务器，则是通过网络来进行输入和输出。这个时候，网卡既是输入设备又是输出设备；

任何一台计算机的任何一个部件都可以归到`运算器/处理器单元`、`控制器`、`存储器`、`输入设备`和`输出设备`中，而所有的现代计算机也都是基于这个基础架构来设计开发的；

而所有的计算机程序，也都可以抽象为从输入设备读取输入信息，通过运算器和控制器来执行存储在存储器里的程序，最终把结果输出到输出设备中；

冯·诺依曼体系结构确立了我们现在每天使用的计算机硬件的基础架构

冯·诺依曼体机与图灵机两者比较：两者有交叉但是不同
- 图灵机是一种思想模型（计算机的基本理论基础），是一种有穷的、构造性的问题的问题求解思路，图灵认为凡是能用算法解决的问题也一定能用图灵机解决；
- 冯诺依曼提出了“存储程序”的计算机设计思想，并“参照”图灵模型设计了历史上第一台电子计算机，即冯诺依曼机

# 2、计算机性能和功耗

对于计算机的性能，我们需要有个标准来衡量。这个标准中主要有两个指标：
- 第一个是响应时间（Response time）或者叫执行时间（Execution time）：让计算机跑的更快，响应时间指的就是，我们执行一个程序，到底需要花多少时间。花的时间越少，自然性能就越好
- 第二个是吞吐率（Throughput）或者带宽（Bandwidth）：让计算机搬的更多；吞吐率是指我们在一定的时间范围内，到底能处理多少事情

一般把性能定义成响应时间的倒数：`性能 = 1 / 响应时间`，响应时间越短，性能的数值就越大
 
## 2.1、CPU 时钟

用时间来衡量性能，存在两个问题：
- 第一个就是时间不“准”
- 其次，即使我们已经拿到了 CPU 时间，也不一定可以直接“比较”出两个程序的性能差异，即使在同一台计算机上，CPU 可能满载运行也可能降频运行，降频运行的时候自然花的时间会多一些

**时间不准**

为什么不准？首先，统计时间是用类似于“掐秒表”一样，记录程序运行结束的时间减去程序开始运行的时间。这个时间也叫 Wall Clock Time 或者 Elapsed Time，就是在运行程序期间，挂在墙上的钟走掉的时间；

但是，计算机可能同时运行着好多个程序，CPU 实际上不停地在各个程序之间进行切换。在这些走掉的时间里面，很可能 CPU 切换去运行别的程序了。而且，有些程序在运行的时候，可能要从网络、硬盘去读取数据，要等网络和硬盘把数据读出来，给到内存和 CPU。**所以说，要想准确统计某个程序运行时间，进而去比较两个程序的实际性能，得把这些时间给刨除掉。**

Linux 下有一个叫 time 的命令，可以统计出来：同样的 Wall Clock Time 下，程序实际在 CPU 上到底花了多少时间；它会返回三个值：
```bash
[root@bluefish ~]# time seq 1000000 |wc -l
1000000
real    0m0.013s
user    0m0.011s
sys     0m0.012s
```
- 第一个是real time，也就是前面说的 Wall Clock Time，也就是运行程序整个过程中流逝掉的时间；
- 第二个是user time，也就是 CPU 在运行你的程序，在用户态运行指令的时间；
- 第三个是sys time，是 CPU 在运行你的程序，在操作系统内核里运行指令的时间。而程序实际花费的 CPU 执行时间（CPU Time），就是 user time 加上 sys time；

除了 CPU 之外，时间这个性能指标还会受到主板、内存这些其他相关硬件的影响。所以，需要对“时间”这个可以感知的指标进行拆解，把程序的 CPU 执行时间变成` CPU 时钟周期数（CPU Cycles）`和 `时钟周期时间（Clock Cycle）`的乘积：

<p align="center">程序的CPU执行时间 = CPU时钟周期数 × 时钟周期时间</p>

**时钟周期**

比如电脑的CPU描述：`Intel Core-i7 2.8GHz`，这里的 `2.8GHz` 就是电脑的主频（Frequency/Clock Rate），`2.8GHz` 就代表，我们 CPU 的一个“钟表”能够识别出来的最小的时间间隔；

而在 CPU 内部，和电子石英表类似，有一个叫晶体振荡器（Oscillator Crystal）的东西，简称为晶振。把晶振当成 CPU 内部的电子表来使用。**晶振带来的每一次“滴答”，就是时钟周期时间**

在这个 2.8GHz的CPU上，时间周期时间就是：`1/2.8G`；CPU，是按照这个“时钟”提示的时间来进行自己的操作。主频越高，意味着这个表走得越快，我们的 CPU 也就“被逼”着走得越快；

根据前面计算程序CPU执行时间的公式，最简单的提升性能方案，自然缩短时钟周期时间，也就是提升主频。换句话说，就是换一块好一点的 CPU；

**CPU 时钟周期数**

前面提到提升性能的简单方案是缩短时钟周期时间，即提升主频，也就是换一块好的CPU；除了这个，还可以减少程序需要的 CPU 时钟周期数量，一样能够提升程序性能；

对于 CPU 时钟周期数，可以再做一个分解，把它变成“`指令数×每条指令的平均时钟周期数（Cycles Per Instruction，简称 CPI）`”。不同的指令需要的 Cycles 是不同的，加法和乘法都对应着一条 CPU 指令，但是乘法需要的 Cycles 就比加法要多，自然也就慢。在这样拆分了之后，程序的 CPU 执行时间就可以变成这样三个部分的乘积：

<p align="center">程序的 CPU 执行时间 = 指令数 × CPI × Clock Cycle Time</p>

因此想要解决性能问题，其实是优化这三者：
- 时钟周期时间，就是计算机主频，这个取决于计算机硬件。摩尔定律就一直在不停地提高我们计算机的主频。
- 每条指令的平均时钟周期数 CPI，就是一条指令到底需要多少 CPU Cycle。
- 指令数，代表执行我们的程序到底需要多少条指令、用哪些指令。这个一般交给了编译器。同样的代码，编译成计算机指令时候，就有各种不同的表示方式；

如果要提升计算机的性能，可以从指令数、CPI 以及 CPU 主频这三个地方入手。要搞定指令数或者 CPI，就在 CPU 上多放一点晶体管，不断提升 CPU 的时钟频率，这样就能让 CPU 变得更快，程序的执行时间就会缩短
 
## 2.2、功耗

早期提升CPU性能，就是堆晶体管；

*为什么奔腾 4 的主频没能超过 3.8GHz 的障碍呢？*因为功耗

功耗问题的直观例子：一个 3.8GHz 的奔腾 4 处理器，满载功率是 130 瓦。这个 130 瓦是什么概念呢？机场允许带上飞机的充电宝的容量上限是 100 瓦时。如果我们把这个 CPU 安在手机里面，不考虑屏幕内存之类的耗电，这个 CPU 满载运行 45 分钟，充电宝里面就没电了。而 iPhone X 使用 ARM 架构的 CPU，功率则只有 4.5 瓦左右；

CPU，一般都被叫作`超大规模集成电路（Very-Large-Scale Integration，VLSI）`。这些电路，实际上都是一个个晶体管组合而成的。CPU 在计算，其实就是让晶体管里面的“开关”不断地去“打开”和“关闭”，来组合完成各种运算和功能，想要计算得快：
- 一方面，我们要在 CPU 里，同样的面积里面，多放一些晶体管，也就是`增加密度`；
- 另一方面，我们要让晶体管“打开”和“关闭”得更快一点，也就是`提升主频`。
 
而这两者，都会增加功耗，带来耗电和散热的问题，因此，在 CPU 里面，能够放下的晶体管数量和晶体管的“开关”频率也都是有限的。一个 CPU 的功率，可以用这样一个公式来表示：

<p align="center"> 功耗 ~= 1/2 × 负载电容 × 电压的平方 × 开关频率 × 晶体管数量 </p>

为了要提升性能：
- 需要不断地增加晶体管数量。同样的面积下，想要多放一点晶体管，就要把晶体管造得小一点。这个就是平时所说的提升“制程”。从 28nm 到 7nm，相当于晶体管本身变成了原来的 1/4 大小；
- 还提升主频，让开关的频率变快；
- 功耗增加太多，就会导致 CPU 散热跟不上，这时，就需要降低电压；在整个功耗的公式里面，功耗和电压的平方是成正比的。这意味着电压下降到原来的 1/5，整个的功耗会变成原来的 1/25；

## 2.3、并行优化与阿姆达尔定律

随着技术的发展，面向[摩尔定律](https://en.wikipedia.org/wiki/Moore%27s_law)编程越来越行不通了，Intel 意识到通过提升主频比较“难”去实现性能提升，边开始推出 Core Duo 这样的多核 CPU，通过提升“吞吐率”而不是“响应时间”，来达到目的；这是一个常见的性能提升方式：通过并行提高性能；

能够使用并行计算，需要满足如下条件：
- 要进行的计算，本身可以分解成几个可以并行的任务。好比上面的乘法和加法计算，几个人可以同时进行，不会影响最后的结果。
- 需要能够分解好问题，并确保几个人的结果能够汇总到一起。
- 在“汇总”这个阶段，是没有办法并行进行的，还是得顺序执行，一步一步来；
 
在进行性能优化中，常常用到的一个经验定律，[阿姆达尔定律（Amdahl’s Law）](https://en.wikipedia.org/wiki/Amdahl%27s_law)。这个定律说的就是，对于一个程序进行优化之后，处理器并行运算之后效率提升的情况。具体可以用这样一个公式来表示：
<p align="center">优化后的执行时间 = 受优化影响的执行时间 / 加速倍数 + 不受影响的执行时间</p>

## 2.4、提升性能原则

- 加速大概率事件；
- 通过流水线提高性能：把 CPU 指令执行的过程进行拆分，细化运行，也是现代 CPU 在主频没有办法提升那么多的情况下，性能仍然可以得到提升的重要原因之一；
- 通过预测提高性能：通过预先猜测下一步该干什么，而不是等上一步运行的结果，提前进行运算，也是让程序跑得更快一点的办法；比如数组的访问；“分支和冒险”、“局部性原理”这些 CPU 和存储系统设计方法，其实都是在利用我们对于未来的“预测”，提前进行相应的操作，来提升我们的程序性能

# 2、计算机指令

## 2.1、if/else指令


## 2.2、函数调用

### 2.2.1、程序栈

- [程序栈压栈和出栈](https://manybutfinite.com/post/journey-to-the-stack/)
- [程序栈压栈和出栈](https://manybutfinite.com/post/epilogues-canaries-buffer-overflows/)

```c
// function_example.c
#include <stdio.h>
int static add(int a, int b)
{
    return a+b;
}
int main()
{
    int x = 5;
    int y = 10;
    int u = add(x, y);
}
```
把这个程序编译之后，objdump 出来。我们来看一看对应的汇编代码
```
$ gcc -g -c function_example.c
$ objdump -d -M intel -S function_example.o
```
对应的汇编代码如下：
```
function_example.o:     file format elf64-x86-64


Disassembly of section .text:

0000000000000000 <add>:

// function_example.c
#include <stdio.h>
int static add(int a, int b)
{
   0:	55                   	push   rbp
   1:	48 89 e5             	mov    rbp,rsp
   4:	89 7d fc             	mov    DWORD PTR [rbp-0x4],edi
   7:	89 75 f8             	mov    DWORD PTR [rbp-0x8],esi
    return a+b;
   a:	8b 55 fc             	mov    edx,DWORD PTR [rbp-0x4]
   d:	8b 45 f8             	mov    eax,DWORD PTR [rbp-0x8]
  10:	01 d0                	add    eax,edx
}
  12:	5d                   	pop    rbp
  13:	c3                   	ret    

0000000000000014 <main>:

int main()
{
  14:	55                   	push   rbp
  15:	48 89 e5             	mov    rbp,rsp
  18:	48 83 ec 10          	sub    rsp,0x10
    int x = 5;
  1c:	c7 45 fc 05 00 00 00 	mov    DWORD PTR [rbp-0x4],0x5
    int y = 10;
  23:	c7 45 f8 0a 00 00 00 	mov    DWORD PTR [rbp-0x8],0xa
    int u = add(x, y);
  2a:	8b 55 f8             	mov    edx,DWORD PTR [rbp-0x8]
  2d:	8b 45 fc             	mov    eax,DWORD PTR [rbp-0x4]
  30:	89 d6                	mov    esi,edx
  32:	89 c7                	mov    edi,eax
  34:	e8 c7 ff ff ff       	call   0 <add>
  39:	89 45 f4             	mov    DWORD PTR [rbp-0xc],eax
  3c:	b8 00 00 00 00       	mov    eax,0x0
}
  41:	c9                   	leave  
  42:	c3                   	ret    
```
先看add函数，add 函数编译之后，代码先执行了一条 push 指令和一条 mov 指令；在函数执行结束的时候，又执行了一条 pop 和一条 ret 指令。这四条指令的执行，其实就是在进行我们接下来要讲`压栈（Push）`和`出栈（Pop）`操作。

函数调用和 `if…else` 和 `for/while` 循环有点像，它们两个都是在原来顺序执行的指令过程里，执行了一个内存地址的跳转指令，让指令从原来顺序执行的过程里跳开，从新的跳转后的位置开始执行；if…else 和 for/while 的跳转，是跳转走了就不再回来了，就在跳转后的新地址开始顺序地执行指令；而函数调用的跳转，在对应函数的指令执行完了之后，还要再回到函数调用的地方，继续执行 call 之后的指令；

rbp 是 register base pointer 栈基址寄存器（栈帧指针），指向当前栈帧的栈底地址。rsp 是 register stack pointer 栈顶寄存器（栈指针），指向栈顶元素。


# 参考资料

- [计算机科学速成课](https://github.com/chenlanqing/Crash-Course-Computer-Science-Chinese)
- [图解计算机基础](https://xiaolincoding.com/)
- [如何开发操作系统](http://osdev.foofun.cn/index.php?title=Expanded_Main_Page)
- [计算机底层资料分享](https://github.com/liuyubobobo/cool-open-sharings)
- [计算机学习路线](https://csguide.cn/roadmap/)
- [计算机专业学习路线](https://hackway.org/docs/cs/intro)
