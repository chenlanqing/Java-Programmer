![](image/计算机组成原理-知识地图.png)

# 1、冯·诺依曼体系结构

## 1.1、计算机的基本硬件组成

三大件：
- CPU：中央处理器（Central Processing Unit）
- 内存：存放在内存里的程序和数据，需要被 CPU 读取，CPU 计算完之后，还要把数据写回到内存
- 主板：CPU 要插在主板上，内存也要插在主板上。主板的芯片组（Chipset）和总线（Bus）解决了 CPU 和内存之间如何通信的问题。芯片组控制了数据传输的流转，也就是数据从哪里到哪里的问题。总线则是实际数据传输的高速公路。因此，总线速度（Bus Speed）决定了数据能传输得多快

最后配上电源、输入输出设备；

另外还有一个特殊设备显卡，图形操作系统少不了这个，显卡之所以特殊，是因为显卡里有除了 CPU 之外的另一个“处理器”，也就是GPU（Graphics Processing Unit，图形处理器），GPU 一样可以做各种“计算”的工作；

### 1.2、冯·诺依曼体系结构

冯·诺依曼在[First Draft](https://en.wikipedia.org/wiki/First_Draft_of_a_Report_on_the_EDVAC)里面描述了一台计算机应该有哪些部分组成
- 首先是一个包含算术逻辑单元（Arithmetic Logic Unit，ALU）和处理器寄存器（Processor Register）的`处理器单元（Processing Unit）`，用来完成各种算术和逻辑运算。因为它能够完成各种数据的处理或者计算工作，因此也有人把这个叫作数据通路（Datapath）或者运算器；
- 然后是一个包含指令寄存器（Instruction Reigster）和程序计数器（Program Counter）的`控制器单元（Control Unit/CU）`，用来控制程序的流程，通常就是不同条件下的分支和跳转。在现在的计算机里，上面的算术逻辑单元和这里的控制器单元，共同组成了我们说的 CPU；
- 接着是用来存储数据（Data）和指令（Instruction）的`内存`，以及更大容量的`外部存储`，在过去，可能是磁带、磁鼓这样的设备，现在通常就是硬盘；
- 最后就是各种`输入和输出设备`，以及对应的输入和输出机制。个人电脑的鼠标键盘是输入设备，显示器是输出设备。我们用的智能手机，触摸屏既是输入设备，又是输出设备。而跑在各种云上的服务器，则是通过网络来进行输入和输出。这个时候，网卡既是输入设备又是输出设备；

任何一台计算机的任何一个部件都可以归到`运算器/处理器单元`、`控制器`、`存储器`、`输入设备`和`输出设备`中，而所有的现代计算机也都是基于这个基础架构来设计开发的；

而所有的计算机程序，也都可以抽象为从输入设备读取输入信息，通过运算器和控制器来执行存储在存储器里的程序，最终把结果输出到输出设备中；

冯·诺依曼体系结构确立了我们现在每天使用的计算机硬件的基础架构

冯·诺依曼体机与图灵机两者比较：两者有交叉但是不同
- 图灵机是一种思想模型（计算机的基本理论基础），是一种有穷的、构造性的问题的问题求解思路，图灵认为凡是能用算法解决的问题也一定能用图灵机解决；
- 冯诺依曼提出了“存储程序”的计算机设计思想，并“参照”图灵模型设计了历史上第一台电子计算机，即冯诺依曼机

# 2、计算机性能和功耗

对于计算机的性能，我们需要有个标准来衡量。这个标准中主要有两个指标：
- 第一个是响应时间（Response time）或者叫执行时间（Execution time）：让计算机跑的更快，响应时间指的就是，我们执行一个程序，到底需要花多少时间。花的时间越少，自然性能就越好
- 第二个是吞吐率（Throughput）或者带宽（Bandwidth）：让计算机搬的更多；吞吐率是指我们在一定的时间范围内，到底能处理多少事情

一般把性能定义成响应时间的倒数：`性能 = 1 / 响应时间`，响应时间越短，性能的数值就越大
 
## 2.1、CPU 时钟

用时间来衡量性能，存在两个问题：
- 第一个就是时间不“准”
- 其次，即使我们已经拿到了 CPU 时间，也不一定可以直接“比较”出两个程序的性能差异，即使在同一台计算机上，CPU 可能满载运行也可能降频运行，降频运行的时候自然花的时间会多一些

**时间不准**

为什么不准？首先，统计时间是用类似于“掐秒表”一样，记录程序运行结束的时间减去程序开始运行的时间。这个时间也叫 Wall Clock Time 或者 Elapsed Time，就是在运行程序期间，挂在墙上的钟走掉的时间；

但是，计算机可能同时运行着好多个程序，CPU 实际上不停地在各个程序之间进行切换。在这些走掉的时间里面，很可能 CPU 切换去运行别的程序了。而且，有些程序在运行的时候，可能要从网络、硬盘去读取数据，要等网络和硬盘把数据读出来，给到内存和 CPU。**所以说，要想准确统计某个程序运行时间，进而去比较两个程序的实际性能，得把这些时间给刨除掉。**

Linux 下有一个叫 time 的命令，可以统计出来：同样的 Wall Clock Time 下，程序实际在 CPU 上到底花了多少时间；它会返回三个值：
```bash
[root@bluefish ~]# time seq 1000000 |wc -l
1000000
real    0m0.013s
user    0m0.011s
sys     0m0.012s
```
- 第一个是real time，也就是前面说的 Wall Clock Time，也就是运行程序整个过程中流逝掉的时间；
- 第二个是user time，也就是 CPU 在运行你的程序，在用户态运行指令的时间；
- 第三个是sys time，是 CPU 在运行你的程序，在操作系统内核里运行指令的时间。而程序实际花费的 CPU 执行时间（CPU Time），就是 user time 加上 sys time；

除了 CPU 之外，时间这个性能指标还会受到主板、内存这些其他相关硬件的影响。所以，需要对“时间”这个可以感知的指标进行拆解，把程序的 CPU 执行时间变成` CPU 时钟周期数（CPU Cycles）`和 `时钟周期时间（Clock Cycle）`的乘积：

<p align="center">程序的CPU执行时间 = CPU时钟周期数 × 时钟周期时间</p>

**时钟周期**

比如电脑的CPU描述：`Intel Core-i7 2.8GHz`，这里的 `2.8GHz` 就是电脑的主频（Frequency/Clock Rate），`2.8GHz` 就代表，我们 CPU 的一个“钟表”能够识别出来的最小的时间间隔；

而在 CPU 内部，和电子石英表类似，有一个叫晶体振荡器（Oscillator Crystal）的东西，简称为晶振。把晶振当成 CPU 内部的电子表来使用。**晶振带来的每一次“滴答”，就是时钟周期时间**

在这个 2.8GHz的CPU上，时间周期时间就是：`1/2.8G`；CPU，是按照这个“时钟”提示的时间来进行自己的操作。主频越高，意味着这个表走得越快，我们的 CPU 也就“被逼”着走得越快；

根据前面计算程序CPU执行时间的公式，最简单的提升性能方案，自然缩短时钟周期时间，也就是提升主频。换句话说，就是换一块好一点的 CPU；

**CPU 时钟周期数**

前面提到提升性能的简单方案是缩短时钟周期时间，即提升主频，也就是换一块好的CPU；除了这个，还可以减少程序需要的 CPU 时钟周期数量，一样能够提升程序性能；

对于 CPU 时钟周期数，可以再做一个分解，把它变成“`指令数×每条指令的平均时钟周期数（Cycles Per Instruction，简称 CPI）`”。不同的指令需要的 Cycles 是不同的，加法和乘法都对应着一条 CPU 指令，但是乘法需要的 Cycles 就比加法要多，自然也就慢。在这样拆分了之后，程序的 CPU 执行时间就可以变成这样三个部分的乘积：

<p align="center">程序的 CPU 执行时间 = 指令数 × CPI × Clock Cycle Time</p>

因此想要解决性能问题，其实是优化这三者：
- 时钟周期时间，就是计算机主频，这个取决于计算机硬件。摩尔定律就一直在不停地提高我们计算机的主频。
- 每条指令的平均时钟周期数 CPI，就是一条指令到底需要多少 CPU Cycle。
- 指令数，代表执行我们的程序到底需要多少条指令、用哪些指令。这个一般交给了编译器。同样的代码，编译成计算机指令时候，就有各种不同的表示方式；

如果要提升计算机的性能，可以从指令数、CPI 以及 CPU 主频这三个地方入手。要搞定指令数或者 CPI，就在 CPU 上多放一点晶体管，不断提升 CPU 的时钟频率，这样就能让 CPU 变得更快，程序的执行时间就会缩短
 
## 2.2、功耗

早期提升CPU性能，就是堆晶体管；

*为什么奔腾 4 的主频没能超过 3.8GHz 的障碍呢？*因为功耗

功耗问题的直观例子：一个 3.8GHz 的奔腾 4 处理器，满载功率是 130 瓦。这个 130 瓦是什么概念呢？机场允许带上飞机的充电宝的容量上限是 100 瓦时。如果我们把这个 CPU 安在手机里面，不考虑屏幕内存之类的耗电，这个 CPU 满载运行 45 分钟，充电宝里面就没电了。而 iPhone X 使用 ARM 架构的 CPU，功率则只有 4.5 瓦左右；

CPU，一般都被叫作`超大规模集成电路（Very-Large-Scale Integration，VLSI）`。这些电路，实际上都是一个个晶体管组合而成的。CPU 在计算，其实就是让晶体管里面的“开关”不断地去“打开”和“关闭”，来组合完成各种运算和功能，想要计算得快：
- 一方面，我们要在 CPU 里，同样的面积里面，多放一些晶体管，也就是`增加密度`；
- 另一方面，我们要让晶体管“打开”和“关闭”得更快一点，也就是`提升主频`。
 
而这两者，都会增加功耗，带来耗电和散热的问题，因此，在 CPU 里面，能够放下的晶体管数量和晶体管的“开关”频率也都是有限的。一个 CPU 的功率，可以用这样一个公式来表示：

<p align="center"> 功耗 ~= 1/2 × 负载电容 × 电压的平方 × 开关频率 × 晶体管数量 </p>

为了要提升性能：
- 需要不断地增加晶体管数量。同样的面积下，想要多放一点晶体管，就要把晶体管造得小一点。这个就是平时所说的提升“制程”。从 28nm 到 7nm，相当于晶体管本身变成了原来的 1/4 大小；
- 还提升主频，让开关的频率变快；
- 功耗增加太多，就会导致 CPU 散热跟不上，这时，就需要降低电压；在整个功耗的公式里面，功耗和电压的平方是成正比的。这意味着电压下降到原来的 1/5，整个的功耗会变成原来的 1/25；

## 2.3、并行优化与阿姆达尔定律

随着技术的发展，面向[摩尔定律](https://en.wikipedia.org/wiki/Moore%27s_law)编程越来越行不通了，Intel 意识到通过提升主频比较“难”去实现性能提升，边开始推出 Core Duo 这样的多核 CPU，通过提升“吞吐率”而不是“响应时间”，来达到目的；这是一个常见的性能提升方式：通过并行提高性能；

能够使用并行计算，需要满足如下条件：
- 要进行的计算，本身可以分解成几个可以并行的任务。好比上面的乘法和加法计算，几个人可以同时进行，不会影响最后的结果。
- 需要能够分解好问题，并确保几个人的结果能够汇总到一起。
- 在“汇总”这个阶段，是没有办法并行进行的，还是得顺序执行，一步一步来；
 
在进行性能优化中，常常用到的一个经验定律，[阿姆达尔定律（Amdahl’s Law）](https://en.wikipedia.org/wiki/Amdahl%27s_law)。这个定律说的就是，对于一个程序进行优化之后，处理器并行运算之后效率提升的情况。具体可以用这样一个公式来表示：
<p align="center">优化后的执行时间 = 受优化影响的执行时间 / 加速倍数 + 不受影响的执行时间</p>

## 2.4、提升性能原则

- 加速大概率事件；
- 通过流水线提高性能：把 CPU 指令执行的过程进行拆分，细化运行，也是现代 CPU 在主频没有办法提升那么多的情况下，性能仍然可以得到提升的重要原因之一；
- 通过预测提高性能：通过预先猜测下一步该干什么，而不是等上一步运行的结果，提前进行运算，也是让程序跑得更快一点的办法；比如数组的访问；“分支和冒险”、“局部性原理”这些 CPU 和存储系统设计方法，其实都是在利用我们对于未来的“预测”，提前进行相应的操作，来提升我们的程序性能

# 3、指令和运算

## 3.1、计算机指令

- [Instruction Set Architecture](https://en.wikipedia.org/wiki/Instruction_set_architecture)

### 3.1、CPU做了啥

CPU 的全称是 Central Processing Unit，中文是中央处理器：
- 从硬件的角度来看，CPU 就是一个超大规模集成电路，通过电路实现了加法、乘法乃至各种各样的处理逻辑；
- 从软件工程师的角度来讲，CPU 就是一个执行各种计算机指令（Instruction Code）的逻辑机器。这里的计算机指令，就好比一门 CPU 能够听得懂的语言，也可以把它叫作机器语言（Machine Language）

**计算机指令集（ Instruction Set）：**不同的 CPU 能够听懂的语言不太一样，比如，个人电脑用的是 Intel 的 CPU，苹果手机用的是 ARM 的 CPU。这两者能听懂的语言就不太一样。类似这样两种 CPU 各自支持的语言，就是两组不同的计算机指令集；

**存储程序型计算机（Stored-program Computer）：**一个计算机程序，不可能只有一条指令，而是由成千上万条指令组成的。但是 CPU 里不能一直放着所有指令，所以计算机程序平时是存储在存储器中的。这种程序指令存储在存储器里面的计算机，就叫存储程序型计算机

### 3.2、代码如何编程机器码

下面是一段简单的C语言代码：
```c
// test.c
int main()
{
  int a = 1; 
  int b = 2;
  a = a + b;
}
```
如何让这段程序在计算中运行起来：
- 要让这段程序在一个 Linux 操作系统上跑起来，需要把整个程序翻译成一个**汇编语言（ASM，Assembly Language）**的程序，这个过程一般叫**编译（Compile）成汇编代码**；
- 针对汇编代码，可以再用汇编器（Assembler）翻译成机器码（Machine Code）。这些机器码由“0”和“1”组成的机器语言表示。这一条条机器码，就是一条条的**计算机指令**，这样一串串的 16 进制数字，就是CPU 能够真正认识的计算机指令；

**如何生成汇编代码和机器码**

在一个 Linux 操作系统上，可以简单地使用 gcc 和 objdump 这样两条命令，把对应的汇编代码和机器码都打印出来：
```bash
[root@bluefish language]# gcc -g -c test.c
[root@bluefish language]# objdump -d -M intel -S test.o
test.o:     file format elf64-x86-64
Disassembly of section .text:
0000000000000000 <main>:
int main()
{
   0:   55                      push   rbp
   1:   48 89 e5                mov    rbp,rsp
  int a = 1; 
   4:   c7 45 fc 01 00 00 00    mov    DWORD PTR [rbp-0x4],0x1
  int b = 2;
   b:   c7 45 f8 02 00 00 00    mov    DWORD PTR [rbp-0x8],0x2
  a = a + b;
  12:   8b 45 f8                mov    eax,DWORD PTR [rbp-0x8]
  15:   01 45 fc                add    DWORD PTR [rbp-0x4],eax
}
  18:   5d                      pop    rbp
  19:   c3                      ret    
```
左侧有一堆数字，这些就是一条条机器码；右边有一系列的 push、mov、add、pop 等，这些就是对应的汇编代码。一行 C 语言代码，有时候只对应一条机器码和汇编代码，有时候则是对应两条机器码和汇编代码。汇编代码和机器码之间是一一对应的；

汇编代码其实就是“给程序员看的机器码”，也正因为这样，机器码和汇编代码是一一对应的。人类很容易记住 `add、mov` 这些用英文表示的指令，而 `8b 45 f8` 这样的指令，由于很难一下子看明白是在干什么，所以会非常难以记忆

### 3.3、解析指令和机器码

日常用的Intel的CPU大概有2000条左右的CPU指令，常见的指令可以分为如下5类：

指令类型 | 指令描述 | 示例指令 | 示例汇编代码 | 含义 | 注释
--------|----------|---------|-------------|--------|--------
算术类指令|加减乘除，在 CPU 层面，都会变成一条条算术类指令|`add` | `add $s1,$s2,$s3` | `$s1=$s2+$s3`|将s2和s3寄存器中的数相加后的结果放到寄存器s1中
逻辑类指令|逻辑上的与或非，都是这一类指令|`or`|`or $s1,$s2,$s3` | `$s1=$s2\|$s3` | 将s2和s3寄存器中的数按位或后的结果放到寄存器s1中
数据传输类指令|给变量赋值、在内存里读写数据，用的都是数据传输类指令|`load word` | `load $s1,10($s2)` | `$1=memory[$s2+10]`|取s2寄存器中的数，加上10偏移量之后，存入到s2的寄存器中
条件分支类指令|日常我们写的“if/else”，其实都是条件分支类指令|`branch no equal`|`beq $s1,$s2,10`|`if($s1==$s2) go to PC+4+10`|如果s1和s2寄存器的值相等，从程序计数器往后跳10
无条件跳转指令|在调用函数的时候，其实就是发起了一个无条件跳转指令|`jump`|`j 1000`|`go to 1000`|跳转到1000这个目标地址；

**汇编器是怎么把对应的汇编代码，翻译成为机器码的**

- [MIPS指令集-指令学习](https://www.cnblogs.com/Roboduster/p/16158413.html)

不同的 CPU 有不同的指令集，也就对应着不同的汇编语言和不同的机器码，这里采用最简单的[MIPS指令集](https://en.wikipedia.org/wiki/MIPS_architecture)，看看机器码是如何生成的

MIPS 的指令是一个 32 位的整数，高 6 位叫操作码（Opcode），也就是代表这条指令具体是一条什么样的指令，剩下的 26 位有三种格式，分别是 R、I 和 J：

![](image/MIPS指令集-指令类型.png)

- `R 指令`是一般用来做算术和逻辑操作，里面有读取和写入数据的寄存器的地址。如果是逻辑位移操作，后面还有位移操作的位移量，而最后的功能码，则是在前面的操作码不够的时候，扩展操作码表示对应的具体指令的。
- `I 指令`，则通常是用在数据传输、条件分支，以及在运算的时候使用的并非变量还是常数的时候。这个时候，没有了位移量和操作码，也没有了第三个寄存器，而是把这三部分直接合并成了一个地址值或者一个常数。
- `J 指令`就是一个跳转指令，高 6 位之外的 26 位都是一个跳转后的地址；

### 3.4、演示MIPS指令集生成机器码

有指令：`add $t0, $s1, $s2`，转换成机器码，遵循以下步骤，首先确定这是一个R类型指令，其字段如下所示：
- `opcode`（操作码）: 对于所有R类型指令，`opcode`是`000000`。
- `rs`（第一个源寄存器）: `$s1`的编号是17，二进制表示为`10001`。
- `rt`（第二个源寄存器）: `$s2`的编号是18，二进制表示为`10010`。
- `rd`（目标寄存器）: `$t0`的编号是8，二进制表示为`01000`。
- `shamt`（位移量）: 对于`add`指令，这是`00000`，因为这不是位移指令。
- `funct`（功能码）: 对于`add`指令，这是`100000`。

把这些信息组合起来，我们得到这条指令的二进制表示：
```
000000 10001 10010 01000 00000 100000
```
现在，将这个二进制表示转换成十六进制：
- 二进制：`000000 10001 10010 01000 00000 100000`
- 分组（每4位一组，从右到左）：`0000 0010 0011 0010 0100 0000 0010 0000`
- 转换为十六进制：`0x02324020`

因此，MIPS指令 `add $t0, $s1, $s2` 对应的机器码是 `0x02324020`。

## 3.2、CPU如何执行指令

CPU内部是有数以亿计的晶体管组成的，一条条计算机指令的执行非常麻烦，但CPU在软件层面已经封装了，对于软件开发程序员来说，写好的代码变成指令之后，是一条一条顺序执行的；

在逻辑上，可以认为 CPU 其实就是由一堆`寄存器`组成的。而`寄存器`就是 CPU 内部，由多个`触发器（Flip-Flop）`或者`锁存器（Latches）`组成的简单电路，其中`触发器`和`锁存器`是两种不同原理的[数字电路组成的逻辑门](https://en.wikipedia.org/wiki/Logic_gate)；

`N 个触发器或者锁存器`，就可以组成一个 `N 位（Bit）的寄存器`，能够保存 N 位的数据。比方说，用的 64 位 Intel 服务器，寄存器就是 64 位的

![](image/CPU寄存器.png)

一个 CPU 里面会有很多种不同功能的寄存器，下面是三种比较特殊的：
- （1）`PC 寄存器（Program Counter Register）`，也叫`指令地址寄存器（Instruction Address Register）`。顾名思义，它就是用来存放下一条需要执行的计算机指令的内存地址。
- （2）`指令寄存器（Instruction Register）`，用来存放当前正在执行的指令。
- （3）`条件码寄存器（Status Register）`，用里面的一个一个标记位（Flag），存放 CPU 进行算术或者逻辑计算的结果；

除了这些特殊的寄存器，CPU 里面还有更多用来存储数据和内存地址的寄存器。这样的寄存器通常一类里面不止一个。通常根据存放的数据内容来给它们取名字，
- 比如整数寄存器、浮点数寄存器、向量寄存器和地址寄存器等等。
- 有些寄存器既可以存放数据，又能存放地址，我们就叫它通用寄存器

![](image/CPU寄存器与指令对应.png)

**CPU是如何执行指令的？**
- 一个程序执行的时候，CPU 会根据 PC 寄存器里的地址，从内存里面把需要执行的指令读取到指令寄存器里面执行，然后根据指令长度自增，开始顺序读取下一条指令。可以看到，一个程序的一条条指令，在内存里面是连续保存的，也会一条条顺序加载；
- 有些特殊指令，比如 J 类指令，也就是跳转指令，会修改 PC 寄存器里面的地址值。这样，下一条要执行的指令就不是从内存里面顺序加载的了。事实上，这些跳转指令的存在，也是可以在写程序的时候，使用 `if…else` 条件语句和 `while/for` 循环语句的原因；

## 3.3、指令跳转

### 3.3.1、if...else 的指令跳转

看一段简单的代码
```c
// test.c
#include <time.h>
#include <stdlib.h>
int main()
{
  srand(time(NULL));
  int r = rand() % 2;
  int a = 10;
  if (r == 0)
  {
    a = 1;
  } else {
    a = 2;
  }
}
// 执行如下命令
$ gcc -g -c test.c
$ objdump -d -M intel -S test.o 
```
编译之后，忽略除 if...else之外的汇编代码：
```c
    if (r == 0)
  3b:   83 7d fc 00             cmp    DWORD PTR [rbp-0x4],0x0
  3f:   75 09                   jne    4a <main+0x4a>
    {
        a = 1;
  41:   c7 45 f8 01 00 00 00    mov    DWORD PTR [rbp-0x8],0x1
  48:   eb 07                   jmp    51 <main+0x51>
    }
    else
    {
        a = 2;
  4a:   c7 45 f8 02 00 00 00    mov    DWORD PTR [rbp-0x8],0x2
  51:   b8 00 00 00 00          mov    eax,0x0
    } 
```
分析上述汇编代码：
（1）这里对于 `r == 0` 的条件判断，被编译成了 `cmp` 和 `jne` 这两条指令：
- cmp 指令比较了前后两个操作数的值，这里的 `DWORD PTR` 代表操作的数据类型是 32 位的整数，而 `[rbp-0x4]` 则是一个寄存器的地址。所以，第一个操作数就是从寄存器里拿到的变量 r 的值。第二个操作数 `0x0` 就是设定的常量 0 的 16 进制表示。`cmp` 指令的比较结果，会存入到`条件码寄存器`当中去；<br/>
  如果比较的结果是 True，也就是 r == 0，就把`零标志条件码`（对应的条件码是 ZF，`Zero Flag`）设置为 1。除了零标志之外，Intel 的 CPU 下还有`进位标志`（CF，Carry Flag）、`符号标志`（SF，Sign Flag）以及`溢出标志`（OF，Overflow Flag），用在不同的判断条件下；

- cmp 指令执行完成之后，PC 寄存器会自动自增，开始执行下一条 jne 的指令； jne 指令，是` jump if not equal` 的意思，它会查看对应的零标志位。
  - 如果为 0，会跳转到后面跟着的操作数 4a 的位置。这个 4a，对应这里汇编代码的行号，也就是上面设置的 else 条件里的第一条指令。当跳转发生的时候，PC 寄存器就不再是自增变成下一条指令的地址，而是被直接设置成这里的 4a 这个地址。这个时候，CPU 再把 4a 地址里的指令加载到指令寄存器中来执行；

    跳转到执行地址为 4a 的指令，实际是一条 mov 指令，第一个操作数和前面的 cmp 指令一样，是另一个 32 位整型的寄存器地址，以及对应的 2 的 16 进制值 0x2。mov 指令把 2 设置到对应的寄存器里去，相当于一个赋值操作。然后，PC 寄存器里的值继续自增，执行下一条 mov 指令； mov 指令的第一个操作数 eax，代表累加寄存器，第二个操作数 0x0 则是 16 进制的 0 的表示。这条指令其实没有实际的作用，它的作用是一个占位符

  - 如果if条件满足的话，在赋值的 mov 指令（位置：41）执行完成之后，有一个 jmp 的无条件跳转指令。跳转的地址就是这一行的地址 51。 main 函数没有设定返回值，而 mov eax, 0x0 其实就是给 main 函数生成了一个默认的为 0 的返回值到累加器里面。if 条件里面的内容执行完成之后也会跳转到这里，和 else 里的内容结束之后的位置是一样的

![](image/CPU指令-if-else指令执行过程.png)

### 3.3.2、如何实现循环

CPU指令来实现循序一般是通过  `if…else` 和 `goto` 来实现循环，如何实现？看一段代码：
```c
int main()
{
    int a = 0;
    for (int i = 0; i < 3; i++)
    {
        a += i;
    }
}
```
编译成汇编代码之后：
```c
    for (int i = 0; i < 3; i++)
   b:   c7 45 f8 00 00 00 00    mov    DWORD PTR [rbp-0x8],0x0
  12:   eb 0a                   jmp    1e <main+0x1e>
    {
        a += i;
  14:   8b 45 f8                mov    eax,DWORD PTR [rbp-0x8]
  17:   01 45 fc                add    DWORD PTR [rbp-0x4],eax
    for (int i = 0; i < 3; i++)
  1a:   83 45 f8 01             add    DWORD PTR [rbp-0x8],0x1
  1e:   83 7d f8 02             cmp    DWORD PTR [rbp-0x8],0x2
  22:   7e f0                   jle    14 <main+0x14>
  24:   b8 00 00 00 00          mov    eax,0x0
    }
```
对应的循环也是用 1e 这个地址上的 cmp 比较指令，和紧接着的 `jle` 条件跳转指令来实现的。主要的差别在于，这里的 jle 跳转的地址，在这条指令之前的地址 `14`，而非 `if…else` 编译出来的跳转指令之后。往前跳转使得条件满足的时候，PC 寄存器会把指令地址设置到之前执行过的指令位置，重新执行之前执行过的指令，直到条件不满足，顺序往下执行 jle 之后的指令，整个循环才结束

![](image/CPU指令-循环指令执行过程.png)

jle 和 jmp 指令，有点像程序语言里面的 goto 命令，直接指定了一个特定条件下的跳转位置；想要在硬件层面实现这个 goto 语句，除了本身需要用来保存下一条指令地址，以及当前正要执行指令的 PC 寄存器、指令寄存器外，只需要再增加一个`条件码寄存器`，来保留条件判断的状态。这样简简单单的三个寄存器，就可以实现条件判断和循环重复执行代码的功能

## 3.4、函数调用

- [程序栈压栈和出栈](https://manybutfinite.com/post/journey-to-the-stack/)
- [程序栈压栈和出栈](https://manybutfinite.com/post/epilogues-canaries-buffer-overflows/)

### 3.4.1、为什么需要程序栈

先看一段代码：
```c
// function_example.c
#include <stdio.h>
int static add(int a, int b)
{
    return a+b;
}
int main()
{
    int x = 5;
    int y = 10;
    int u = add(x, y);
}
```
把这个程序编译之后，objdump 出来。我们来看一看对应的汇编代码
```
$ gcc -g -c function_example.c
$ objdump -d -M intel -S function_example.o
```
对应的汇编代码如下：
```c
function_example.o:     file format elf64-x86-64
Disassembly of section .text:
0000000000000000 <add>:
// function_example.c
int static add(int a, int b)
{
   0:   55                      push   rbp
   1:   48 89 e5                mov    rbp,rsp
   4:   89 7d fc                mov    DWORD PTR [rbp-0x4],edi
   7:   89 75 f8                mov    DWORD PTR [rbp-0x8],esi
    return a+b;
   a:   8b 55 fc                mov    edx,DWORD PTR [rbp-0x4]
   d:   8b 45 f8                mov    eax,DWORD PTR [rbp-0x8]
  10:   01 d0                   add    eax,edx
}
  12:   5d                      pop    rbp
  13:   c3                      ret    
0000000000000014 <main>:
int main()
{
  14:   55                      push   rbp
  15:   48 89 e5                mov    rbp,rsp
  18:   48 83 ec 10             sub    rsp,0x10
    int x = 5;
  1c:   c7 45 fc 05 00 00 00    mov    DWORD PTR [rbp-0x4],0x5
    int y = 10;
  23:   c7 45 f8 0a 00 00 00    mov    DWORD PTR [rbp-0x8],0xa
    int u = add(x, y);
  2a:   8b 55 f8                mov    edx,DWORD PTR [rbp-0x8]
  2d:   8b 45 fc                mov    eax,DWORD PTR [rbp-0x4]
  30:   89 d6                   mov    esi,edx
  32:   89 c7                   mov    edi,eax
  34:   e8 c7 ff ff ff          call   0 <add>
  39:   89 45 f4                mov    DWORD PTR [rbp-0xc],eax
  3c:   b8 00 00 00 00          mov    eax,0x0
}
  41:   c9                      leave  
  42:   c3                      ret 
```
跟前面的汇编代码主要区别是：把 `jump` 指令换成了函数调用的 `call` 指令。 `call` 指令后面跟着的，仍然是跳转后的程序地址

先看add函数，add 函数编译之后，代码先执行了一条 push 指令和一条 mov 指令；在函数执行结束的时候，又执行了一条 pop 和一条 ret 指令。这四条指令的执行，其实就是在进行要讲`压栈（Push）`和`出栈（Pop）`操作。

函数调用和 `if…else` 和 `for/while` 循环有点像，它们两个都是在原来顺序执行的指令过程里，执行了一个内存地址的跳转指令，让指令从原来顺序执行的过程里跳开，从新的跳转后的位置开始执行；
- `if…else` 和 `for/while` 的跳转，是跳转走了就不再回来了，就在跳转后的新地址开始顺序地执行指令；
- 函数调用的跳转，在对应函数的指令执行完了之后，还要再回到函数调用的地方，继续执行 call 之后的指令；

  思考：有没有一个可以不跳转回到原来开始的地方，来实现函数的调用呢？可以把调用的函数指令，直接插入在调用函数的地方，替换掉对应的 call 指令，然后在编译器编译代码的时候，直接就把函数调用变成对应的指令替换掉；不过，仔细琢磨一下，会发现这个方法有些问题：如果函数 A 调用了函数 B，然后函数 B 再调用函数 A，就得面临在 A 里面插入 B 的指令，然后在 B 里面插入 A 的指令，这样就会产生无穷无尽地替换。就好像两面镜子面对面放在一块儿，任何一面镜子里面都会看到无穷多面镜子

函数的跳转是单独在内存中开辟一块空间，用栈这个后进先出（LIFO，Last In First Out）的数据结构，栈就像一个乒乓球桶：
- 每次程序调用函数之前，都把调用返回后的地址写在一个乒乓球上，然后塞进这个球桶。这个操作其实就是常说的`压栈`。
- 如果函数执行完了，就从球桶里取出最上面的那个乒乓球，很显然，这就是`出栈`；

在真实的程序里，压栈的不只有函数调用完成后的返回地址。比如函数 A 在调用 B 的时候，需要传输一些参数数据，这些参数数据在寄存器不够用的时候也会被压入栈中。整个函数 A 所占用的所有内存空间，就是函数 A 的`栈帧（Stack Frame）`

而实际的程序栈布局，顶和底与我们的乒乓球桶相比是倒过来的。底在最上面，顶在最下面，这样的布局是因为栈底的内存地址是在一开始就固定的。而一层层压栈之后，栈顶的内存地址是在逐渐变小而不是变大；

![](image/CPU指令-函数调用-压栈出栈过程.png)

对应上面的汇编代码，main 函数调用 add 函数时，add 函数入口在 0～1 行，add 函数结束之后在 12～13 行：
- 第 34 行的 call 指令时，会把当前的 PC 寄存器里的下一条指令的地址压栈，保留函数调用结束后要执行的指令地址；而 add 函数的第 0 行，`push rbp` 这个指令，就是在进行`压栈`。这里的` rbp 又叫栈帧指针（Frame Pointer）`，是一个存放了`当前栈帧位置的寄存器`。`push rbp` 就把之前调用函数，也就是 main 函数的栈帧的栈底地址，压到栈顶；
- 接着，第 1 行的一条命令 `mov rbp, rsp` 里，则是把 `rsp` 这个栈指针（Stack Pointer）的值复制到 `rbp` 里，而 `rsp 始终会指向栈顶`。这个命令意味着，`rbp 这个栈帧指针指向的地址`，变成当前最新的栈顶，也就是 add 函数的栈帧的栈底地址了；
- 在函数 add 执行完成之后，又会分别调用第 12 行的 pop rbp 来将当前的栈顶出栈，这部分操作维护好了我们整个栈帧。然后，我们可以调用第 13 行的 ret 指令，这时候同时要把 call 调用的时候压入的 PC 寄存器里的下一条指令出栈，更新到 PC 寄存器中，将程序的控制权返回到出栈后的栈顶

**如何构造一个 stack overflow**

通过引入栈，可以看到，无论有多少层的函数调用，或者在函数 A 里调用函数 B，再在函数 B 里调用 A，这样的递归调用，都只需要通过维持 rbp 和 rsp，这两个维护栈顶所在地址的寄存器，就能管理好不同函数之间的跳转。不过，栈的大小也是有限的。如果函数调用层数太多，往栈里压入它存不下的内容，程序在执行的过程中就会遇到栈溢出的错误，这就是“stack overflow”

### 3.4.2、如何利用函数内联进行性能优化

前面提到把一个实际调用的函数产生的指令，直接插入到的位置，来替换对应的函数调用指令。尽管这个通用的函数调用方案，不适用，但是如果被调用的函数里，没有调用其他函数，这个方法还是可以行得通的；

这就是一个常见的编译器进行自动优化的场景，我们通常叫函数内联（Inline）；只要在 GCC 编译的时候，加上对应的一个让编译器自动优化的参数 -O，编译器就会在可行的情况下，进行这样的指令替换
```c
// function_example_inline.c
#include <stdio.h>
#include <time.h>
#include <stdlib.h>
 
int static add(int a, int b)
{
    return a+b;
}
int main()
{
    srand(time(NULL));
    int x = rand() % 5;
    int y = rand() % 10;
    int u = add(x, y);
    printf("u = %d\n", u)
}
// 编译命令：
$ gcc -g -c -O function_example_inline.c
$ objdump -d -M intel -S function_example_inline.o
```
汇编代码：上面的 function_example_inline.c 的编译出来的汇编代码，没有把 add 函数单独编译成一段指令顺序，而是在调用 u = add(x, y) 的时候，直接替换成了一个 add 指令。
```c
 return a+b;
  4c:   01 de                   add    esi,ebx
```
内联带来的优化是，CPU 需要执行的指令数变少了，根据地址跳转的过程不需要了，压栈和出栈的过程也不用了。

不过内联并不是没有代价，内联意味着，把可以复用的程序指令在调用它的地方完全展开了。如果一个函数在很多地方都被调用了，那么就会展开很多次，整个程序占用的空间就会变大了，这样没有调用其他函数，只会被调用的函数，我们一般称之为**叶子函数（或叶子过程）**。

## 3.5、ELF和静态链接

既然程序最终都被变成了一条条机器码去执行，那为什么同一个程序，在同一台计算机上，在 Linux 下可以运行，而在 Windows 下却不行呢？反过来，Windows 上的程序在 Linux 上也是一样不能执行的。可是CPU 并没有换掉，它应该可以识别同样的指令呀？

### 3.5.1、编译、链接和装载

C语言程序是如何变成一个可执行程序的？有如下两段代码：
```c
// add_lib.c
int add(int a, int b)
{
    return a+b;
}
// link_example.c
#include <stdio.h>
int main()
{
    int a = 10;
    int b = 5;
    int c = add(a, b);
    printf("c = %d\n", c);
}
```
通过 gcc 来编译这两个文件，然后通过 objdump 命令看看它们的汇编代码
```bash
[root@bluefish language]# gcc -g -c add_lib.c link_example.c
[root@bluefish language]# objdump -d -M intel -S add_lib.o
add_lib.o:     file format elf64-x86-64
Disassembly of section .text:
0000000000000000 <add>:
   0:   55                      push   rbp
   1:   48 89 e5                mov    rbp,rsp
   4:   89 7d fc                mov    DWORD PTR [rbp-0x4],edi
   7:   89 75 f8                mov    DWORD PTR [rbp-0x8],esi
   a:   8b 55 fc                mov    edx,DWORD PTR [rbp-0x4]
   d:   8b 45 f8                mov    eax,DWORD PTR [rbp-0x8]
  10:   01 d0                   add    eax,edx
  12:   5d                      pop    rbp
  13:   c3                      ret    
[root@bluefish language]# objdump -d -M intel -S link_example.o
link_example.o:     file format elf64-x86-64
Disassembly of section .text:
0000000000000000 <main>:
   0:   55                      push   rbp
   1:   48 89 e5                mov    rbp,rsp
   4:   48 83 ec 10             sub    rsp,0x10
   8:   c7 45 fc 0a 00 00 00    mov    DWORD PTR [rbp-0x4],0xa
   f:   c7 45 f8 05 00 00 00    mov    DWORD PTR [rbp-0x8],0x5
  16:   8b 55 f8                mov    edx,DWORD PTR [rbp-0x8]
  19:   8b 45 fc                mov    eax,DWORD PTR [rbp-0x4]
  1c:   89 d6                   mov    esi,edx
  1e:   89 c7                   mov    edi,eax
  20:   b8 00 00 00 00          mov    eax,0x0
  25:   e8 00 00 00 00          call   2a <main+0x2a>
  2a:   89 45 f4                mov    DWORD PTR [rbp-0xc],eax
  2d:   8b 45 f4                mov    eax,DWORD PTR [rbp-0xc]
  30:   89 c6                   mov    esi,eax
  32:   48 8d 3d 00 00 00 00    lea    rdi,[rip+0x0]        # 39 <main+0x39>
  39:   b8 00 00 00 00          mov    eax,0x0
  3e:   e8 00 00 00 00          call   43 <main+0x43>
  43:   b8 00 00 00 00          mov    eax,0x0
  48:   c9                      leave  
  49:   c3                      ret    
```
既然代码已经“编译”成了指令，不妨尝试运行一下 `./link_example.o`。不幸的是，文件没有执行权限，遇到一个 Permission denied 错误。即使通过 chmod 命令赋予 link_example.o 文件可执行的权限，运行`./link_example.o` 仍然只会得到一条 `cannot execute binary file: Exec format error` 的错误；objdump出来的两个程序的地址都是从 0开始的，如果地址是一样的，程序如果需要通过 call 指令调用函数的话，它怎么知道应该跳转到哪一个文件里呢？

无论是这里的运行报错，还是 objdump 出来的汇编代码里面的重复地址，都是因为 add_lib.o 以及 link_example.o 并不是一个`可执行文件（Executable Program）`，而是·。只有通过链接器（Linker）把多个目标文件以及调用的各种函数库链接起来，才能得到一个可执行文件：
```bash
$ gcc -o link-example add_lib.o link_example.o
$ ./link_example
c = 15
```
**C 语言代码 - 汇编代码 - 机器码** 这个过程，在计算机上进行的时候是由两部分组成的：
- 第一个部分由编译（Compile）、汇编（Assemble）以及链接（Link）三个阶段组成。在这三个阶段完成之后，就生成了一个可执行文件；
- 第二部分，通过装载器（Loader）把可执行文件装载（Load）到内存中。CPU 从内存中读取指令和数据，来开始真正执行程序

![](image/C语言装载-执行过程.png)

### 3.5.2、ELF 格式和链接

程序最终是通过装载器变成指令和数据的，所以其实生成的可执行代码也并不仅仅是一条条的指令。通过 objdump 指令，把`可执行文件`的内容拿出来看看：
```bash
[root@bluefish language]# objdump -d -M intel -S link-example
link-example:     file format elf64-x86-64

Disassembly of section .init:
...
Disassembly of section .plt:
...
Disassembly of section .text:
...

000000000040052d <add>:
int add(int a, int b)
{
  40052d:	55                   	push   rbp
  40052e:	48 89 e5             	mov    rbp,rsp
  400531:	89 7d fc             	mov    DWORD PTR [rbp-0x4],edi
  400534:	89 75 f8             	mov    DWORD PTR [rbp-0x8],esi
    return a+b;
  400537:	8b 45 f8             	mov    eax,DWORD PTR [rbp-0x8]
  40053a:	8b 55 fc             	mov    edx,DWORD PTR [rbp-0x4]
  40053d:	01 d0                	add    eax,edx
}
  40053f:	5d                   	pop    rbp
  400540:	c3                   	ret    

0000000000400541 <main>:
#include <stdio.h>
int main()
{
  400541:	55                   	push   rbp
  400542:	48 89 e5             	mov    rbp,rsp
  400545:	48 83 ec 10          	sub    rsp,0x10
    int a = 10;
  400549:	c7 45 fc 0a 00 00 00 	mov    DWORD PTR [rbp-0x4],0xa
    int b = 5;
  400550:	c7 45 f8 05 00 00 00 	mov    DWORD PTR [rbp-0x8],0x5
    int c = add(a, b);
  400557:	8b 55 f8             	mov    edx,DWORD PTR [rbp-0x8]
  40055a:	8b 45 fc             	mov    eax,DWORD PTR [rbp-0x4]
  40055d:	89 d6                	mov    esi,edx
  40055f:	89 c7                	mov    edi,eax
  400561:	b8 00 00 00 00       	mov    eax,0x0
  400566:	e8 c2 ff ff ff       	call   40052d <add>
  40056b:	89 45 f4             	mov    DWORD PTR [rbp-0xc],eax
    printf("c = %d\n", c);
  40056e:	8b 45 f4             	mov    eax,DWORD PTR [rbp-0xc]
  400571:	89 c6                	mov    esi,eax
  400573:	bf 20 06 40 00       	mov    edi,0x400620
  400578:	b8 00 00 00 00       	mov    eax,0x0
  40057d:	e8 8e fe ff ff       	call   400410 <printf@plt>
}
  400582:	c9                   	leave  
  400583:	c3                   	ret    
  400584:	66 2e 0f 1f 84 00 00 	nop    WORD PTR cs:[rax+rax*1+0x0]
  40058b:	00 00 00 
  40058e:	66 90                	xchg   ax,ax
...

Disassembly of section .fini:
...
```
在 Linux 下，可执行文件和目标文件所使用的都是一种叫`ELF（Execuatable and Linkable File Format）`的文件格式，中文名字叫`可执行与可链接文件格式`，这里面不仅存放了编译成的汇编指令，还保留了很多别的数据；

**符号表：** 像 add、main 等等，乃至自己定义的全局可以访问的变量名称，都存放在这个 ELF 格式文件里。这些名字和它们对应的地址，在 ELF 文件里面，存储在一个叫作`符号表（Symbols Table）`的位置里。符号表相当于一个地址簿，把名字和地址关联了起来；

main 函数里调用 add 的跳转地址，不再是下一条指令的地址了，而是 add 函数的入口地址了，这就是 EFL 格式和链接器的功劳；

![](image/Linux-ELF文件格式.png)

**ELF文件格式**

ELF 文件格式把各种信息，分成一个一个的 Section 保存起来。ELF 有一个基本的文件头（File Header），用来表示这个文件的基本属性，比如是否是可执行文件，对应的 CPU、操作系统等等。除了这些基本属性之外，大部分程序还有这么一些 Section：
- 首先是`.text Section`，也叫作`代码段`或者指令段（Code Section），用来保存程序的代码和指令；
- 接着是`.data Section`，也叫作`数据段`（Data Section），用来保存程序里面设置好的初始化数据信息；
- 然后就是`.rel.text Secion`，叫作`重定位表`（Relocation Table）。重定位表里，保留的是当前的文件里面，哪些跳转地址其实是不知道的。比如上面的 link_example.o 里面，在 main 函数里面调用了 add 和 printf 这两个函数，但是在链接发生之前，并不知道该跳转到哪里，这些信息就会存储在重定位表里；
- 最后是`.symtab Section`，叫作`符号表`（Symbol Table）。符号表保留了当前文件里面定义的函数名称和对应地址的地址簿。

**可执行文件生成过程：**
- 链接器会扫描所有输入的目标文件，然后把所有符号表里的信息收集起来，构成一个全局的符号表。
- 然后再根据重定位表，把所有不确定要跳转地址的代码，根据符号表里面存储的地址，进行一次修正。
- 最后，把所有的目标文件的对应段进行一次合并，变成了最终的可执行代码。这也是为什么，可执行文件里面的函数调用的地址都是正确的；

在链接器把程序变成可执行文件之后，要装载器去执行程序就容易多了。装载器不再需要考虑地址跳转的问题，只需要解析 ELF 文件，把对应的指令和数据，加载到内存里面供 CPU 执行就可以了

![](image/Linux-ELF文件-生成链接过程.png)

**为什么同样一个程序，在 Linux 下可以执行而在 Windows 下不能执行了。其中一个非常重要的原因就是，两个操作系统下可执行文件的格式不一样**

## 3.6、程序分页装载

### 3.6.1、程序装载的挑战

可执行文件运行时，实际上是通过一个装载器，解析 ELF 或者 PE 格式的可执行文件。装载器会把对应的指令和数据加载到内存里面来，让 CPU 去执行；

**装载器需要满足两个要求：**
- 执行程序加载后占用的内存空间应该是连续的：执行指令的时候，程序计数器是顺序地一条一条指令执行下去。这也就意味着，这一条条指令需要连续地存储在一起；
- 需要同时加载很多个程序，并且不能让程序自己规定在内存中加载的位置，虽然编译出来的指令里已经有了对应的各种各样的内存地址，但是实际加载的时候，没有办法确保，这个程序一定加载在哪一段内存地址上。因为现在的计算机通常会同时运行很多个程序，可能你想要的内存地址已经被其他加载了的程序占用了；

**如何满足上述条件：**

可以在内存里面，找到一段连续的内存空间，然后分配给装载的程序，然后把这段连续的内存空间地址，和整个程序指令里指定的内存地址做一个映射：
- 指令里用到的内存地址叫作`虚拟内存地址`（Virtual Memory Address）；
- 实际在内存硬件里面的空间地址，叫`物理内存地址`（Physical Memory Address；

程序里有指令和各种内存地址，只需要关心虚拟内存地址就行了。对于任何一个程序来说，它看到的都是同样的内存地址。

维护一个虚拟内存到物理内存的映射表，这样实际程序指令执行的时候，会通过虚拟内存地址，找到对应的物理内存地址，然后执行。因为是连续的内存地址空间，所以只需要维护映射关系的`起始地址`和`对应的空间大小`即可

### 3.6.2、内存分段

找出一段连续的物理内存和虚拟内存地址进行映射的方法，叫**分段（Segmentation）**。这里的段，就是指系统分配出来的那个连续的`内存空间`；

分段的优缺点：
- 优点：解决了程序本身不需要关心具体的物理内存地址的问题；
- 缺点：其中一个就是内存碎片（Memory Fragmentation）的问题

比如：我现在手头的这台电脑，有 1GB 的内存。<br/>
（1）我们先启动一个图形渲染程序，占用了 512MB 的内存，接着启动一个 Chrome 浏览器，占用了 128MB 内存，再启动一个 Python 程序，占用了 256MB 内存。<br/>
（2）这个时候，关掉 Chrome，于是空闲内存还有 1024 - 512 - 256 = 256MB。按理来说，我们有足够的空间再去装载一个 200MB 的程序。但是，这 256MB 的内存空间不是连续的，而是被分成了两段 128MB 的内存。因此，实际情况是，我们的程序没办法加载进来；

上面问题的解决办法：`内存交换（Memory Swapping）` —— 可以把 Python 程序占用的那 256MB 内存写到硬盘上，然后再从硬盘上读回来到内存里面。不过读回来的时候，不再把它加载到原来的位置，而是紧紧跟在那已经被占用了的 512MB 内存后面。这样，就有了连续的 256MB 内存空间，就可以去加载一个新的 200MB 的程序

**总结：**

`虚拟内存`、`分段`，再加上`内存交换`，看起来似乎已经解决了计算机同时装载运行很多个程序的问题。不过，这三者的组合仍然会遇到一个性能瓶颈：硬盘的访问速度要比内存慢很多，而每一次内存交换，都需要把一大段连续的内存数据写到硬盘上。
> 所以，如果内存交换的时候，交换的是一个很占内存空间的程序，这样整个机器都会显得卡顿；

### 3.6.2、内存分页

解决问题的思路：问题出在内存碎片和内存交换的空间太大上，解决问题的办法：
- 少出现一些内存碎片；
- 当需要进行内存交换的时候，让需要交换写入或者从磁盘装载的数据更少一点

上面解决问题的办法：在现在计算机的内存管理里面，就叫作`内存分页（Paging）`，和分段这样分配一整段连续的空间给到程序相比，`分页是把整个物理内存空间切成一段段固定尺寸的大小`，对应的程序所需要占用的虚拟内存空间，也会同样切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间，叫`页（Page）`；

从虚拟内存到物理内存的映射，不再是拿整段连续的内存的物理地址，而是按照一个一个页来的。页的尺寸一般远远小于整个程序的大小。

在 Linux 下，通常只设置成 4KB。可以通过命令看看 Linux 系统设置的页的大小：
```bash
[root@bluefish ~]# getconf PAGE_SIZE
4096
```
- 由于内存空间都是预先划分好的，也就没有了不能使用的碎片，而只有被释放出来的很多 4KB 的页。即使内存空间不够，需要让现有的、正在运行的其他程序，通过内存交换释放出一些内存的页出来，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，让整个机器被内存交换的过程给卡住；
- 分页的方式使得在加载程序的时候，不再需要一次性都把程序加载到物理内存中。完全可以在进行虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存里，而是只在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去；

**缺页错误：**

操作系统也是这么干的：当要读取特定的页，却发现数据并没有加载到物理内存里的时候，就会触发一个来自于 CPU 的缺页错误（Page Fault）。操作系统会捕捉到这个错误，然后将对应的页，从存放在硬盘上的虚拟内存里读取出来，加载到物理内存里。这种方式，使得我们可以运行那些远大于我们实际物理内存的程序。同时，这样一来，任何程序都不需要一次性加载完所有指令和数据，只需要加载当前需要用到就行了

通过虚拟内存、内存交换和内存分页这三个技术的组合，最终得到了一个让程序不需要考虑实际的物理内存地址、大小和当前分配空间的解决方案。这些技术和方法，对于程序的编写、编译和链接过程都是透明的。这也是我们在计算机的软硬件开发中常用的一种方法，就是`加入一个间接层`；

> 总结：通过引入虚拟内存、页映射和内存交换，程序本身不再需要考虑对应的真实的内存地址、程序加载、内存管理等问题了。任何一个程序，都只需要把内存当成是一块完整而连续的空间来直接使用

？在 Java 这样使用虚拟机的编程语言里面，我们写的程序是怎么装载到内存里面来的呢？jvm已经是上层应用，无需考虑物理分页，一般更直接是考虑对象本身的空间大小，物理硬件管理统一由承载jvm的操纵系统去解决吧

# 参考资料

- [计算机科学速成课](https://github.com/chenlanqing/Crash-Course-Computer-Science-Chinese)
- [图解计算机基础](https://xiaolincoding.com/)
- [如何开发操作系统](http://osdev.foofun.cn/index.php?title=Expanded_Main_Page)
- [计算机底层资料分享](https://github.com/liuyubobobo/cool-open-sharings)
- [计算机学习路线](https://csguide.cn/roadmap/)
- [计算机专业学习路线](https://hackway.org/docs/cs/intro)
