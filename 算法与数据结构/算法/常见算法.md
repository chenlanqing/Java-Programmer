<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
**目录**

- [一、一致性Hash算法](#%E4%B8%80%E4%B8%80%E8%87%B4%E6%80%A7hash%E7%AE%97%E6%B3%95)
- [二、加密算法](#%E4%BA%8C%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95)
- [三、缓存淘汰算法](#%E4%B8%89%E7%BC%93%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AE%97%E6%B3%95)
  - [1、LRU-根据数据的历史访问记录来进行淘汰数据](#1lru-%E6%A0%B9%E6%8D%AE%E6%95%B0%E6%8D%AE%E7%9A%84%E5%8E%86%E5%8F%B2%E8%AE%BF%E9%97%AE%E8%AE%B0%E5%BD%95%E6%9D%A5%E8%BF%9B%E8%A1%8C%E6%B7%98%E6%B1%B0%E6%95%B0%E6%8D%AE)
- [四、A*寻路算法](#%E5%9B%9Ba%E5%AF%BB%E8%B7%AF%E7%AE%97%E6%B3%95)
- [五、分治算法](#%E4%BA%94%E5%88%86%E6%B2%BB%E7%AE%97%E6%B3%95)
  - [1、概述](#1%E6%A6%82%E8%BF%B0)
- [六、动态规划](#%E5%85%AD%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92)
  - [1、概述](#1%E6%A6%82%E8%BF%B0-1)
  - [2、斐波那契数列](#2%E6%96%90%E6%B3%A2%E9%82%A3%E5%A5%91%E6%95%B0%E5%88%97)
- [七、贪心算法](#%E4%B8%83%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95)
- [八、回溯](#%E5%85%AB%E5%9B%9E%E6%BA%AF)
- [九、分支界定](#%E4%B9%9D%E5%88%86%E6%94%AF%E7%95%8C%E5%AE%9A)
- [十、海量数据处理算法](#%E5%8D%81%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E7%AE%97%E6%B3%95)
  - [1、BitMap算法](#1bitmap%E7%AE%97%E6%B3%95)
  - [2、布隆过滤器](#2%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8)
- [参考资料](#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

# 一、一致性Hash算法

- [一致性哈希算法原理](https://www.cnblogs.com/lpfuture/p/5796398.html)

## 1、定义

一致性哈希将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0-2^32-1（即哈希值是一个32位无符号整型），整个空间按顺时针方向组织。0和232-1在零点中方向重合；

![](image/Hash环.png)

## 2、一致性Hash特性

- 平衡性(Balance)：是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用；
- 单调性(Monotonicity)：是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲区加入到系统中，那么哈希的结果应能够保证原有已分配的内容可以被映射到新的缓冲区中去，而不会被映射到旧的缓冲集合中的其他缓冲区；
- 分散性(Spread)：
- 负载(Load)：
- 平滑性(Smoothness)：是指缓存服务器的数目平滑改变和缓存对象的平滑改变是一致的

## 3、Hash环的偏斜

一致性哈希算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜问题，例如系统中只有两台服务器，其环分布如下：

![](image/Hash环偏斜.png)

此时必然造成大量数据集中到Node A上，而只有极少量会定位到Node B上

- 虚拟节点：为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点

    具体做法可以在服务器ip或主机名的后面增加编号来实现。例如上面的情况，可以为每台服务器计算三个虚拟节点，于是可以分别计算 “Node A#1”、“Node A#2”、“Node A#3”、“Node B#1”、“Node B#2”、“Node B#3”的哈希值，于是形成六个虚拟节点：

    ![](image/Hash环偏斜与虚拟节点.png)

    同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，例如定位到“Node A#1”、“Node A#2”、“Node A#3”三个虚拟节点的数据均定位到Node A上。这样就解决了服务节点少时数据倾斜的问题。在实际应用中，通常将虚拟节点数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布；


# 二、加密算法



# 三、缓存淘汰算法

* [缓存淘汰算法](http://flychao88.iteye.com/blog/1977653)

## 1、LRU算法

* [什么是LRU算法](https://mp.weixin.qq.com/s/h_Ns5HY27NmL_odCYLgx_Q)

根据数据的历史访问记录来进行淘汰数据，其核心思想是：如果数据最近被访问过，那么将来被访问的几率也更高

### 1.1、实现：最常见的实现是使用一个链表保存缓存数

使用的数据结构：哈希链表；在哈希链表当中，这些Key-Value不再是彼此无关的存在，而是被一个链条串了起来。每一个Key-Value都具有它的前驱Key-Value、后继Key-Value，就像双向链表中的节点一样，这样一来，原本无序的哈希表拥有了固定的排列顺序；
- 新数据插入链表头部;
- 每当缓存命中（即缓存数据被访问）,则将数据移动到链表头部;
- 当链表满的时候,将链表尾部的数据丢弃;

### 1.2、分析

- 命中率：当存在热点数据时,LRU的效率很好,但偶发性的\周期性的批量操作会导致LRU命中率急剧下降,缓存污染情况比较严重；
- 实现简单；
- 代价：命中时需要遍历链表,找到命中的数据索引,然后将数据移到头部；

### 1.3、源码实现

- 实现1：[LRUMap](https://github.com/chenlanqing/algorithm-learning/blob/master/src/main/java/com/interview/lru/LRUMap.java)

- 实现2：使用LinkedHashMap来实现，LinkedHashMap 内部也有维护一个双向队列，在初始化时也会给定一个缓存大小的阈值，初始化时自定义是否需要删除最近不常使用的数据，如果是则会按照实现二中的方式管理数据：
    ```java
    protected boolean removeEldestEntry(Map.Entry<K,V> eldest) {
        return false;
    }
    ```
    我们自定义大于了阈值时返回 true，这样 LinkedHashMap 就会帮我们删除最近最少使用的数据

# 四、A*寻路算法

https://mp.weixin.qq.com/s/FYKR_1yBKR4GJTn0fFIuAA

# 五、分治算法

## 1、概述

### 1.1、基本概念

分而治之，把一个复杂的问题分成两个或更多的相同或相似的子问题，再把子问题分成更小的子问题……直到最后子问题可以简单的直接求解，原问题的解即子问题的解的合并；

### 1.2、设计思想与策略

- 设计思想

  将一个难以直接解决的大问题，分割成一些规模较小的相同问题，以便各个击破，分而治之

- 分治策略

  对于一个规模为n的问题，若该问题可以容易地解决（比如说规模n较小）则直接解决，否则将其分解为k个规模较小的子问题，这些子问题互相独立且与原问题形式相同，递归地解这些子问题，然后将各子问题的解合并得到原问题的解

### 1.3、分治法所能解决问题的特征

- （1）该问题的规模缩小到一定的程度就可以容易地解决；
- （2）该问题可以分解为若干个规模较小的相同问题，即该问题具有最优子结构性质
- （3）利用该问题分解出的子问题的解可以合并为该问题的解；
- （4）该问题所分解出的各个子问题是相互独立的，即子问题之间不包含公共的子子问题

第一条特征是绝大多数问题都可以满足的，因为问题的计算复杂性一般是随着问题规模的增加而增加

第二条特征是应用分治法的前提它也是大多数问题可以满足的，此特征反映了递归思想的应用

**第三条特征是关键，能否利用分治法完全取决于问题是否具有第三条特征，如果具备了第一条和第二条特征，而不具备第三条特征，则可以考虑用贪心法或动态规划法**

*第四条特征涉及到分治法的效率，如果各子问题是不独立的则分治法要做许多不必要的工作，重复地解公共的子问题，此时虽然可用分治法，但一般用动态规划法较好*

### 1.4、分治法的基本步骤

- （1）分解：将原问题分解为若干个规模较小，相互独立，与原问题形式相同的子问题；
- （2）解决：若子问题规模较小而容易被解决则直接解，否则递归地解各个子问题
- （3）合并：将各个子问题的解合并为原问题的解

### 1.5、可用分治法解决的经典问题

- 二分搜索
- [大整数乘法](https://github.com/chenlanqing/learningNote/blob/master/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E7%AE%97%E6%B3%95/%E7%AE%97%E6%B3%95%E9%A2%98.md#4%E5%A4%A7%E6%95%B0%E7%9A%84%E4%B9%98%E6%B3%95)
- Strassen矩阵乘法
- 棋盘覆盖
- [归并排序](https://github.com/chenlanqing/learningNote/blob/master/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E7%AE%97%E6%B3%95/%E6%8E%92%E5%BA%8F/Java%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95.md#4%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F-on--log-n)
- [快速排序](https://github.com/chenlanqing/learningNote/blob/master/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E7%AE%97%E6%B3%95/%E6%8E%92%E5%BA%8F/Java%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95.md#5%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F-%E7%B1%BB%E4%BC%BC%E4%BA%8E%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F)
- 线性时间选择
- 最接近点对问题
- 循环赛日程表
- 汉诺塔


# 六、动态规划

## 1、概述
### 1.1、动态规划

将原问题拆解成若干个子问题，同时保存子问题的答案，使得每个子问题只求解一次，最终获得原问题的答案；是求解决策过程(decision process)最优化的数学方法；

把多阶段过程转化为一系列单阶段问题，利用各阶段之间的关系，逐个求解，创立了解决这类过程优化问题的新方法；

### 1.2、动态规划的本质是-递归问题
### 1.3、基本思想

与分治算法类类似，是将待求解的问题分解为若干个子问题(阶段)，按顺序求解子阶段，前一子问题的解为后一子问题的求解.

多数有重叠子问题这个特点，为减少重复计算，对每一个子问题只解一次，将其不同阶段的不同状态保存在一个二维数组中

### 1.4、与分治算法区别

适合于用动态规划法求解的问题，经分解后得到的子问题往往不是互相独立的，即下一个子阶段的求解是建立在上一个子阶段的解的基础上，进行进一步的求解。

### 1.5、适用情况

- 最优化原理：如果问题的最优解所包含的子问题的解也是最优的，就称该问题具有最优子结构，即满足最优化原理；
- 无后效性：即某阶段状态一旦确定，就不受这个状态以后决策的影响。也就是说，某状态以后的过程不会影响以前的状态，只与当前状态有关。
- 有重叠子问题：即子问题之间是不独立的，一个子问题在下一阶段决策中可能被多次使用到；该性质并不是动态规划适用的必要条件，但是如果没有这条性质，动态规划算法同其他算法相比就不具备优势.

### 1.6、求解的基本步骤

动态规划所处理的问题是一个多阶段决策问题，动态规划的设计都有着一定的模式，一般要经历以下几个步骤：初始状态→│决策１│→│决策２│→…→│决策ｎ│→结束状态

- （1）划分阶段：按照问题的时间或空间特征，把问题分为若干个阶段。在划分阶段时，注意划分后的阶段一定要是有序的或者是可排序的，否则问题就无法求解；
- （2）确定状态和状态变量： 将问题发展到各个阶段时所处于的各种客观情况用不同的状态表示出来.当然，状态的选择要满足无后效性；
- （3）确定决策并写出状态转移方程： 因为决策和状态转移有着天然的联系，状态转移就是根据上一阶段的状态和决策来导出本阶段的状态。根据相邻两个阶段的状态之间的关系来确定决策方法和状态转移方程.
- （4）寻找边界条件：给出的状态转移方程是一个递推式，需要一个递推的终止条件或边界条件.

实际应用中可以按以下几个简化的步骤进行设计：

- A、分析最优解的性质，并刻画其结构特征。
- B、递归的定义最优解。
- C、以自底向上或自顶向下的记忆化方式（备忘录法）计算出最优值
- D、根据计算最优值时得到的信息，构造问题的最优解

### 1.7、算法实现
最重要的就是确定动态规划三要素-问题的阶段、每个阶段的状态、从前一个阶段转化到后一个阶段之间的递推关系

- 推关系必须是从次小的问题开始到较大的问题之间的转化，从这个角度来说，动态规划往往可以用递归程序来实现。不过因为递推可以充分利用前面保存的子问题的解来减少重复计算，所以对于大规模问题来说，有递归不可比拟的优势，这也是动态规划算法的核心之处
- 确定了动态规划的这三要素，整个求解过程就可以用一个最优决策表来描述，最优决策表是一个二维表，其中行表示决策的阶段，列表示问题状态，表格需要填写的数据一般对应此问题的在某个阶段某个状态下的最优值.

## 2、斐波那契数列
```java
/**
  * 基本算法：里面有很多重复运算，其最终的递归结果是一个递归树；<br/>
  * 比如计算 5：<br/>
  * 先计算 4、3；<br/>
  * 计算 4 的话需要计算3、2；计算 3 的话计算 2、1；<br/>
  * 计算 3 的话计算 2、1；。。。。<br/>
  * 如此重复计算：3 重复计算了两次，2 重复计算了三次，如果更大的输的话，重复计算的次数将会非常巨大。<br/>
  * 该算法的时间复杂度为指数级的 O(2^N)。
  */
public static int bruteForce(int n) {
    if (n == 0) {
        return 0;
    }
    if (n == 1) {
        return 1;
    }
    return bruteForce(n - 1) + bruteForce(n - 2);
}
/**
  * 记忆搜索（备忘录）：在基本算法的思路上将有计算过的数据存储起来，如果有重复计算的，就不递归调用；<br/>
  * 该算法的时间复杂度是：O(N)，空间复杂度是：O(N)-因为需要申请空间来存储计算过的数据
  */
public static int memorySearch(int n, Map<Integer, Integer> memo) {
    if (n == 0) {
        return 0;
    }
    if (n == 1) {
        return 1;
    }
    if (!memo.containsKey(n)) {
        memo.put(n, memorySearch(n - 1, memo) + memorySearch(n - 2, memo));
    }
    return memo.get(n);
}

/**
  * 动态规划法：其实跟记忆搜索类似，记忆搜索是自顶向下解决问题；而动态规划是自下而上解决问题；<br/>
  * 相比于 记忆搜索法，这里动态规划并未使用递归，减少了函数的调用栈空间；同时减少了数据的搜索过程；<br/>
  * 该算法的时间复杂度是：O(N)，空间复杂度是：O(N)-因为需要申请空间来存储计算过的数据
  */
public static int dynamicProgramming(int n) {
    List<Integer> list = new ArrayList<>(n);
    list.add(0);
    list.add(1);
    for (int i = 2; i <= n; i++) {
        list.add(list.get(i - 1) + list.get(i - 2));
    }
    return list.get(n);
}
```

- 矩阵

# 七、贪心算法

- [删去k个数字后的最小值](https://mp.weixin.qq.com/s/4pK5MLMkcuX_1RK_2Pth9g)


# 八、回溯

# 九、分支界定

# 十、海量数据处理算法

## 1、BitMap算法

https://mp.weixin.qq.com/s/xxauNrJY9HlVNvLrL5j2hg

## 2、布隆过滤器

* [布隆算法](https://mp.weixin.qq.com/s/RmR5XmLeMvk35vgjwxANFQ)

# 十一、TimeWheel算法

## 资料
- [Netty源码解读之时间轮算法实现](https://zacard.net/2016/12/02/netty-hashedwheeltimer/)

# 十二、牛顿迭代法

https://mp.weixin.qq.com/s/NyOO6408rLN524vCB0-KhA

# 十三、泰勒公式法



# 参考资料
* [面试和算法心得](https://www.kancloud.cn/kancloud/the-art-of-programming/41619)




