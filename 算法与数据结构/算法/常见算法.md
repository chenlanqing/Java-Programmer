<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
**目录**

- [一、一致性Hash算法](#%E4%B8%80%E4%B8%80%E8%87%B4%E6%80%A7hash%E7%AE%97%E6%B3%95)
  - [1、定义](#1%E5%AE%9A%E4%B9%89)
  - [2、一致性Hash特性](#2%E4%B8%80%E8%87%B4%E6%80%A7hash%E7%89%B9%E6%80%A7)
  - [3、Hash环的偏斜](#3hash%E7%8E%AF%E7%9A%84%E5%81%8F%E6%96%9C)
- [二、加密算法](#%E4%BA%8C%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95)
- [三、缓存淘汰算法](#%E4%B8%89%E7%BC%93%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AE%97%E6%B3%95)
  - [1、LRU算法](#1lru%E7%AE%97%E6%B3%95)
- [四、A*寻路算法](#%E5%9B%9Ba%E5%AF%BB%E8%B7%AF%E7%AE%97%E6%B3%95)
- [五、分治算法](#%E4%BA%94%E5%88%86%E6%B2%BB%E7%AE%97%E6%B3%95)
  - [1、概述](#1%E6%A6%82%E8%BF%B0)
- [六、动态规划](#%E5%85%AD%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92)
  - [1、概述](#1%E6%A6%82%E8%BF%B0-1)
  - [2、斐波那契数列](#2%E6%96%90%E6%B3%A2%E9%82%A3%E5%A5%91%E6%95%B0%E5%88%97)
- [七、贪心算法](#%E4%B8%83%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95)
- [八、回溯](#%E5%85%AB%E5%9B%9E%E6%BA%AF)
- [九、分支界定](#%E4%B9%9D%E5%88%86%E6%94%AF%E7%95%8C%E5%AE%9A)
- [十、海量数据处理算法](#%E5%8D%81%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E7%AE%97%E6%B3%95)
  - [1、BitMap算法](#1bitmap%E7%AE%97%E6%B3%95)
  - [2、布隆过滤器](#2%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8)
- [十一、TimeWheel算法](#%E5%8D%81%E4%B8%80timewheel%E7%AE%97%E6%B3%95)
  - [资料](#%E8%B5%84%E6%96%99)
- [十二、牛顿迭代法](#%E5%8D%81%E4%BA%8C%E7%89%9B%E9%A1%BF%E8%BF%AD%E4%BB%A3%E6%B3%95)
- [十三、泰勒公式法](#%E5%8D%81%E4%B8%89%E6%B3%B0%E5%8B%92%E5%85%AC%E5%BC%8F%E6%B3%95)
- [十四、算法技巧](#%E5%8D%81%E5%9B%9B%E7%AE%97%E6%B3%95%E6%8A%80%E5%B7%A7)
  - [1、巧用数组下标](#1%E5%B7%A7%E7%94%A8%E6%95%B0%E7%BB%84%E4%B8%8B%E6%A0%87)
  - [2、巧用取余](#2%E5%B7%A7%E7%94%A8%E5%8F%96%E4%BD%99)
  - [3、巧用双指针](#3%E5%B7%A7%E7%94%A8%E5%8F%8C%E6%8C%87%E9%92%88)
  - [4、巧用移位运算](#4%E5%B7%A7%E7%94%A8%E7%A7%BB%E4%BD%8D%E8%BF%90%E7%AE%97)
  - [5、设置哨兵位](#5%E8%AE%BE%E7%BD%AE%E5%93%A8%E5%85%B5%E4%BD%8D)
  - [6、递归问题的优化](#6%E9%80%92%E5%BD%92%E9%97%AE%E9%A2%98%E7%9A%84%E4%BC%98%E5%8C%96)
- [参考资料](#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

# 一、一致性Hash算法

- [一致性哈希算法原理](https://www.cnblogs.com/lpfuture/p/5796398.html)

## 1、定义

一致性哈希将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0-2^32-1（即哈希值是一个32位无符号整型），整个空间按顺时针方向组织。0和232-1在零点中方向重合；

![](image/Hash环.png)

## 2、一致性Hash特性

- 平衡性(Balance)：是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用；
- 单调性(Monotonicity)：是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲区加入到系统中，那么哈希的结果应能够保证原有已分配的内容可以被映射到新的缓冲区中去，而不会被映射到旧的缓冲集合中的其他缓冲区；
- 分散性(Spread)：
- 负载(Load)：
- 平滑性(Smoothness)：是指缓存服务器的数目平滑改变和缓存对象的平滑改变是一致的

## 3、Hash环的偏斜

一致性哈希算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜问题，例如系统中只有两台服务器，其环分布如下：

![](image/Hash环偏斜.png)

此时必然造成大量数据集中到Node A上，而只有极少量会定位到Node B上

- 虚拟节点：为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点

    具体做法可以在服务器ip或主机名的后面增加编号来实现。例如上面的情况，可以为每台服务器计算三个虚拟节点，于是可以分别计算 “Node A#1”、“Node A#2”、“Node A#3”、“Node B#1”、“Node B#2”、“Node B#3”的哈希值，于是形成六个虚拟节点：

    ![](image/Hash环偏斜与虚拟节点.png)

    同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，例如定位到“Node A#1”、“Node A#2”、“Node A#3”三个虚拟节点的数据均定位到Node A上。这样就解决了服务节点少时数据倾斜的问题。在实际应用中，通常将虚拟节点数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布；


# 二、加密算法



# 三、缓存淘汰算法

* [缓存淘汰算法](http://flychao88.iteye.com/blog/1977653)

## 1、LRU算法

* [什么是LRU算法](https://mp.weixin.qq.com/s/h_Ns5HY27NmL_odCYLgx_Q)

根据数据的历史访问记录来进行淘汰数据，其核心思想是：如果数据最近被访问过，那么将来被访问的几率也更高

### 1.1、实现：最常见的实现是使用一个链表保存缓存数

使用的数据结构：哈希链表；在哈希链表当中，这些Key-Value不再是彼此无关的存在，而是被一个链条串了起来。每一个Key-Value都具有它的前驱Key-Value、后继Key-Value，就像双向链表中的节点一样，这样一来，原本无序的哈希表拥有了固定的排列顺序；
- 新数据插入链表头部;
- 每当缓存命中（即缓存数据被访问）,则将数据移动到链表头部;
- 当链表满的时候,将链表尾部的数据丢弃;

### 1.2、分析

- 命中率：当存在热点数据时,LRU的效率很好,但偶发性的\周期性的批量操作会导致LRU命中率急剧下降,缓存污染情况比较严重；
- 实现简单；
- 代价：命中时需要遍历链表,找到命中的数据索引,然后将数据移到头部；

### 1.3、源码实现

- 实现1：[LRUMap](https://github.com/chenlanqing/algorithm-learning/blob/master/interview/src/main/java/com/algorithm/interview/lru/LRUMap.java)

- 实现2：使用LinkedHashMap来实现，LinkedHashMap 内部也有维护一个双向队列，在初始化时也会给定一个缓存大小的阈值，初始化时自定义是否需要删除最近不常使用的数据，如果是则会按照实现二中的方式管理数据：
    ```java
    protected boolean removeEldestEntry(Map.Entry<K,V> eldest) {
        return false;
    }
    ```
    我们自定义大于了阈值时返回 true，这样 LinkedHashMap 就会帮我们删除最近最少使用的数据

# 四、A*寻路算法

https://mp.weixin.qq.com/s/FYKR_1yBKR4GJTn0fFIuAA

# 五、分治算法

## 1、概述

### 1.1、基本概念

分而治之，把一个复杂的问题分成两个或更多的相同或相似的子问题，再把子问题分成更小的子问题……直到最后子问题可以简单的直接求解，原问题的解即子问题的解的合并；

### 1.2、设计思想与策略

- 设计思想

  将一个难以直接解决的大问题，分割成一些规模较小的相同问题，以便各个击破，分而治之

- 分治策略

  对于一个规模为n的问题，若该问题可以容易地解决（比如说规模n较小）则直接解决，否则将其分解为k个规模较小的子问题，这些子问题互相独立且与原问题形式相同，递归地解这些子问题，然后将各子问题的解合并得到原问题的解

### 1.3、分治法所能解决问题的特征

- （1）该问题的规模缩小到一定的程度就可以容易地解决；
- （2）该问题可以分解为若干个规模较小的相同问题，即该问题具有最优子结构性质
- （3）利用该问题分解出的子问题的解可以合并为该问题的解；
- （4）该问题所分解出的各个子问题是相互独立的，即子问题之间不包含公共的子子问题

第一条特征是绝大多数问题都可以满足的，因为问题的计算复杂性一般是随着问题规模的增加而增加

第二条特征是应用分治法的前提它也是大多数问题可以满足的，此特征反映了递归思想的应用

**第三条特征是关键，能否利用分治法完全取决于问题是否具有第三条特征，如果具备了第一条和第二条特征，而不具备第三条特征，则可以考虑用贪心法或动态规划法**

*第四条特征涉及到分治法的效率，如果各子问题是不独立的则分治法要做许多不必要的工作，重复地解公共的子问题，此时虽然可用分治法，但一般用动态规划法较好*

### 1.4、分治法的基本步骤

- （1）分解：将原问题分解为若干个规模较小，相互独立，与原问题形式相同的子问题；
- （2）解决：若子问题规模较小而容易被解决则直接解，否则递归地解各个子问题
- （3）合并：将各个子问题的解合并为原问题的解

### 1.5、可用分治法解决的经典问题

- 二分搜索
- [大整数乘法](算法题.md#4大数的乘法)
- Strassen矩阵乘法
- 棋盘覆盖
- [归并排序](排序/Java排序算法.md#4归并排序-on--log-n)
- [快速排序](排序/Java排序算法.md#5快速排序-类似于归并排序)
- 线性时间选择
- 最接近点对问题
- 循环赛日程表
- 汉诺塔


# 六、动态规划

## 1、概述

### 1.1、动态规划

将原问题拆解成若干个子问题，同时保存子问题的答案，使得每个子问题只求解一次，最终获得原问题的答案；是求解决策过程(decision process)最优化的数学方法；

把多阶段过程转化为一系列单阶段问题，利用各阶段之间的关系，逐个求解，创立了解决这类过程优化问题的新方法；

### 1.2、动态规划的本质是-递归问题

递归问题 -> 重叠子问题
- 记忆化搜索 -> 自顶向下解决问题
- 动态规划 -> 自底向上的解决问题

### 1.3、基本思想

与分治算法类类似，是将待求解的问题分解为若干个子问题(阶段)，按顺序求解子阶段，前一子问题的解为后一子问题的求解.

多数有重叠子问题这个特点，为减少重复计算，对每一个子问题只解一次，将其不同阶段的不同状态保存在一个二维数组中

### 1.4、与分治算法区别

适合于用动态规划法求解的问题，经分解后得到的子问题往往不是互相独立的，即下一个子阶段的求解是建立在上一个子阶段的解的基础上，进行进一步的求解。

### 1.5、适用情况

- 最优化原理：如果问题的最优解所包含的子问题的解也是最优的，就称该问题具有最优子结构，即满足最优化原理；
- 无后效性：即某阶段状态一旦确定，就不受这个状态以后决策的影响。也就是说，某状态以后的过程不会影响以前的状态，只与当前状态有关。
- 有重叠子问题：即子问题之间是不独立的，一个子问题在下一阶段决策中可能被多次使用到；该性质并不是动态规划适用的必要条件，但是如果没有这条性质，动态规划算法同其他算法相比就不具备优势.

### 1.6、求解的基本步骤

动态规划所处理的问题是一个多阶段决策问题，动态规划的设计都有着一定的模式，一般要经历以下几个步骤：初始状态→│决策１│→│决策２│→…→│决策ｎ│→结束状态

- （1）划分阶段：按照问题的时间或空间特征，把问题分为若干个阶段。在划分阶段时，注意划分后的阶段一定要是有序的或者是可排序的，否则问题就无法求解；
- （2）确定状态和状态变量： 将问题发展到各个阶段时所处于的各种客观情况用不同的状态表示出来.当然，状态的选择要满足无后效性；
- （3）确定决策并写出状态转移方程： 因为决策和状态转移有着天然的联系，状态转移就是根据上一阶段的状态和决策来导出本阶段的状态。根据相邻两个阶段的状态之间的关系来确定决策方法和状态转移方程.
- （4）寻找边界条件：给出的状态转移方程是一个递推式，需要一个递推的终止条件或边界条件.

实际应用中可以按以下几个简化的步骤进行设计：

- A、分析最优解的性质，并刻画其结构特征。
- B、递归的定义最优解。
- C、以自底向上或自顶向下的记忆化方式（备忘录法）计算出最优值
- D、根据计算最优值时得到的信息，构造问题的最优解

### 1.7、算法实现

最重要的就是确定动态规划三要素-问题的阶段、每个阶段的状态、从前一个阶段转化到后一个阶段之间的递推关系

- 推关系必须是从次小的问题开始到较大的问题之间的转化，从这个角度来说，动态规划往往可以用递归程序来实现。不过因为递推可以充分利用前面保存的子问题的解来减少重复计算，所以对于大规模问题来说，有递归不可比拟的优势，这也是动态规划算法的核心之处
- 确定了动态规划的这三要素，整个求解过程就可以用一个最优决策表来描述，最优决策表是一个二维表，其中行表示决策的阶段，列表示问题状态，表格需要填写的数据一般对应此问题的在某个阶段某个状态下的最优值.

## 2、斐波那契数列
```java
/**
  * 基本算法：里面有很多重复运算，其最终的递归结果是一个递归树；<br/>
  * 比如计算 5：<br/>
  * 先计算 4、3；<br/>
  * 计算 4 的话需要计算3、2；计算 3 的话计算 2、1；<br/>
  * 计算 3 的话计算 2、1；。。。。<br/>
  * 如此重复计算：3 重复计算了两次，2 重复计算了三次，如果更大的输的话，重复计算的次数将会非常巨大。<br/>
  * 该算法的时间复杂度为指数级的 O(2^N)。
  */
public static int bruteForce(int n) {
    if (n == 0) {
        return 0;
    }
    if (n == 1) {
        return 1;
    }
    return bruteForce(n - 1) + bruteForce(n - 2);
}
/**
  * 记忆搜索（备忘录）：在基本算法的思路上将有计算过的数据存储起来，如果有重复计算的，就不递归调用；<br/>
  * 该算法的时间复杂度是：O(N)，空间复杂度是：O(N)-因为需要申请空间来存储计算过的数据
  */
public static int memorySearch(int n, Map<Integer, Integer> memo) {
    if (n == 0) {
        return 0;
    }
    if (n == 1) {
        return 1;
    }
    if (!memo.containsKey(n)) {
        memo.put(n, memorySearch(n - 1, memo) + memorySearch(n - 2, memo));
    }
    return memo.get(n);
}

/**
  * 动态规划法：其实跟记忆搜索类似，记忆搜索是自顶向下解决问题；而动态规划是自下而上解决问题；<br/>
  * 相比于 记忆搜索法，这里动态规划并未使用递归，减少了函数的调用栈空间；同时减少了数据的搜索过程；<br/>
  * 该算法的时间复杂度是：O(N)，空间复杂度是：O(N)-因为需要申请空间来存储计算过的数据
  */
public static int dynamicProgramming(int n) {
    List<Integer> list = new ArrayList<>(n);
    list.add(0);
    list.add(1);
    for (int i = 2; i <= n; i++) {
        list.add(list.get(i - 1) + list.get(i - 2));
    }
    return list.get(n);
}
```

- 矩阵

# 七、贪心算法

- [删去k个数字后的最小值](https://mp.weixin.qq.com/s/4pK5MLMkcuX_1RK_2Pth9g)


# 八、回溯

回溯是暴力解法的一个主要实现手段；

## 1、概念

## 2、树形问题

## 3、排列问题

## 4、回溯剪枝

## 5、floodFill算法

# 九、分支界定

# 十、海量数据处理算法

## 1、BitMap算法

https://mp.weixin.qq.com/s/xxauNrJY9HlVNvLrL5j2hg

## 2、布隆过滤器

* [布隆算法](https://mp.weixin.qq.com/s/RmR5XmLeMvk35vgjwxANFQ)

# 十一、TimeWheel算法

- [Netty源码解读之时间轮算法实现](https://zacard.net/2016/12/02/netty-hashedwheeltimer/)

## 1、时间轮算法

时间轮其实就是一种环形的数据结构，可以想象成时钟，分成很多格子，一个格子代码一段时间（这个时间越短，Timer的精度越高）。并用一个链表报错在该格子上的到期任务，同时一个指针随着时间一格一格转动，并执行相应格子中的到期任务。任务通过取摸决定放入那个格子；

![](image/TimerWheel.png)

以上图为例，假设一个格子是1秒，则整个wheel能表示的时间段为8s，假如当前指针指向2，此时需要调度一个3s后执行的任务，显然应该加入到(2+3=5)的方格中，指针再走3次就可以执行了；如果任务要在10s后执行，应该等指针走完一个round零2格再执行，因此应放入4，同时将round（1）保存到任务中。检查到期任务时应当只执行round为0的，格子上其他任务的round应减1

- 添加任务-schedule: O(1) 
- 删除/取消任务-cancel : O(1) 
- expire : 最坏情况O(n)，平均O(1) // 显然格子越多每个格子对应的List就越短，越接近O(1)；最坏情况下所有的任务都在一个格子中，O(n)

单层时间轮只需增加每一轮的格子就能解决链表过长的问题。因此，更倾向使用单层的时间轮，netty4中时间轮的实现也是单层的

## 2、多层时间轮

如果任务的时间跨度很大，数量很大，单层的时间轮会造成任务的round很大，单个格子的链表很长。这时候可以将时间轮分层，类似于时钟的时分秒3层

![](image/TimerWheel-多轮.png)

现在，每个任务除了要维护在当前轮子的round，还要计算在所有下级轮子的round。当本层的round为0时，任务按下级round值被下放到下级轮子，最终在最底层的轮子得到执行。

现在，schedule的复杂度提高到了O(m)，m为轮子的级数，因为要计算每级的round值。

这种方式的优点在于能够保证任务链表的长度一直在比较短的状态，但缺点是需要更多的空间。

## 3、HashWheelTimer

其使用的是单层时间轮来实现的

# 十二、牛顿迭代法

https://mp.weixin.qq.com/s/NyOO6408rLN524vCB0-KhA

# 十三、泰勒公式法


# 十四、算法技巧

## 1、巧用数组下标

数组的下标是一个隐含的很有用的数组，特别是在统计一些数字，或者判断一些整型数是否出现过的时候；

例如，给你一串字母，让你判断这些字母出现的次数时，我们就可以把这些字母作为下标，在遍历的时候，如果字母a遍历到，则arr[a]就可以加1了，即  arr[a]++;

给你n个无序的int整型数组arr，并且这些整数的取值范围都在0-20之间，要你在O(n)的时间复杂度中把这 n 个数按照从小到大的顺序打印出来？
```java
public void f(int arr[]) {
    int[] temp = new int[21];
    for (int i = 0; i < arr.length; i++) {
        temp[arr[i]]++;
    }
    //顺序打印
    for (int i = 0; i < 21; i++) {
        for (int j = 0; j < temp[i]; j++) {
            System.out.println(i);
        }
    }
}
```
又比如计数排序：数组有20个随机整数，取值范围是0~10，要求用最快的顺序速度把这几个数进行排序；

## 2、巧用取余

有时候我们在遍历数组的时候，会进行越界判断，如果下标差不多要越界了，我们就把它置为0重新遍历。

特别是在一些环形的数组中，例如用数组实现的队列。往往会写出这样的代码：
```java
for (int i = 0; i < N; i++) {
    if (pos < N) {
    //没有越界
    // 使用数组arr[pos]
    else {
        pos = 0;//置为0再使用数组
        //使用arr[pos]
        }
    pos++;
}
```
实际上可以使用取余来实现：
```java
for (int i = 0; i < N; i++) {
    //使用数组arr[pos]   (我们假设刚开始的时候pos < N)
    pos = (pos + 1) % N;
}
```

## 3、巧用双指针

对于双指针，在做关于单链表的题是特别有用，比如“判断单链表是否有环”、“如何一次遍历就找到链表中间位置节点”、“单链表中倒数第 k 个节点”等问题。对于这种问题，我们就可以使用双指针了，会方便很多。我顺便说下这三个问题怎么用双指针解决吧

- 判断单链表是否有环：可以设置一个慢指针和一个快指针来遍历这个链表。慢指针一次移动一个节点，而快指针一次移动两个节点，如果该链表没有环，则快指针会先遍历完这个表，如果有环，则快指针会在第二次遍历时和慢指针相遇；

- 如何一次遍历就找到链表中间位置节点：一个快指针和慢指针。慢的一次移动一个节点，而快的两个。在遍历链表的时候，当快指针遍历完成时，慢指针刚好达到中点；

- 单链表中倒数第 k 个节点：设置两个指针，其中一个指针先移动k个节点。之后两个指针以相同速度移动。当那个先移动的指针遍历完成的时候，第二个指针正好处于倒数第k个节点；

## 4、巧用移位运算

有时候我们在进行除数或乘数运算的时候，例如n / 2，n / 4, n / 8这些运算的时候，我们就可以用移位的方法来运算了，这样会快很多

    n / 2 等价于 n >> 1
    n / 4 等价于 n >> 2
    n / 8 等价于 n >> 3

还有一些 &(与)、|(或)的运算，也可以加快运算的速度。例如判断一个数是否是奇数，你可能会这样做
```java
if(n & 1 == 1){
    dosomething();
)
```

## 5、设置哨兵位

在链表的相关问题中，我们经常会设置一个头指针，而且这个头指针是不存任何有效数据的，只是为了操作方便，这个头指针我们就可以称之为哨兵位了

例如我们要删除头第一个节点是时候，如果没有设置一个哨兵位，那么在操作上，它会与删除第二个节点的操作有所不同。但是我们设置了哨兵，那么删除第一个节点和删除第二个节点那么在操作上就一样了，不用做额外的判断。当然，插入节点的时候也一样。

有时候我们在操作数组的时候，也是可以设置一个哨兵的，把arr[0]作为哨兵。例如，要判断两个相邻的元素是否相等时，设置了哨兵就不怕越界等问题了，可以直接arr[i] == arr[i-1]?了。不用怕i = 0时出现越界。

## 6、递归问题的优化

- 对于可以递归的问题考虑状态保存

    当我们使用递归来解决一个问题的时候，容易产生重复去算同一个子问题，这个时候我们要考虑状态保存以防止重复计算

- 考虑自底向上

    对于递归的问题，我们一般都是从上往下递归的，直到递归到最底，再一层一层着把值返回。

    不过，有时候当n比较大的时候，例如当 n = 10000时，那么必须要往下递归10000层直到 n <=2 才将结果慢慢返回，如果n太大的话，可能栈空间会不够用。

对于这种情况，其实我们是可以考虑自底向上的做法

## 7、快速幂思想

# 参考资料
* [面试和算法心得](https://www.kancloud.cn/kancloud/the-art-of-programming/41619)




